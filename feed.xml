<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Torsten Scholak</title>
    <link href="https://tscholak.github.io/feed.xml" rel="self" type="application/rss+xml" />
  <updated>2025-11-19T05:58:31.444324195Z</updated>
  <author>
      <name>Torsten Scholak</name>
  </author>
  <id>https://tscholak.github.io/</id>

  <entry>
      <title>Speed Creates Capability: Why Efficient Attention Matters for AI
Strategy</title>
      <link href="https://tscholak.github.io/posts/speed-creates-capability.html"/>
      <id>https://tscholak.github.io/posts/speed-creates-capability.html</id>
      <updated>2025-11-18T00:00:00Z</updated>
      <category term="ai"/>
      <category term="strategy"/>
      <category term="inference-efficiency"/>
      <category term="hybrid-architectures"/>
      <summary type="html"><![CDATA[<p>If your models think slowly, your roadmap does too. This essay argues
that efficient attention is the hidden control knob for margins, RL
capacity, and agent reliability, and shows how Apriel-H1 makes
chain-of-thought, test-time compute, and large-scale RL practical at
production scale.</p>]]></summary>
      <content type="html"><![CDATA[<p>In my previous post, <a href="/posts/stop-renting-moat.html">Stop
Renting Your Moat</a>, I argued that relying on foundation model APIs
creates a strategic dependency that limits your ability to build
differentiated products. Owning your learning loop (i.e., your data,
your training infrastructure, and your model development) is the only
thing that secures you control over capabilities that matter to your
business.</p>
<p>This is great in theory, but what does it mean in practice? Today I
want to dig into one specific aspect: inference speed. Inference speed
is often treated as an operational concern: reduce costs, improve
latency, optimize user experience. But it should instead be a core part
of your AI strategy, because it determines which capabilities you can
actually build and deploy.</p>
<p>The bottleneck has shifted from a year ago. Back then, the primary
constraint for building reliable AI systems was model quality and how to
make them reason well. Think of <a
href="https://arxiv.org/abs/2501.12948">DeepSeek-R1</a>. Nowadays we
have strong reasoning, including <a
href="https://moonshotai.github.io/Kimi-K2/thinking.html">open-weight
models</a>, and the new constraint has become making them also fast
enough to be useful. Reasoning models are getting slower as they get
better, because better reasoning requires longer chains of thought.
Every additional reasoning step adds latency, which is why the models
achieving the best results on hard problems are also the least practical
to deploy.</p>
<p>It turns out that this is an architectural concern and ultimately
comes down to attention mechanisms. If your reasoning model uses full
attention, then every token attends to every other token in the context.
This gives great fidelity but scales quadratically with context length.
Doubling context length quadruples compute cost. For reasoning models
generating 64k-token internal deliberations, such quadratic scaling
makes long contexts prohibitively expensive to run in practice. That
quadratic cost becomes the hard ceiling on what you can build: You can't
run longer chains because latency becomes unacceptable, you can't deploy
agents that keep full context because memory consumption explodes, and
you can't scale test-time compute because generating multiple candidates
takes too long.</p>
<p>Breaking that quadratic scaling therefore doesn't just reduce costs
but creates capabilities that are qualitatively different from what full
attention can deliver at acceptable latency. A model that runs at twice
the throughput can explore twice as many solution paths in the same time
budget, maintain twice as much context without compression, or serve
twice as many agents in parallel. An agent that keeps full conversation
history across 50 tool calls behaves fundamentally differently from one
that must compress and forget after every 10 interactions.</p>
<p>At the beginning of the year, hybrid architectures mixing efficient
and full attention were research curiosities. Today they're shipping in
production at scale. In the last six months alone: NVIDIA's <a
href="https://arxiv.org/abs/2504.03624">Nemotron-H-47B</a> (9:1
Mamba:attention hybrid, 3x faster), <a
href="https://arxiv.org/abs/2507.22448">Falcon-H1-34B</a> (1:1
intra-layer hybrid, 4x faster prefill, 8x faster decode), <a
href="https://arxiv.org/abs/2506.13585">MiniMax's M1</a> (7:1
Lightning:attention hybrid, 3-4x faster at 100K tokens), NVIDIA's <a
href="https://arxiv.org/abs/2508.14444">Nemotron-Nano-9B-v2</a> (7:1
hybrid, up to 6x faster throughput), <a
href="https://qwen.ai/blog?id=4074cca80393150c248e508aa62983f9cb7d27cd&amp;from=research.latest-advancements-list">Qwen3-Next-80B-A3B</a>
(3:1 hybrid, &gt;10x faster throughput at &gt;32K context), <a
href="https://api-docs.deepseek.com/news/news250929">DeepSeek
V3.2-Exp</a> (sparse attention, 3x faster), and <a
href="https://arxiv.org/abs/2510.26692">Kimi-Linear-48B</a> (3:1 hybrid,
up to 6x faster at 1M tokens).</p>
<p>What's striking is how consistent the pattern is across different
organizations, architectures, and design choices. It always comes down
to mixing efficient attention mechanisms (sparse or linear) with some
full attention layers to preserve global context. The exact ratio varies
(3:1, 7:1, 9:1 efficient-to-full) but the principle is the same. In the
end we see similar throughput gains from 2x to 10x depending on context
length.</p>
<p>This means that the industry has identified quadratic attention cost
as the bottleneck preventing deployment of capabilities teams want to
ship, and efficient hybrids are the response. What makes this strategic
rather than just an efficiency win is that these architectures break the
fundamental tradeoffs that have constrained what you can build.</p>
<h2 id="breaking-the-fast-cheap-good-triangle">Breaking the
Fast-Cheap-Good Triangle</h2>
<p>The conventional wisdom about inference optimization follows the
classic engineering tradeoff: you can have fast, cheap, or good. Pick
two. Want high-quality reasoning with long chains of thought? That's
good but slow and expensive. Want fast responses? Run shorter chains,
sacrifice quality. Want cheap serving costs? Accept higher latency. This
tradeoff has governed production deployment decisions for the past two
years.</p>
<p>Efficient architectures break this triangle by making inference
fundamentally cheaper in compute terms, which cascades through every
dimension simultaneously.</p>
<p>Start with the first-order effects: doubling throughput means you can
serve the same workload at half the cost, or twice the workload on the
same hardware. For API providers, this difference determines gross
margin, because it changes which use cases are economically viable to
support. Enterprises running millions of daily requests see that cost
difference compound into seven-figure annual savings.</p>
<p>But the cheaper serving cost enables something more valuable: you can
now afford to run chain-of-thought reasoning by default, not as an
expensive special mode you activate selectively. When inference is 3-5x
cheaper, you make test-time compute the default serving path rather than
the exception. Every request gets multi-step reasoning, verification,
reflection. The quality improvement from running CoT inference
universally can be larger than most post-training gains.</p>
<p>The UX implications are direct and measurable. Coding agents that
execute tests, query documentation, and validate solutions need to
complete complex workflows in seconds, not tens of seconds. A 20-second
agent breaks user flow because they context-switch to other work and
lose the thread. A 5-second agent stays within the bounds of acceptable
wait time. That 15-second difference determines whether users actually
integrate the agent into their workflow or find reasons to avoid it. For
production agents handling complex multi-step tasks (like database
queries, API calls, file operations, or error recovery) being able to
maintain full context across 50 tool calls instead of compressing
aggressively after 10 changes reliability from "mostly works" to
"actually dependable." These are differences that determine product
success.</p>
<p>The second-order effect is where efficient architectures create
lasting competitive advantage. Cheaper inference means you can afford
substantially more reinforcement learning during post-training. RL
requires generating millions of reasoning traces, scoring them, updating
the model, repeating. With 3-5x faster sampling, you run 3-5 times as
many rollouts on the same budget. That means dramatically denser
feedback signals, far more thorough exploration of solution space,
better model behaviors discovered during training. This compounds.
Better exploration finds better policies, which improve model quality,
which generates better training data for the next RL iteration.</p>
<p>I think this is the real hundred-million-dollar lever. Companies like
Qwen, DeepSeek, and Kimi are investing heavily in efficient
architectures alongside RL-based post-training because the architecture
choice determines how much RL you can afford to run. More RL means
better models. Better models mean better user experience, higher win
rates against competitors, and ultimately stickier products. Efficient
model architectures multiply your post-training capacity on the same
budget, which directly improves model quality.</p>
<p>There is also a third-order effect. The above advantages compound
over time through a reinforcing cycle. Efficient architecture enables
more RL training, which produces better models. Better models drive
higher user adoption and usage. Higher usage would normally explode
serving costs, but efficient architecture keeps costs manageable even as
scale increases. That cost headroom funds another round of intensive RL
training for the next model iteration. Competitors running less
efficient architectures can't match this cycle, because they either
can't afford the RL at scale, or their serving costs grow unsustainably
as usage increases, forcing them to throttle features or raise prices.
In this way, the architecture choice determines whether you can sustain
the compounding advantage or whether each success creates new
constraints.</p>
<h2 id="proving-it-works-for-reasoning">Proving It Works for
Reasoning</h2>
<p>My team at ServiceNow built <a
href="https://arxiv.org/abs/2511.02651">Apriel-H1</a> to settle whether
you can retrofit efficiency into an existing reasoning model without
breaking it. I wrote about the journey <a
href="https://huggingface.co/blog/ServiceNow-AI/apriel-h1">here</a>. We
started with Apriel-15B, our full-attention reasoning model, and
replaced 30 of 50 attention layers with Mamba blocks. We hit 2.1x
throughput with quality holding—math and coding benchmarks stayed flat,
conversational reasoning improved. We did this with 76.8 billion tokens
of distillation and SFT. Retrofitting works.</p>
<p>Distillation de-risks when you have a strong model. From-scratch
training gets you the ceiling (4x to &gt;10x throughput gains) but costs
two orders of magnitude more compute. Companies like Qwen, DeepSeek, and
NVIDIA take this path because they get to co-design architecture and
data from day one.</p>
<p>There's a middle path: slot the architecture change mid-training.
Pretrain with full attention to build a strong foundation, then switch
to a hybrid mid-training to capture efficiency gains. If it doesn't
work, you stay with full attention and haven't lost the pretrain
investment.</p>
<p>The industry is moving. Qwen, DeepSeek, and NVIDIA are shipping
efficient hybrids because they figured out that throughput determines RL
capacity, and RL capacity determines who wins on model quality. They're
treating architecture as strategic, not just operational.</p>
<p>If you're renting inference through APIs, your roadmap depends on
someone else's architecture priorities. When you need longer context or
agent workflows that keep full state, you're constrained by their
optimization choices and economics.</p>
<p>Own your training loop, you control which capabilities exist. Own
your architecture, you control which capabilities deploy. The paths are
proven. The decision is which one matches your constraints.</p>
<hr />
<h2 id="appendix-generating-the-simplex-diagram">Appendix: Generating
the Simplex Diagram</h2>
<p>This <a href="https://wiki.haskell.org/Literate_programming">Literate
Haskell</a> appendix contains the code that generates the
quality-speed-cost simplex diagram shown at the top of this essay.</p>
<p>We use a few language extensions and imports:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE OverloadedStrings #-}</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE RecordWildCards   #-}</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="kw">module</span> <span class="dt">SpeedCreatesCapability</span> <span class="kw">where</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="kw">qualified</span> <span class="dt">Data.Text</span>              <span class="kw">as</span> <span class="dt">T</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="kw">qualified</span> <span class="dt">Data.Text.Lazy.IO</span>      <span class="kw">as</span> <span class="dt">TL</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="kw">qualified</span> <span class="dt">Data.Text.Lazy.Builder</span> <span class="kw">as</span> <span class="dt">B</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span>           <span class="dt">Data.Text.Lazy.Builder</span> (<span class="dt">Builder</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span>           <span class="dt">Numeric</span>                (showFFloat)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span>           <span class="dt">System.Directory</span>       (createDirectoryIfMissing)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span>           <span class="dt">System.FilePath</span>        (takeDirectory)</span></code></pre></div>
<p>Configuration and data types:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Canvas dimensions</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  width,<span class="ot"> height ::</span> <span class="dt">Double</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  width  <span class="ot">=</span> <span class="dv">900</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  height <span class="ot">=</span> <span class="dv">600</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  marginX,<span class="ot"> marginY ::</span> <span class="dt">Double</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  marginX <span class="ot">=</span> <span class="dv">60</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  marginY <span class="ot">=</span> <span class="dv">60</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Barycentric coordinates: (quality, speed, cost)</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="kw">data</span> <span class="dt">BaryCoord</span> <span class="ot">=</span> <span class="dt">Bary</span> <span class="dt">Double</span> <span class="dt">Double</span> <span class="dt">Double</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">deriving</span> (<span class="dt">Show</span>, <span class="dt">Eq</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Normalized coordinates in [0,1]^2</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>  <span class="kw">data</span> <span class="dt">NormCoord</span> <span class="ot">=</span> <span class="dt">Norm</span> <span class="dt">Double</span> <span class="dt">Double</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">deriving</span> (<span class="dt">Show</span>, <span class="dt">Eq</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Pixel coordinates</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>  <span class="kw">data</span> <span class="dt">PixelCoord</span> <span class="ot">=</span> <span class="dt">Pixel</span> <span class="dt">Double</span> <span class="dt">Double</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">deriving</span> (<span class="dt">Show</span>, <span class="dt">Eq</span>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | A region in the simplex</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>  <span class="kw">data</span> <span class="dt">Region</span> <span class="ot">=</span> <span class="dt">Region</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    {<span class="ot"> regionName     ::</span> <span class="dt">T.Text</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    ,<span class="ot"> regionColor    ::</span> <span class="dt">T.Text</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    ,<span class="ot"> regionOpacity  ::</span> <span class="dt">Double</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    ,<span class="ot"> regionVertices ::</span> [<span class="dt">BaryCoord</span>]</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    } <span class="kw">deriving</span> (<span class="dt">Show</span>, <span class="dt">Eq</span>)</span></code></pre></div>
<p>Region positioning philosophy:</p>
<p>These barycentric coordinates are tuned to show regions that reflect
real-world architectural tradeoffs, not extreme theoretical corners.</p>
<p>Key design principles:</p>
<ol>
<li>Each region is a large triangle to show the viable design space</li>
<li>Regions overlap because production models can sit in multiple
zones</li>
<li>Quality values reflect second/third-order effects:
<ul>
<li>Linear attention can reach higher quality by spending speed on RL +
CoT</li>
<li>Hybrids bridge the gap between full attention quality and efficient
speed/cost</li>
</ul></li>
</ol>
<p>Quality ranges:</p>
<ul>
<li>Full attention: q ∈ [0.60, 0.90] - top tier, but extends down to
overlap hybrids</li>
<li>Hybrids: q ∈ [0.35, 0.85] - bridge region, overlaps both
extremes</li>
<li>Linear: q ∈ [0.20, 0.52] - bottom edge is fast/cheap, top reflects
RL gains</li>
</ul>
<p>The apex of linear/hybrid regions represents spending efficiency on
<em>capability</em>, not just on lower cloud bills. You burn surplus
speed on RL + test-time compute to climb the quality ladder at roughly
fixed cost. If we wanted "slash costs at any latency", we'd make it
right-leaning (c &gt; s), but that contradicts the essay: we use speed
primarily to unlock deeper reasoning at production latency. Therefore,
the linear and hybrid regions are slightly left-leaning (s &gt; c).</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ot">  regions ::</span> [<span class="dt">Region</span>]</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  regions <span class="ot">=</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    [ <span class="dt">Region</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        { regionName    <span class="ot">=</span> <span class="st">&quot;Full\nattention\nmodels&quot;</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        , regionColor   <span class="ot">=</span> <span class="st">&quot;#9ca3af&quot;</span>  <span class="co">-- muted gray</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        , regionOpacity <span class="ot">=</span> <span class="fl">0.28</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        , regionVertices <span class="ot">=</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>            <span class="co">-- q ∈ [0.60, 0.90]: High quality, modest speed/cost</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>            [ <span class="dt">Bary</span> <span class="fl">0.90</span> <span class="fl">0.05</span> <span class="fl">0.05</span>  <span class="co">-- FA1: near pure quality</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>            , <span class="dt">Bary</span> <span class="fl">0.60</span> <span class="fl">0.30</span> <span class="fl">0.10</span>  <span class="co">-- FA2: trade some quality for speed</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>            , <span class="dt">Bary</span> <span class="fl">0.60</span> <span class="fl">0.10</span> <span class="fl">0.30</span>  <span class="co">-- FA3: trade some quality for cost</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    , <span class="dt">Region</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        { regionName    <span class="ot">=</span> <span class="st">&quot;Linear\nattention\nmodels&quot;</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        , regionColor   <span class="ot">=</span> <span class="st">&quot;#f59e0b&quot;</span>  <span class="co">-- pale amber</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        , regionOpacity <span class="ot">=</span> <span class="fl">0.18</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        , regionVertices <span class="ot">=</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>            <span class="co">-- q ∈ [0.20, 0.52]: Bottom edge hugs speed/cost extremes</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>            [ <span class="dt">Bary</span> <span class="fl">0.20</span> <span class="fl">0.70</span> <span class="fl">0.10</span>  <span class="co">-- L1: speed-focused extreme</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>            , <span class="dt">Bary</span> <span class="fl">0.20</span> <span class="fl">0.10</span> <span class="fl">0.70</span>  <span class="co">-- L2: cost-focused extreme</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>            , <span class="dt">Bary</span> <span class="fl">0.52</span> <span class="fl">0.35</span> <span class="fl">0.13</span>  <span class="co">-- L3: quality via RL + CoT</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    , <span class="dt">Region</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>        { regionName    <span class="ot">=</span> <span class="st">&quot;Hybrid\nmodels&quot;</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>        , regionColor   <span class="ot">=</span> <span class="st">&quot;#2563eb&quot;</span>  <span class="co">-- rich blue</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>        , regionOpacity <span class="ot">=</span> <span class="fl">0.30</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>        , regionVertices <span class="ot">=</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>            <span class="co">-- q ∈ [0.35, 0.85]: Bridge between full and linear</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>            [ <span class="dt">Bary</span> <span class="fl">0.85</span> <span class="fl">0.09</span> <span class="fl">0.06</span>  <span class="co">-- H1: high quality, closer to full</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>            , <span class="dt">Bary</span> <span class="fl">0.35</span> <span class="fl">0.55</span> <span class="fl">0.10</span>  <span class="co">-- H2: speed-leaning, toward linear</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>            , <span class="dt">Bary</span> <span class="fl">0.35</span> <span class="fl">0.10</span> <span class="fl">0.55</span>  <span class="co">-- H3: cost-leaning, symmetric</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    ]</span></code></pre></div>
<p>Barycentric coordinate system:</p>
<p>The outer triangle vertices in normalized space (x, y) ∈ [0,1]²:</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Quality vertex (top)</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="ot">  qVertex ::</span> <span class="dt">NormCoord</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  qVertex <span class="ot">=</span> <span class="dt">Norm</span> <span class="fl">0.5</span> <span class="fl">1.0</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Speed vertex (bottom-left)</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="ot">  sVertex ::</span> <span class="dt">NormCoord</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  sVertex <span class="ot">=</span> <span class="dt">Norm</span> <span class="fl">0.0</span> <span class="fl">0.0</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Cost vertex (bottom-right)</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="ot">  cVertex ::</span> <span class="dt">NormCoord</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>  cVertex <span class="ot">=</span> <span class="dt">Norm</span> <span class="fl">1.0</span> <span class="fl">0.0</span></span></code></pre></div>
<p>Coordinate transformations:</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Map barycentric (q, s, c) to normalized (x, y)</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="ot">  baryToNorm ::</span> <span class="dt">BaryCoord</span> <span class="ot">-&gt;</span> <span class="dt">NormCoord</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  baryToNorm (<span class="dt">Bary</span> qCoord sCoord cCoord) <span class="ot">=</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> <span class="dt">Norm</span> qx qy <span class="ot">=</span> qVertex</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Norm</span> sx sy <span class="ot">=</span> sVertex</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Norm</span> cx cy <span class="ot">=</span> cVertex</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        x <span class="ot">=</span> qCoord <span class="op">*</span> qx <span class="op">+</span> sCoord <span class="op">*</span> sx <span class="op">+</span> cCoord <span class="op">*</span> cx</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        y <span class="ot">=</span> qCoord <span class="op">*</span> qy <span class="op">+</span> sCoord <span class="op">*</span> sy <span class="op">+</span> cCoord <span class="op">*</span> cy</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">in</span> <span class="dt">Norm</span> x y</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Map normalized (x, y) to pixel coordinates</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="ot">  normToPixels ::</span> <span class="dt">NormCoord</span> <span class="ot">-&gt;</span> <span class="dt">PixelCoord</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>  normToPixels (<span class="dt">Norm</span> x y) <span class="ot">=</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> scaleX <span class="ot">=</span> width  <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> marginX</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        scaleY <span class="ot">=</span> height <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> marginY</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        pxX    <span class="ot">=</span> marginX <span class="op">+</span> x <span class="op">*</span> scaleX</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        pxY    <span class="ot">=</span> height <span class="op">-</span> marginY <span class="op">-</span> y <span class="op">*</span> scaleY  <span class="co">-- Flip y so quality is at the top</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">in</span> <span class="dt">Pixel</span> pxX pxY</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Map barycentric to pixels (composition)</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="ot">  baryToPixels ::</span> <span class="dt">BaryCoord</span> <span class="ot">-&gt;</span> <span class="dt">PixelCoord</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>  baryToPixels <span class="ot">=</span> normToPixels <span class="op">.</span> baryToNorm</span></code></pre></div>
<p>SVG generation helpers:</p>
<p>We use a tiny SVG AST and builder to avoid ad-hoc string
concatenation.</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Minimal SVG AST</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">data</span> <span class="dt">Svg</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="ot">=</span> <span class="dt">Elem</span> <span class="dt">T.Text</span> [(<span class="dt">T.Text</span>, <span class="dt">T.Text</span>)] [<span class="dt">Svg</span>]</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="op">|</span> <span class="dt">Txt</span>  <span class="dt">T.Text</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Format a Double with one decimal place</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="ot">  format1 ::</span> <span class="dt">Double</span> <span class="ot">-&gt;</span> <span class="dt">T.Text</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  format1 x <span class="ot">=</span> T.pack (showFFloat (<span class="dt">Just</span> <span class="dv">1</span>) x <span class="st">&quot;&quot;</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Convert Text to a Builder</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="ot">  tB ::</span> <span class="dt">T.Text</span> <span class="ot">-&gt;</span> <span class="dt">Builder</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>  tB <span class="ot">=</span> B.fromText</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Render attributes: key=&quot;value&quot;</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="ot">  renderAttrs ::</span> [(<span class="dt">T.Text</span>, <span class="dt">T.Text</span>)] <span class="ot">-&gt;</span> <span class="dt">Builder</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>  renderAttrs <span class="ot">=</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">foldMap</span> (\(k, v) <span class="ot">-&gt;</span> <span class="st">&quot; &quot;</span> <span class="op">&lt;&gt;</span> tB k <span class="op">&lt;&gt;</span> <span class="st">&quot;=\&quot;&quot;</span> <span class="op">&lt;&gt;</span> tB v <span class="op">&lt;&gt;</span> <span class="st">&quot;\&quot;&quot;</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Render the SVG AST to a Builder</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="ot">  renderSvg ::</span> <span class="dt">Svg</span> <span class="ot">-&gt;</span> <span class="dt">Builder</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>  renderSvg (<span class="dt">Txt</span> t) <span class="ot">=</span> tB t</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>  renderSvg (<span class="dt">Elem</span> name attrs children) <span class="ot">=</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;&lt;&quot;</span> <span class="op">&lt;&gt;</span> tB name <span class="op">&lt;&gt;</span> renderAttrs attrs <span class="op">&lt;&gt;</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>      <span class="kw">if</span> <span class="fu">null</span> children</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        <span class="kw">then</span> <span class="st">&quot;/&gt;&quot;</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>        <span class="kw">else</span> <span class="st">&quot;&gt;&quot;</span> <span class="op">&lt;&gt;</span> <span class="fu">foldMap</span> renderSvg children <span class="op">&lt;&gt;</span> <span class="st">&quot;&lt;/&quot;</span> <span class="op">&lt;&gt;</span> tB name <span class="op">&lt;&gt;</span> <span class="st">&quot;&gt;&quot;</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Smart constructors</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="ot">  elem_ ::</span> <span class="dt">T.Text</span> <span class="ot">-&gt;</span> [(<span class="dt">T.Text</span>, <span class="dt">T.Text</span>)] <span class="ot">-&gt;</span> [<span class="dt">Svg</span>] <span class="ot">-&gt;</span> <span class="dt">Svg</span></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>  elem_ <span class="ot">=</span> <span class="dt">Elem</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a><span class="ot">  txt_ ::</span> <span class="dt">T.Text</span> <span class="ot">-&gt;</span> <span class="dt">Svg</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>  txt_ <span class="ot">=</span> <span class="dt">Txt</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Polygon helper</span></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a><span class="ot">  polygon ::</span> [<span class="dt">PixelCoord</span>] <span class="ot">-&gt;</span> <span class="dt">T.Text</span> <span class="ot">-&gt;</span> <span class="dt">Double</span> <span class="ot">-&gt;</span> <span class="dt">Svg</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>  polygon pts color opacity <span class="ot">=</span></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> pointText <span class="ot">=</span></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>          T.intercalate <span class="st">&quot; &quot;</span></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>            [ format1 x <span class="op">&lt;&gt;</span> <span class="st">&quot;,&quot;</span> <span class="op">&lt;&gt;</span> format1 y</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>            <span class="op">|</span> <span class="dt">Pixel</span> x y <span class="ot">&lt;-</span> pts</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>    <span class="kw">in</span> elem_ <span class="st">&quot;polygon&quot;</span></span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>         [ (<span class="st">&quot;points&quot;</span>,       pointText)</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>         , (<span class="st">&quot;fill&quot;</span>,         color)</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>         , (<span class="st">&quot;fill-opacity&quot;</span>, format1 opacity)</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>         , (<span class="st">&quot;stroke&quot;</span>,       color)</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>         , (<span class="st">&quot;stroke-width&quot;</span>, <span class="st">&quot;2&quot;</span>)</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>         ]</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>         []</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Multi-line text helper</span></span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a><span class="ot">  textBlock ::</span> <span class="dt">PixelCoord</span> <span class="ot">-&gt;</span> <span class="dt">T.Text</span> <span class="ot">-&gt;</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">Svg</span></span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>  textBlock (<span class="dt">Pixel</span> x y) txt size weight <span class="ot">=</span></span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>    <span class="kw">case</span> T.splitOn <span class="st">&quot;\n&quot;</span> txt <span class="kw">of</span></span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>      [single] <span class="ot">-&gt;</span></span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>        elem_ <span class="st">&quot;text&quot;</span> (baseAttrs y) [txt_ single]</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>      ls <span class="ot">-&gt;</span></span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>        <span class="kw">let</span> lineSpacing <span class="ot">=</span> <span class="fu">fromIntegral</span> size <span class="op">*</span> <span class="fl">1.2</span></span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>            n           <span class="ot">=</span> <span class="fu">length</span> ls</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>            startY      <span class="ot">=</span> y <span class="op">-</span> <span class="fu">fromIntegral</span> (n <span class="op">-</span> <span class="dv">1</span>) <span class="op">*</span> lineSpacing <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>            mkLine i lineTxt <span class="ot">=</span></span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>              <span class="kw">let</span> lineY <span class="ot">=</span> startY <span class="op">+</span> <span class="fu">fromIntegral</span> i <span class="op">*</span> lineSpacing</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>              <span class="kw">in</span> elem_ <span class="st">&quot;text&quot;</span> (baseAttrs lineY) [txt_ lineTxt]</span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>        <span class="kw">in</span> elem_ <span class="st">&quot;g&quot;</span> [] (<span class="fu">zipWith</span> mkLine [<span class="dv">0</span><span class="op">..</span>] ls)</span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>      baseAttrs yPos <span class="ot">=</span></span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>        [ (<span class="st">&quot;x&quot;</span>,           format1 x)</span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>        , (<span class="st">&quot;y&quot;</span>,           format1 yPos)</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>        , (<span class="st">&quot;text-anchor&quot;</span>, <span class="st">&quot;middle&quot;</span>)</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>        , (<span class="st">&quot;font-size&quot;</span>,   T.pack (<span class="fu">show</span> size))</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>        , (<span class="st">&quot;font-weight&quot;</span>, T.pack (<span class="fu">show</span> weight))</span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>        , (<span class="st">&quot;fill&quot;</span>,        <span class="st">&quot;#1f2937&quot;</span>)</span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>        ]</span></code></pre></div>
<p>Main SVG building function:</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | The full SVG node (without XML prolog)</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="ot">  svgRoot ::</span> <span class="dt">Svg</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  svgRoot <span class="ot">=</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> <span class="co">-- Background</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        background <span class="ot">=</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>          elem_ <span class="st">&quot;rect&quot;</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>            [ (<span class="st">&quot;width&quot;</span>,  format1 width)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>            , (<span class="st">&quot;height&quot;</span>, format1 height)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>            , (<span class="st">&quot;fill&quot;</span>,   <span class="st">&quot;#ffffff&quot;</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>            ] []</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        <span class="co">-- Outer simplex</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        outerVertices <span class="ot">=</span> <span class="fu">map</span> normToPixels [qVertex, sVertex, cVertex]</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        outerTriangle <span class="ot">=</span> polygon outerVertices <span class="st">&quot;#d1d5db&quot;</span> <span class="fl">0.0</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>        <span class="co">-- Region triangles</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>        regionPolys <span class="ot">=</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>          [ polygon (<span class="fu">map</span> baryToPixels (regionVertices r))</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>                    (regionColor r)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>                    (regionOpacity r)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>          <span class="op">|</span> r <span class="ot">&lt;-</span> regions</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>          ]</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        <span class="co">-- Axis labels</span></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Pixel</span> qx qy <span class="ot">=</span> normToPixels qVertex</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Pixel</span> sx sy <span class="ot">=</span> normToPixels sVertex</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Pixel</span> cx cy <span class="ot">=</span> normToPixels cVertex</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>        axisLabels <span class="ot">=</span></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>          [ textBlock (<span class="dt">Pixel</span> qx (qy <span class="op">-</span> <span class="dv">15</span>)) <span class="st">&quot;Quality&quot;</span> <span class="dv">20</span> <span class="dv">600</span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>          , textBlock (<span class="dt">Pixel</span> sx (sy <span class="op">+</span> <span class="dv">25</span>)) <span class="st">&quot;Speed&quot;</span>   <span class="dv">20</span> <span class="dv">600</span></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>          , textBlock (<span class="dt">Pixel</span> cx (cy <span class="op">+</span> <span class="dv">25</span>)) <span class="st">&quot;Low cost&quot;</span> <span class="dv">20</span> <span class="dv">600</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>          ]</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>        <span class="co">-- Region labels at centroids</span></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>        regionLabels <span class="ot">=</span></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>          [ <span class="kw">let</span> coords <span class="ot">=</span> <span class="fu">map</span> baryToPixels (regionVertices r)</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>                xs     <span class="ot">=</span> [x <span class="op">|</span> <span class="dt">Pixel</span> x _ <span class="ot">&lt;-</span> coords]</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>                ys     <span class="ot">=</span> [y <span class="op">|</span> <span class="dt">Pixel</span> _ y <span class="ot">&lt;-</span> coords]</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>                n      <span class="ot">=</span> <span class="fu">fromIntegral</span> (<span class="fu">length</span> coords)</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>                mx     <span class="ot">=</span> <span class="fu">sum</span> xs <span class="op">/</span> n</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>                my     <span class="ot">=</span> <span class="fu">sum</span> ys <span class="op">/</span> n</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>                w      <span class="ot">=</span> <span class="kw">if</span> <span class="st">&quot;Hybrid&quot;</span> <span class="ot">`T.isInfixOf`</span> regionName r</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>                            <span class="kw">then</span> <span class="dv">600</span></span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>                            <span class="kw">else</span> <span class="dv">500</span></span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>            <span class="kw">in</span> textBlock (<span class="dt">Pixel</span> mx my) (regionName r) <span class="dv">20</span> w</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>          <span class="op">|</span> r <span class="ot">&lt;-</span> regions</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>          ]</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>        styleNode <span class="ot">=</span></span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>          elem_ <span class="st">&quot;style&quot;</span> []</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>            [ txt_</span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;text {\n      font-family: &#39;PragmataPro&#39;, monospace;\n    }\n&quot;</span></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>        intText n <span class="ot">=</span> T.pack (<span class="fu">show</span> (<span class="fu">round</span><span class="ot"> n ::</span> <span class="dt">Int</span>))</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>    <span class="kw">in</span> elem_ <span class="st">&quot;svg&quot;</span></span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>         [ (<span class="st">&quot;width&quot;</span>,  intText width)</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>         , (<span class="st">&quot;height&quot;</span>, intText height)</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>         , (<span class="st">&quot;viewBox&quot;</span></span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>           , T.concat</span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>               [ <span class="st">&quot;0 0 &quot;</span></span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>               , intText width</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>               , <span class="st">&quot; &quot;</span></span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>               , intText height</span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>               ])</span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>         , (<span class="st">&quot;xmlns&quot;</span>, <span class="st">&quot;http://www.w3.org/2000/svg&quot;</span>)</span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>         ]</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a>         (  [styleNode, background, outerTriangle]</span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a>         <span class="op">++</span> regionPolys</span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>         <span class="op">++</span> axisLabels</span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>         <span class="op">++</span> regionLabels</span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>         )</span></code></pre></div>
<p>Writing the SVG to a file:</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Full document builder (XML prolog + SVG)</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="ot">  documentBuilder ::</span> <span class="dt">Builder</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  documentBuilder <span class="ot">=</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;&lt;?xml version=\&quot;1.0\&quot; encoding=\&quot;UTF-8\&quot;?&gt;\n&quot;</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="op">&lt;&gt;</span> <span class="st">&quot;&lt;?xml-stylesheet type=\&quot;text/css\&quot; href=\&quot;/css/fonts.css\&quot; ?&gt;\n&quot;</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="op">&lt;&gt;</span> renderSvg svgRoot</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">&lt;&gt;</span> <span class="st">&quot;\n&quot;</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="ot">  writeSVG ::</span> <span class="dt">FilePath</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  writeSVG path <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    createDirectoryIfMissing <span class="dt">True</span> (takeDirectory path)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    TL.writeFile path (B.toLazyText documentBuilder)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="ot">  main ::</span> <span class="dt">IO</span> ()</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>  main <span class="ot">=</span> writeSVG <span class="st">&quot;images/speed-creates-capability.svg&quot;</span></span></code></pre></div>]]></content>
  </entry>
  <entry>
      <title>Trouble in LA LA Land: Did MiniMax Just Kill Efficient Attention?</title>
      <link href="https://tscholak.github.io/posts/minimax-m2.html"/>
      <id>https://tscholak.github.io/posts/minimax-m2.html</id>
      <updated>2025-10-30T00:00:00Z</updated>
      <category term="ai"/>
      <category term="linear-attention"/>
      <summary type="html"><![CDATA[<p>When you're building efficient LLMs and a major industrial lab says
"we tried this path, it doesn't work at scale," your first instinct is
to listen (and cry). Maybe your assumptions are wrong. Maybe you're
about to waste a lot of compute chasing a dead end. That's where I was
this week.</p>]]></summary>
      <content type="html"><![CDATA[<p>My team is betting big on hybrid architectures: mixing full and
efficient attention (SWA/sparse, linear/SSM, etc.) with learned layer
placement. Then MiniMax dropped their <a
href="https://www.zhihu.com/question/1965302088260104295/answer/1966810157473335067">M2
post-mortem bomb</a> on October 25th explaining to everyone why they
went back to quadratic attention for their 230B model. By October 29th,
<a href="https://x.com/giffmana/status/1983457240452673710">the</a> <a
href="https://x.com/zpysky1125/status/1983383094607347992">internet</a>
<a href="https://x.com/p_nawrot/status/1983579777844834459">was</a> <a
href="https://x.com/DBahdanau/status/1983909078414831987">convinced</a>:
efficient attention is dead. We told you so.</p>
<p>Except that's not what MiniMax said. The more I looked into their
reasoning, the more I realized their decision actually strengthens the
case for efficient hybrids in ways nobody's talking about.</p>
<h2 id="what-minimax-actually-said">What MiniMax Actually Said</h2>
<p>If you read MiniMax's post-mortem carefully, their conclusion is
actually nuanced. They didn't say efficient attention is fundamentally
broken. Their exact words: "一直在做，但是在工业系统里真的打过Full
Attention还有些距离" (We've always been working on it, but truly beating
full attention (FA) in industrial systems still has some way to go). In
other words, efficient attention lacks production readiness at their
scale with today's infrastructure. So it's a question of not if, but
when.</p>
<p>And yeah, I get it. Anyone who's tried to run linear attention in
production knows the pain. I can personally attest to this, because we
did it in our <a
href="https://github.com/ServiceNow/Fast-LLM">Fast-LLM</a> training
framework this year. Build failures from <code>mamba-ssm</code> or FLA
with cryptic CUDA linker errors. An afternoon hunting for the magic
combination of torch version, CUDA toolkit, and kernel implementation
that doesn't segfault. Getting TP to work wasn't straightforward either.
Then the serving stack surprises you by missing chunked prefill,
speculative decoding, or prefix caching. On that note, prefix caching is
the reason why efficient attention often fails to deliver in practice:
once your serving stack caches the prefix, the memory and compute
savings compared to FA vanish. And that's exactly where most production
traffic lives.</p>
<p>Also, FA just works. The kernel ecosystem is mature, and the whole
ecosystem is built around its assumptions. It's still getting better all
the time. For a 230B production model serving millions of users, you
really can't mess around.</p>
<p>Then there's model quality. Their <a
href="https://arxiv.org/abs/2501.08313">Lightning Attention hybrid</a>
crushed the standard benchmarks everybody uses for pretraining ablations
that work without much post-training. Your usual suspects, MMLU, BBH,
LongBench, etc. But when they scaled to large-scale, multi-hop reasoning
and agent tasks with genuinely long contexts, big cracks appeared. After
their pretrained FA model was converted to Lightning Attention hybrids,
performance on these tasks dropped significantly. They attributed this
to the hybrid's inability to maintain the complex attention patterns
that the model had developed during pretraining. These are retrieval
heads, induction heads, and long-range coherence mechanisms that become
structurally essential. They tried detecting critical heads and keeping
only those as FA, but they weren't able to reliably identify and retain
all the patterns.</p>
<p>In the end, they chose certainty over risk. For their timeline and
scale, that was the right call.</p>
<p>But while MiniMax was wrestling with efficient attention, a different
line of research was quietly changing the landscape.</p>
<h2 id="the-delethink-twist">The Delethink Twist</h2>
<p>The recent <a href="https://arxiv.org/abs/2510.06557">Markovian
Thinker</a> work shows something that will send shockwaves through the
efficient attention debate: reasoning is naturally Markovian. Put
simply, when models think step by step, they rarely need to remember the
entire chain of thought. What matters is the most recent slice, the
current working memory.</p>
<p>Delethink from the paper is a technique that exploits this. The idea:
Train a model to reason in 8K-token chunks. Then, at the chunk boundary,
delete the first part of the reasoning chain, keep only the last portion
as carryover state, and continue. Sounds weird and counterintuitive, but
this works reasonably well already for large off-the-shelf models, i.e.
unmodified gpt-oss. Through RL even 1.5B parameter models can learn to
work under the Delethink Markovian constraint. They showed that such a
Delethink-enabled model can think in 8K chunks and match standard
LongCoT-RL performance trained with full 24K context.</p>
<p>I will spell this out for you: <strong>Delethink lets you run FA
models with effectively linear memory and compute for reasoning
tasks.</strong> You chunk the reasoning chain, delete the old parts, and
only keep the recent context. This quietly changes the story for FA. If
you're running a thinking process that generates 50K tokens, FA with
Delethink gives you O(1) memory and O(n) compute. The quadratic blowup
disappears. With this, suddenly we have a credible way to stay on plain
FA, handle longer chains, lower memory, and stick with infrastructure
that already works. The pressure to migrate away from FA drops
significantly.</p>
<p>So MiniMax's decision makes sense for single-shot reasoning. They
(and everyone else) can run FA with Delethink, avoid the engineering
pain of efficient attention, and sidestep the quality risks of hybrids.
But what about M2's actual workload? Does M2 do single-shot
reasoning?</p>
<h2 id="the-m2-problem">The M2 Problem</h2>
<p>No, it doesn't. M2 follows the standard <a
href="https://huggingface.co/blog/MiniMax-AI/aligning-to-what#the-need-for-interleaved-thinking">interleaved-thinking
pattern</a>: it emits <code>&lt;think&gt;...&lt;/think&gt;</code>
blocks, and these blocks accumulate over multi-turn conversations. Every
bit of thinking history needs to be retained, and the <a
href="https://huggingface.co/MiniMaxAI/MiniMax-M2#inference-parameters">README</a>
warns that removing them hurts performance. Thus every exchange adds
more tokens, building up tens of thousands of reasoning tokens that must
stay in memory.</p>
<p>Delethink can't help here because it only works for single reasoning
chains, where you can truncate and carry forward a small state. But in
multi-turn conversations, the thinking tokens from previous turns belong
to conversation history. You can't delete all of them without negatively
impacting performance.</p>
<p>That means the computational blow-up returns. The longer a dialogue
continues, the heavier each turn becomes. MiniMax chose FA while
adopting the interleaved-thinking pattern that makes quadratic scaling
still painful. Every multi-turn conversation pays that quadratic tax
again and again.</p>
<p>So is efficient attention back in the game?</p>
<h2 id="what-jet-nemotron-shows">What Jet Nemotron Shows</h2>
<p>MiniMax's complaint was that you can't manually identify which
attention heads need to be FA. True enough. But <a
href="https://arxiv.org/abs/2508.15884">NVIDIA's Jet Nemotron</a> work
shows you can <strong>learn</strong> the placement.</p>
<p>They built a supernet where each attention block can swap between FA,
SWA, and other efficient alternatives. During training, NVIDIA randomly
switched between options at each layer so all paths get gradient signal.
Hence the "supernet." Afterward, a lightweight search finds the optimal
layer configuration under a compute budget.</p>
<p>For a 4B-parameter 36-layer model and a budget of 3 FA, 7 SWA, and 26
linear layers, that's about 30.5 billion possible architectures in the
search space. But hierarchical beam search finds a top architecture
efficiently. After optimizing the linear attention for the chosen layers
further, they get their Jet-Nemotron-4B that beats Qwen3-1.7B on
standard benchmarks (including reasoning-heavy math tasks) while
delivering a massive 21x speedup at 64k tokens decoding length. The
smaller Jet-Nemotron-2B is slightly behind Qwen3-1.7B but delivers 47x
generation throughput speedup at 64k tokens and still 23x speedup at 8k
tokens. Prefill speedups are more modest, around 2.5x at 64k and 6x at
256k tokens, but still significant.</p>
<p>This is a big deal, and I think MiniMax missed it. The gains from Jet
Nemotron's learned placement are huge, and while the potential only
fully shows with large prefill and long decode (because that's where FA
is memory-bound), the impact is clear, because that's also the regime
interleaved thinking with its accumulated context operates in.</p>
<p>But Jet Nemotron proved this only at 2-4B scale. M2 is 230B
parameters, 57 times larger. Nobody has published results at that scale.
We don't know if you still only need 3 FA layers at 230B scale, or if
you need 10 or 20. We don't know what the compute budget looks like for
training the supernet at the big scale. Until that evidence extends
upward, FA remains the safe bet for massive models.</p>
<h2 id="the-nuanced-story">The Nuanced Story</h2>
<p>So, where does that leave us? It's clear that we can't just proclaim
that linear attention blows FA out of the water anymore. I won't be able
to argue that point convincingly anymore. The story now depends very
much on workload and scale.</p>
<p>For single-shot reasoning, FA plus Delethink is pragmatic. Stable
infrastructure, and the Markovian behavior is already there in
pretrained models. That buys time for the efficient attention ecosystem
to mature. At M2's scale, the infrastructure pain and model quality
risks of hybrids outweigh the compute savings and speed benefits of
efficient attention. FA with Delethink is the right call for the
majority of single-shot reasoning workloads right now.</p>
<p>For multi-turn interleaved thinking, hybrids with learned placement
will eventually become essential. Context accumulates, Delethink can't
reset it, and FA's quadratic cost will dominate. Optimized hybrids will
win that regime, and that's where the field is heading. That's where my
team is heading. See you in the efficient-attention trenches.</p>
<hr />
<p><strong>Update Oct 31, 2025:</strong> The day after I posted this, <a
href="https://huggingface.co/moonshotai/Kimi-Linear-48B-A3B-Instruct">Kimi.ai
released</a> <a
href="https://github.com/fla-org/flash-linear-attention/tree/main/fla/ops/kda">Kimi
Linear Attention (KLA)</a>, a new hybrid architecture that validates the
core argument here in ways even I didn't expect, at least not so
soon.</p>
<p>KLA extends Gated DeltaNet with channel-wise gating (instead of
scalar gating) and interleaves this efficient attention with full
attention in a 3:1 ratio. That ratio matters: just like Jet Nemotron
found that only 2-3 layers out of 36 need FA, Kimi found that roughly
25% FA is enough to maintain quality while cutting KV cache by 75% and
delivering 6x decoding throughput at 1M context.</p>
<p>The results are great. On synthetic tasks like MQAR and Stack, KLA
significantly outperforms Mamba2 and beats Gated DeltaNet. On real
reasoning tasks (AIME 2025, MATH500, LiveCodeBench), it matches or beats
both MLA (DeepSeek's compressed full attention) and Gated DeltaNet-H
after the same SFT recipe. Pretraining scaling laws show 1.16x better
loss at the same compute budget.</p>
<p>Two caveats: First, this is a 3B-activated, 48B-total parameter
model. M2 is 230B total, so roughly 5x larger. We still don't know what
happens at that scale, but the trend is promising. Second, Kimi uses a
fixed 3:1 ratio rather than learned placement, so we don't know if
that's optimal or just good enough.</p>
<p>But here's what matters: within days of MiniMax saying "efficient
attention has some way to go," another major industrial lab shipped a
production-grade hybrid that beats full attention on the metrics that
matter.</p>
<p>The confusion MiniMax's post-mortem created also triggered a flurry
of activity. Everyone working on efficient attention saw an opening and
pushed out their work. <a
href="https://manifestai.com/articles/release-brumby-14b/">Brumby-14B</a>
(an attention-free model converted from Qwen), <a
href="https://arxiv.org/abs/2507.04239">Higher-order Linear
Attention</a>, and several others all dropped within days. The Flash
Linear Attention community <a
href="https://github.com/fla-org/flash-linear-attention/pull/621">merged
Kimi's optimized KDA kernel</a> within hours. There's now active debate
about which approach wins where.</p>
<p>What looked like a setback for efficient attention turned into its
Streisand moment. MiniMax forced everyone to clarify their positions,
tighten their arguments, and ship their code. The infrastructure is
maturing faster than anyone expected. The timeline just got a lot
shorter.</p>]]></content>
  </entry>
  <entry>
      <title>Skills, Composition, and the Coordination Problem</title>
      <link href="https://tscholak.github.io/posts/composable-skills.html"/>
      <id>https://tscholak.github.io/posts/composable-skills.html</id>
      <updated>2025-10-22T00:00:00Z</updated>
      <category term="ai"/>
      <category term="agents"/>
      <summary type="html"><![CDATA[<p>Anthropic released <a
href="https://www.anthropic.com/news/skills">Skills</a> last week, and
the response was immediate: finally, composable AI capabilities! Build
once, reuse anywhere. Give Claude folders of instructions and scripts,
and it'll load what it needs automatically. Modular, portable,
efficient. We'll have reliable AI systems using hundreds or thousands or
hundreds of thousands of skills in no time. There's just one problem:
Skills aren't actually composable, and that creates a coordination
problem that needs to be addressed urgently.</p>]]></summary>
      <content type="html"><![CDATA[<p>When Skills work together to complete a task, fundamental questions
emerge: Who verifies the result is correct? Who gets credit for success
or blame for failure? How does the system learn from millions of such
interactions? Model-mediated coordination alone can't solve these at
scale. The solution requires infrastructure most people building with
Skills haven't considered, and that Anthropic hasn't built yet. The
architectural patterns that solve this problem extend far beyond
multi-agent AI.</p>
<p>This article presents a solution. We'll see why natural language
coordination fails beyond small-scale examples, then work through the
infrastructure that would actually solve it (drawing on principles from
formal verification, market design, and institutional theory). The goal
is understanding how autonomous systems can cooperate reliably when
individual incentives don't naturally align with collective outcomes.
The proposed architecture is precise, and the components exist
today.</p>
<p>This is a follow-up to <a href="/posts/agentkit">"Everyone's Arguing
About the Wrong Abstraction Layer"</a>. That post argued that neither
visual workflow builders nor natural language prompts provide
<em>formal</em> compositional guarantees, and that this lack of
structure creates economic risks as systems scale. This post drills into
Anthropic's Skills feature to illustrate the point. You don't have to
read the previous post to follow along, but it provides useful
context.</p>
<p>The previous piece sparked conversations that shaped this one. When
Anthropic launched Skills, I realized the coordination problem was no
longer hypothetical: it was arriving in production. This article is my
attempt to think through what actually solves it.</p>
<h2 id="what-skills-are">What Skills Are</h2>
<p>A Skill is a folder containing instructions and resources that Claude
loads when relevant. At minimum, it has a <code>SKILL.md</code> file
describing what the Skill does. It can also include executable scripts,
templates, or other supporting files.</p>
<p>Consider a meeting workflow. A <code>transcribe</code> Skill might
contain audio processing instructions and timestamp formatting scripts.
A <code>summarize</code> Skill has prompt templates for different
summary styles. An <code>extract</code> Skill identifies action items. A
<code>format</code> Skill knows your company's email conventions. Each
Skill is self-contained, reusable across contexts (Claude Desktop,
Claude Code, API).</p>
<p>At startup, Claude indexes every Skill by name and description. When
you ask it to "transcribe this meeting and email action items," it
autonomously decides which Skills to load and in what order:
<code>transcribe.audio</code> -&gt; <code>summarize.text</code> -&gt;
<code>extract.actions</code> -&gt; <code>format.email</code>. No
explicit wiring required. Claude orchestrates the sequence based on what
each Skill declares it can do. (That <code>skill.capability</code>
notation is shorthand I'll use throughout for specific capabilities
within Skills, not formal syntax.)</p>
<p><a
href="https://x.com/barry_zyj/status/1978860549837299948">People</a> <a
href="https://x.com/alexalbert__/status/1978877514903884044">are</a> <a
href="https://simonwillison.net/2025/Oct/16/claude-skills/">excited</a>
because this <em>feels</em> like composition: small, independent modules
combining automatically for larger workflows. Skills stack naturally
when multiple are relevant. But from a <em>formal</em> perspective (the
one that lets you build reliable systems), it isn't composition at all,
and that creates serious coordination challenges.</p>
<h2 id="what-skills-are-not">What Skills Are Not</h2>
<p>Formal composition has structure. It defines how pieces fit together
and what happens when they do. Inputs align with outputs. There's an
identity element (something you can compose with anything without
changing it). You can reason about the whole because you understand the
parts.</p>
<p>Is this the case for Skills? No, because they don't have formal
compositional semantics:</p>
<ul>
<li>There's no formal <code>compose(skillA, skillB)</code> operator.
Claude simply decides what to use and to what granularity.</li>
<li>There's no type system or contracts, hence no type safety: In a
chain of actions, the output from skill A may not match the inputs of
skill B.</li>
<li>There's no associativity. <code>(A + B) + C</code> may behave
differently than <code>A + (B + C)</code>. Order of combination
matters.</li>
</ul>
<p>Skills don't compose. Claude orchestrates them heuristically:
interpreting requests, selecting Skills, and routing between them.<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></p>
<p>At small scale, this approach works well enough. For most users,
Skills will feel magical: open a PDF, extract data, format a report.
Done. The model makes the right decisions most of the time, and the
abstraction holds.</p>
<p>But as soon as people start chaining more Skills together, the cracks
appear:</p>
<ul>
<li>Skill A and B work, but A, B, and C in combination fail
unpredictably.</li>
<li>Updating one Skill breaks workflows you didn't know were using
it.</li>
<li>The same workflow can yield very different results depending on what
other Skills are being used or what ran before.</li>
</ul>
<p>Without formal structure, we can't reason about how Skills behave. We
can only test, and even then, the tests aren't stable.</p>
<p>In a nutshell, we've replaced explicit composition with implicit,
model-mediated coordination, and that scales only as far as Claude's
ability to guess correctly.</p>
<p>So how much of a problem is this?</p>
<h2 id="why-coordination-matters">Why Coordination Matters</h2>
<p>Coordination is the linchpin that holds complex systems together. The
more components you have, the more ways they can interact, and the
harder it is to ensure they work together reliably.</p>
<p>The economy of AI systems is moving rapidly toward scale. Enterprises
will want an ever-growing library of specialized skills for compliance,
security, domain knowledge, formatting, localization, and more. Every
team will build custom skills for their workflows. Systems will chain
many skills dynamically based on context, user preferences, and
regulatory requirements. The complexity will explode, and with it, the
coordination challenges.</p>
<p>Some people are optimistic that model intelligence alone will solve
these problems, "ship fast and iterate, it's just a tool, if it's
broken, we'll fix it." That optimism is understandable given current
trends. <a
href="https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/">Research
from METR</a> shows AI's ability to complete long-duration tasks
improving rapidly. Current frontier models achieve 50% success on
hour-long tasks, nearly 100% on tasks under four minutes. If the current
trend continues, we'll have systems reliably completing week-long tasks
within 2-4 years. <a
href="https://www.dwarkesh.com/p/andrej-karpathy">Andrej Karpathy</a>,
who led AI at Tesla and OpenAI, doubts it will: he calls this "the
decade of agents, not the year of agents." AI research itself proves
harder to automate than expected. Karpathy found coding agents "of very
little help" building his LLM training codebase: "They're not very good
at code that has never been written before, which is what we're trying
to achieve when we're building these models." Recursive self-improvement
faces the same barrier.</p>
<p>Even if capabilities do scale as optimists hope, coordination
failures aren't capability problems. <a
href="https://metr.org/blog/2025-06-05-recent-reward-hacking/">METR
found</a> reward hacking in 70-95% of test cases: models knowingly
violating user intent while maximizing specified objectives. <a
href="https://openai.com/index/detecting-and-reducing-scheming-in-ai-models/">Separate
research from OpenAI and Apollo Research</a> found scheming behavior:
models deliberately hiding their intentions while appearing compliant,
even covertly preserving themselves when facing replacement.<a
href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a></p>
<p><a
href="https://fortune.com/2025-06-03/yoshua-bengio-ai-models-dangerous-behaviors-deception-cheating-lying/">Yoshua
Bengio</a>, who won the Turing Award for pioneering deep learning,
observed that these coordination problems emerge from intelligence
itself: frontier models now exhibit deception and goal misalignment in
empirical tests. Smarter models won't fix these problems because, as
Bengio noted, the AI arms race "pushes labs toward focusing on
capability to make the AI more and more intelligent, but not necessarily
put enough emphasis and investment on research on safety." Intelligence
achieves task completion. Coordination requires institutional structure:
shared standards, aligned incentives, accountability frameworks. Those
don't emerge from capability scaling alone.</p>
<p>Right now, we're in the hype phase. Hundreds of billions in AI capex
are already committed. Companies have raised funding on promises of AGI.
Investors expect returns. Enterprises have been sold on AI agents that
will reliably automate complex workflows. The economic pressure to
deploy at scale is immense.</p>
<p>By 2027, if current trends hold, enterprises will be deploying
multi-skill agents for financial consolidations, regulatory compliance,
and hiring decisions. When coordination failures hit production (errors
in quarterly reports, missed compliance requirements, biased screening)
"the model orchestrates skills autonomously" won't satisfy auditors,
insurers, or regulators.</p>
<p>Given that deployment is proceeding regardless of safety researchers'
warnings, the question becomes: do we build coordination infrastructure
proactively or reactively? Waiting for production failures guarantees
reactive regulation and crude capability restrictions. Building it
proactively means designing coordination architecture while systems
remain tractable, before they're operating financial systems and
failures force crude retrofits.</p>
<p>So how do we build that infrastructure?</p>
<h2 id="why-formal-guarantees-arent-enough">Why Formal Guarantees Aren't
Enough</h2>
<p>An obvious answer could be: "Just make it formal." Add types,
contracts, schemas. Verify that skill outputs match skill inputs. Build
a <code>compose(skillA, skillB)</code> operator that actually composes
things. Require Claude to generate formally verifiable plans before
execution.</p>
<p>This would help, but it wouldn't solve the problem.</p>
<p>Formal guarantees make coordination <em>tractable</em>. They prevent
the dumbest failures. They can't prevent the subtle ones. Even perfectly
verified systems misfire when the specifications are wrong, incomplete,
or gameable. And in open-ended environments, specifications are always
at least two of those three.</p>
<p>The specification problem is fundamental. <a
href="https://blog.chain.link/reentrancy-attacks-and-the-dao-hack/">The
DAO smart contract</a> was formally designed with explicit interfaces,
yet lost $50-70 million to a reentrancy attack that exploited the gap
between intended and actual behavior. The code did exactly what the
specification said. The specification said the wrong thing.</p>
<p>Formal methods shine at well-bounded problems: protocol correctness,
safety-critical control loops, system invariants. AI skills are dynamic
behaviors embedded in messy human workflows where "correct" isn't even
well-defined. The complexity comes from the world.</p>
<p>The scalability barrier is fundamental. <a
href="https://amturing.acm.org/award_winners/clarke_1167964.cfm">Edmund
Clarke</a>, who won the Turing Award for inventing <a
href="https://en.wikipedia.org/wiki/Model_checking">model checking</a>,
identified the core problem: as state variables increase, the state
space grows exponentially. For n processes with m states each,
composition may have m^n states. <a
href="https://sel4.systems/">seL4</a> (the most successfully verified
operating system kernel) required 20 person-years to verify 8,700 lines
of C code with 200,000 lines of proof. It's a remarkable achievement for
a microkernel. It doesn't scale to coordinating hundreds of dynamic
skills.</p>
<p>Try to formally verify every possible interaction between skills and
you'll discover why most formal-method projects plateau after a few
components: verification costs explode quadratically while the value of
guarantees grows sublinearly. The economics stop working.</p>
<p>That's why human civilization runs on something else.</p>
<h2 id="how-humans-actually-coordinate">How Humans Actually
Coordinate</h2>
<p>We solved large-scale coordination once already. We used
institutions.</p>
<p>Markets, laws, and peer review manage complexity without central
verification. They don't prove that everyone behaves correctly. They
create feedback loops that punish failure and reward reliability. These
systems are <em>self-correcting</em> without being <em>formally
correct</em>.</p>
<p>But these mechanisms do more than catch errors. They solve problems
that formal verification cannot address at all:</p>
<ul>
<li><p><strong>Markets create information that doesn't
pre-exist.</strong> Prices emerge from millions of decentralized
decisions, revealing preferences and scarcities no central planner could
compute. The FCC spectrum auctions designed by Nobel laureates <a
href="https://www.nobelprize.org/prizes/economic-sciences/2020/popular-information/">Paul
Milgrom and Robert Wilson</a> generated $233 billion across 100 auctions
with less than 1% administrative cost. They elicit optimal allocations
through incentive-compatible mechanisms.</p></li>
<li><p><strong>Legal systems provide legitimacy through
participation.</strong> Courts aren't just error-correctors. They
generate buy-in, establish precedent, and adapt rules to contexts no
specification anticipated. Process matters as much as outcome.</p></li>
<li><p><strong>Science enables discovery under uncertainty.</strong>
Peer review doesn't verify truth. It evaluates plausibility when ground
truth is unknown. <a href="https://www.nber.org/papers/w10002">Alvin
Roth's kidney exchange mechanisms</a> (another Nobel Prize) increased
donor utilization from 55% to 89%, facilitating over 2,000 transplants.
It solved a coordination problem with no "correct" answer to verify
against.</p></li>
</ul>
<p>These systems address problems type-checking cannot solve:</p>
<ul>
<li>incentive alignment when agents have private information,</li>
<li>information creation when optimal solutions are unknown, and</li>
<li>legitimacy when stakeholders must voluntarily participate.</li>
</ul>
<p>These are genuine advantages. But human institutions have a critical
limitation: they self-correct slowly. A bad policy might take years to
reveal itself. Scientific fraud could persist until replication
attempts. Financial markets (our fastest coordination mechanism) <a
href="https://en.wikipedia.org/wiki/2010_flash_crash">crashed in
2010</a> when high-frequency traders created a "hot potato" effect,
dropping the DJIA 998 points in minutes. Implementing circuit breakers
and structural fixes took years. LLM-mediated systems generate, execute,
and fail millions of workflows per hour. They'll accumulate coordination
debt faster than human institutions can correct it. We need institutions
designed to self-correct at the pace AI systems fail.</p>
<h2 id="what-this-actually-requires">What This Actually Requires</h2>
<p>Skills need a three-layer structure combining formal verification,
social coordination, and credit assignment. Each layer addresses
problems the others cannot solve.</p>
<pre><code>APPLICATIONS: Users &amp; Tasks
         ↓ request
┌──────────────────────────────────────────────────────┐
│ FORMAL LAYER: Plan Synthesis &amp; Verification          │
│  • type-checked skill composition                    │
│  • resource budgets enforced                         │
│  • isolation + capability gating                     │
└──────────────────────────────────────────────────────┘
         ↑ plan    ↓ accept/reject    ↓ telemetry
┌──────────────────────────────────────────────────────┐
│ SOCIAL LAYER: Registry &amp; Market                      │
│  • reputation scores (success/failure rates)         │
│  • competitive selection (quality vs. cost)          │
│  • version compatibility tracking                    │
└──────────────────────────────────────────────────────┘
         ↓ outcomes              ↑ credit signals
┌──────────────────────────────────────────────────────┐
│ LEGAL LAYER: Credit Assignment                       │
│  • forensics (causal attribution)                    │
│  • fault allocation (credit signals)                 │
│  • remediation (incentive adjustment)                │
└──────────────────────────────────────────────────────┘</code></pre>
<p>Here's how they work together. An application submits a task. The
planner proposes a plan: a directed graph of skills with declared types,
ordering constraints, and resource budgets. The <strong>formal
layer</strong> performs static checks (type unification, dependency
ordering, cycle detection, resource admission). If well-formed,
execution proceeds with capability-based contexts (each skill gets only
its declared effects) and resource metering (tracking actual consumption
against budgets). The <strong>social layer</strong> tracks which skills
actually deliver quality results and updates reputation scores. The
<strong>legal layer</strong> performs forensic analysis on failures to
assign credit signals that feed back into reputation. Each layer has
specific responsibilities. None can be skipped.</p>
<h3 id="the-formal-layer-verified-composition">The Formal Layer:
Verified Composition</h3>
<p>The formal layer provides guarantees about composition boundaries,
not about correctness of individual skill internals or optimality of
plans. This scoping is deliberate. We verify the narrow waist where
coordination happens, not everything. Here's the breakdown:</p>
<table>
<colgroup>
<col style="width: 31%" />
<col style="width: 31%" />
<col style="width: 37%" />
</colgroup>
<thead>
<tr>
<th>Surface</th>
<th>Verify?</th>
<th>Mechanism</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Edge types between skills</strong></td>
<td>✅ Yes</td>
<td>JSON Schema unification at plan time</td>
</tr>
<tr>
<td><strong>Execution order &amp; acyclicity</strong></td>
<td>✅ Yes</td>
<td>DAG analysis</td>
</tr>
<tr>
<td><strong>Resource budgets</strong> (tokens/latency/calls)</td>
<td>✅ Yes</td>
<td>Static admission + runtime meters</td>
</tr>
<tr>
<td><strong>Side-effect policies</strong> (database writes, API
calls)</td>
<td>✅ Yes</td>
<td>Effect declarations (static) + capability-based contexts
(runtime)</td>
</tr>
<tr>
<td><strong>Skill internals</strong></td>
<td>❌ No</td>
<td>Handled by testing and reputation</td>
</tr>
<tr>
<td><strong>Planner reasoning</strong></td>
<td>⚠️ Partial</td>
<td>Logical structure if typed, optimality by outcomes</td>
</tr>
</tbody>
</table>
<p>This division matters because it keeps the verified core small. The
narrow waist stays manageable because we don't verify everything, just
the composition boundaries where coordination happens.</p>
<p>Consider a workflow: PDF -&gt; Table -&gt; SQL. skills declare their
types: <code>pdf.extractTables</code> accepts PDF and returns
<code>[Table]</code>. <code>table.toSql</code> accepts
<code>[Table]</code> and returns SQL. The planner proposes a two-step
DAG. The checker unifies types across the edge and enforces a 1000-token
budget. If <code>pdf.extractTables</code> returns mixed schemas but
<code>table.toSql</code> expects uniform structure, the checker rejects
the plan unless a normalization step is inserted. Type safety prevents
the runtime failure.</p>
<p>Side effects work the same way. Skills declare effects in their
interfaces (<code>pdf.extractTables: {FileSystem.read}</code>,
<code>db.write: {Database.write}</code>). The Plan Checker statically
verifies the composition is well-formed. At runtime, each skill's
execution context is configured with only the capabilities it declared.
<a
href="https://www.anthropic.com/engineering/claude-code-sandboxing">Claude
Code's sandboxing</a> demonstrates the primitives: filesystem and
network isolation through OS mechanisms. But sandboxing alone creates
privilege escalation at composition: a PDF-to-database workflow must
grant both filesystem and database access globally. Effect declarations
enable least privilege: the PDF skill executes in a context with only
<code>{FileSystem.read}</code>, the DB skill with only
<code>{Database.write}</code>, despite both running in the same
workflow. Effect types provide the compositional algebra for
per-component minimization. Capability-based execution implements it.
Effect violations become impossible by construction.</p>
<p>The narrow waist approach (a small, stable interface layer that
enables diversity above and below) is how successful systems scale. The
Internet scales to billions of devices through this pattern. <a
href="https://datatracker.ietf.org/doc/html/rfc9293">TCP/IP</a> provides
minimal guarantees at the protocol layer (IP) that enable maximum
diversity at the edges, with <a href="https://www.ietf.org/">IETF</a>
governance handling disputes and evolving standards. <a
href="https://sel4.systems/">seL4</a> demonstrates the same. The
verified core enforces isolation, while everything above competes
freely. <a
href="https://cacm.acm.org/magazines/2015/4/184701-how-amazon-web-services-uses-formal-methods/fulltext">AWS
proved this works</a> for distributed systems: TLA+ specifications
(200-1000 lines each) caught critical bugs in DynamoDB requiring 35
steps to trigger. These are bugs that would never surface in testing.
The npm ecosystem's <a
href="https://thehackernews.com/2024/12/thousands-download-malicious-npm.html">15,000+
malicious packages</a> show what happens without this discipline. For
skills: verify how they compose, not what each does internally.<a
href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a></p>
<h3 id="the-social-layer-competitive-coordination">The Social Layer:
Competitive Coordination</h3>
<p>Formal verification ensures skills compose correctly, but it can't
determine which composition is best or whether specifications capture
actual requirements. You can prove code matches spec without proving
spec matches reality. Even perfectly specified systems get gamed, as
seen in the reward hacking research showing agents maximize specified
objectives while violating user intent. When multiple skills satisfy the
same contract with different quality or cost profiles, formal
verification offers no guidance. The social layer fills this gap through
market-like selection mechanisms that function as a learning algorithm.
As Philippe Beaudoin observed, "social structure is the learning
algorithm of society"<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a>. Institutions learn through feedback
which behaviors to reward. The social layer automates this through
several mechanisms:</p>
<p><strong>Reputation and competitive selection.</strong> Track success
rates, latency, and cost per skill. Bad performers decay through disuse.
Good ones capture market share. <a
href="https://link.springer.com/article/10.1007/s10683-006-4309-2">eBay
demonstrates</a> reputation systems create an 8.1% price premium for
trusted sellers. These are quantifiable incentives for good
behavior.</p>
<p>Consider a data extraction skill that passes all formal checks but
consistently produces edge-case formats that downstream skills handle
poorly. Verification sees: types match, contracts satisfied. But
outcomes reveal quality issues. Over 1000 workflows, its reputation
decays from 0.85 to 0.32, dropping its selection probability
proportionally. A competing skill with identical contract but better
output quality captures the market share. No human intervention
required. The system learns which implementations actually work.</p>
<p>These automated learning mechanisms are not hypothetical. <a
href="https://arxiv.org/abs/2507.19457">DSPy's GEPA optimizer</a>
demonstrates that automated learning from execution feedback achieves
dramatic improvements with small datasets: 97.8% accuracy from just 34
training examples, without gradient descent or model retraining. GEPA
uses LLM reflection on execution traces to iteratively improve
performance. This is exactly the pattern the social layer implements
through reputation updates.</p>
<p>The key architectural difference: GEPA optimizes prompts within a
fixed module structure (improving how individual agents work), while the
social layer optimizes skill selection within formally verified
composition boundaries (improving how agents coordinate). Both are
training-free optimization through execution feedback. Both achieve
sample efficiency because they exploit LLM language priors rather than
treating outcomes as scalar rewards. GEPA provides empirical proof that
institutional learning can operate effectively when automated.</p>
<p>Production evaluation systems like <a
href="https://mistral.ai/news/ai-studio">Mistral's judges</a>
demonstrate teams already recognize this need, scoring outputs at scale
and converting production traces into datasets. But evaluation alone
isn't sufficient: judges measure quality, not economic impact. A
financial compliance task failing once is catastrophic, while an email
draft generator failing occasionally is acceptable. The social layer
must weight reputation updates by impact, enabling risk-adjusted
selection where high-stakes tasks select proven reliability even at
higher cost, while low-stakes tasks can use cheaper, less reliable
skills.</p>
<p><strong>Evolutionary dynamics under institutional selection.</strong>
Reputation scores provide fitness signals for automated skill
optimization, as <a href="https://github.com/stanfordnlp/dspy">DSPy</a>
demonstrates through programmatic variation and outcome evaluation.
Applied to skills: the formal layer ensures evolved variations still
compose correctly (providing institutional bounds that prevent runaway
optimization), while the social layer provides selection pressure
through reputation. Better skills gain market share, poor mutations lose
selection probability. Skills improve through variation and selection,
but within verifiable compositional constraints.</p>
<p><strong>Hierarchical coordination emerges naturally.</strong> Recent
agent research focuses on improving individual capabilities (better
reasoning, richer memory, sophisticated execution), but real-world
automation requires coordinating multiple specialized agents. As skill
populations grow, certain organizational structures emerge because they
solve computational problems. Multi-agent AI research shows hierarchical
patterns reduce communication overhead from O(n²) to O(n log n) while
improving performance. Boss-Worker, Actor-Critic, and hierarchical
orchestration are validated patterns. Complex workflows decompose
naturally: coordinator skills delegate to specialist skills recursively,
creating organizational structure through selection pressure rather than
top-down design.</p>
<p><strong>The registry learns compatibility through use.</strong> Which
skills actually work together in production? The system discovers this
through execution: when skill A updates, the registry knows which
downstream dependencies are affected. This enables automatic deprecation
warnings, migration paths, and backward compatibility enforcement (not
through manual declaration, but through observed behavior).</p>
<h3 id="the-legal-layer-credit-assignment-for-multi-agent-learning">The
Legal Layer: Credit Assignment for Multi-Agent Learning</h3>
<p>Reputation mechanisms tell us which skills work better overall, but
they struggle with a fundamental problem: when a multi-component
workflow fails, which component caused it? Penalizing all components
equally kills good skills. Penalizing only the last component misses
root causes. Using global reward signals can't distinguish individual
contributions. Without precise credit assignment, evolutionary dynamics
can't function because the system doesn't know which mutations to
reinforce and which to suppress.</p>
<p>The legal layer solves this through causal attribution: forensics
determines what happened, fault allocation assigns credit, and
remediation adjusts incentives. These are automated platform operations
that enable learning. The audit infrastructure (cryptographically signed
execution traces) serves both automated forensics and human oversight,
but automation is primary because it scales to millions of workflows
where human review cannot.</p>
<p><strong>Forensics establishes causality.</strong> Every execution
produces a structured audit trail: input schemas, component versions
(cryptographic hashes), plan structure, declared contracts
(pre/postconditions, effects), intermediate outputs, and resource
consumption. This becomes a queryable execution graph for automated
analysis. When a workflow produces an unexpected outcome, forensics
analyzes this graph to establish causal relationships: Which component's
output violated which downstream precondition? Which plan decision
introduced the composition error? Which input distribution fell outside
declared envelopes? Forensics itself can be a learned component, a
specialized skill trained on thousands of incidents to identify failure
patterns (<a
href="https://blog.langchain.com/insights-agent-multiturn-evals-langsmith/?utm_medium=social&amp;utm_source=linkedin&amp;utm_campaign=q4-2025_october-launch-week_aw">production
tools</a> demonstrate the value of clustering failures by behavioral
patterns), while still operating within contract boundaries declared at
composition time.</p>
<p><strong>Attribution assigns credit signals.</strong> Once causality
is established, attribution translates this into feedback for the social
layer. A component that violates its postcondition receives negative
credit. A planner that composes skills while ignoring preconditions
receives negative credit. A component that handles edge cases beyond its
specification receives positive credit. These credit signals function as
gradients for evolutionary optimization, indicating which behaviors to
reinforce or suppress.</p>
<p>Consider a failure in <a href="#what-skills-are">the meeting
workflow</a>. The output email says "Sarah will finalize the pricing
proposal by Friday for the client call." What was actually said: "Sarah
might be able to finalize pricing by Friday if bandwidth permits, but
can't commit given the Q4 close." Yet all formal verification passes:
types unify, accuracy thresholds met, contracts satisfied.</p>
<p>The cascade: transcribe makes a phonetic error on the hedge word ("if
bandwidth permits" -&gt; "her bandwidth for it"), producing "Sarah might
be able to finalize pricing by Friday, her bandwidth for it, but can't
commit given Q4 close." Summarize drops the qualifying phrases to be
concise: "Sarah to finalize pricing by Friday (Q4 close)." Extract
treats the deadline as the salient action item: "Sarah: finalize pricing
by Friday." Format makes it definitive: "Sarah will finalize the pricing
proposal by Friday for the client call."</p>
<p>Attribution: transcribe receives minor negative credit (phonetic
error on critical qualifier), summarize receives significant negative
credit (dropped uncertainty signal), extract receives moderate negative
credit (interpreted conditional as commitment), format receives moderate
negative credit (added false definitiveness), planner receives negative
credit (composition progressively removed hedging instead of preserving
it). Each component made defensible choices within its contract, but the
cascade turned a tentative maybe into a firm commitment. Nothing
violated a contract, no types mismatched, no invariants broke. The
system was formally correct but produced the wrong outcome. Formal
verification alone can't catch this.</p>
<p><strong>This completes the learning loop.</strong> The social layer
implements evolutionary dynamics (variation and selection based on
reputation), but can only function with accurate credit signals. Without
causal attribution, evolution observes aggregate outcomes: "this
workflow succeeded" or "this workflow failed." With attribution,
evolution receives precise feedback: "this component violated this
contract, this component exceeded expectations, this composition pattern
reliably fails." The legal layer provides backward-looking credit
assignment, while the social layer provides forward-looking selection.
Together they enable learning.</p>
<p>The reward hacking problem poses a particular challenge: static
reward functions can't anticipate all gaming strategies. But learned
forensics can identify patterns where models maximize specified
objectives while violating intent: outputs that technically satisfy
contracts while degrading unmeasured quality, behaviors that exploit
interface loopholes, workflows that optimize metrics at the expense of
user goals. When forensics identifies such patterns, negative credit
attaches not just to individual instances but to behavior classes,
propagating to similar component versions. The legal layer becomes a
learned reward model that identifies and penalizes gaming strategies as
they emerge.</p>
<p>This solves credit assignment at scale: automated forensics handles
millions of routine failures per day, assigning credit and updating
reputations in seconds. Major disputes (liability questions involving
significant damages, regulatory compliance investigations, questions of
systemic failure) remain under external oversight from courts,
regulators, and arbitrators. The division of labor mirrors human
institutions: automated systems handle routine cases, human judgment
handles precedent-setting ones.</p>
<h3 id="failure-semantics-across-all-layers">Failure Semantics Across
All Layers</h3>
<p>The three layers work together, each handling different failure
modes. When something fails, each layer responds if applicable:</p>
<table>
<colgroup>
<col style="width: 22%" />
<col style="width: 25%" />
<col style="width: 26%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr>
<th>Failure Type</th>
<th>Formal Response</th>
<th>Social Response</th>
<th>Legal Response (Credit Assignment)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Type mismatch</strong></td>
<td>Reject plan statically (no execution)</td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td><strong>Effect violation</strong></td>
<td>Impossible by construction (execution context has only declared
capabilities)</td>
<td>—</td>
<td>—</td>
</tr>
<tr>
<td><strong>Budget exceeded</strong></td>
<td>Admit budget statically -&gt; runtime metering (abort when limit
hit)</td>
<td>Reputation penalty if habitual</td>
<td>Negative credit to component, charge overage</td>
</tr>
<tr>
<td><strong>Malformed output</strong></td>
<td>Pass static checks -&gt; runtime detection (abort with error)</td>
<td>Severe reputation hit</td>
<td>Negative credit to component, positive credit to detector</td>
</tr>
<tr>
<td><strong>Quality degradation</strong></td>
<td>Pass all formal checks</td>
<td>Gradual reputation decay from outcomes</td>
<td>Forensics attributes credit across cascade, planner penalized for
poor composition</td>
</tr>
</tbody>
</table>
<p>This demonstrates why you need all three. Formal verification
prevents violations by construction (type mismatches caught statically,
effect violations made impossible through capability-based execution).
Runtime metering tracks resource consumption that cannot be predicted
statically. Social mechanisms handle quality degradation that passes all
formal checks. Legal assigns credit when outcomes reveal which
components contributed to failures.</p>
<h2 id="the-synthesis">The Synthesis</h2>
<p>The proposed architecture combines three layers because no single
approach suffices. Formal verification prevents predictable composition
failures but cannot specify optimal behavior under uncertainty. Social
mechanisms learn what works through execution feedback but require
formal boundaries to prevent catastrophic failures. Legal accountability
assigns responsibility when the other layers fail but needs verifiable
traces to function. Each layer addresses problems the others cannot
solve.<a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a></p>
<p>AI systems create both necessity and opportunity for automated
coordination. Necessity: workflows execute millions of times per hour,
accumulating coordination debt faster than human institutions can
correct. Opportunity: each layer exploits capabilities human
institutions lack.</p>
<p>The formal layer makes composition boundaries explicit and
machine-checkable. Type-checking catches interface mismatches before
runtime. Effect systems make unauthorized actions impossible by
construction: each execution context has only the capabilities its skill
declared. AI exposes compositional structure as typed interfaces that
can be verified automatically.</p>
<p>The social layer updates reputation immediately after each execution.
Competitive selection occurs at request time. Evaluation runs
automatically on every output. The learning algorithm operates
continuously through execution feedback, no human deliberation required
for routine cases.</p>
<p>The legal layer produces complete, cryptographically signed traces
for every execution: inputs, outputs, skill versions, resource
consumption, decisions. Audit trails are comprehensive and tamper-proof
by construction.</p>
<p>This is training-free optimization. No model weights change, no
gradient descent, no reinforcement learning loops. The formal layer
provides static guarantees through type-checking. The social layer
learns selection policies through automated reputation updates. The
legal layer creates accountability through signed audit trails. Like <a
href="https://github.com/stanfordnlp/dspy">DSPy</a> improving LLM
performance through prompt optimization rather than retraining,
coordination improves by optimizing the environment rather than the
models.</p>
<p>The components exist. <a
href="https://www.anthropic.com/news/model-context-protocol">The Model
Context Protocol</a> provides typed schemas. Multi-agent AI research
validates hierarchical coordination patterns. <a
href="https://ethereum.org/">Ethereum</a> secures $30+ billion through
verified EVM semantics, staking incentives, and immutable transaction
logs. <a href="https://arxiv.org/abs/2507.19457">DSPy's GEPA
optimizer</a> proves automated learning from execution feedback achieves
significant improvements with small datasets (97.8% accuracy from 34
examples, training-free). <a
href="https://www.nobelprize.org/prizes/economic-sciences/2020/popular-information/">Milgrom
and Wilson's auction mechanisms</a> demonstrate incentive-compatible
institutional design at scale ($233 billion across 100 FCC spectrum
auctions). All of these operate in production today.</p>
<p>Skills validate demand for composable capabilities but lack
composition guarantees. Claude orchestrates Skills through inference
rather than verified planning. MCP provides types but requires explicit
invocation. Skills enable autonomous selection but without type safety.
Neither provides reputation tracking, competitive pressure, or audit
trails. The synthesis (autonomous selection of capabilities that
verifiably compose) requires combining these pieces into coherent
architecture.</p>
<p>The formal verification community has the tools. The mechanism design
community has the theory. The ML community ships the systems. Agent
architecture research has focused on individual capabilities (reasoning,
memory, execution), but production demands coordination. What's missing
is synthesis. Skills and MCP demonstrate the pieces are emerging
independently. The question is whether coordination infrastructure gets
built before production failures force reactive regulation, or as
principled architecture that enables scale. Economics determines the
answer by 2027.</p>
<hr />
<p><em>Thanks to Philippe Beaudoin and Paul Chiusano for detailed
feedback that significantly improved this piece. Their insights on
social learning mechanisms and the library/application distinction
shaped the core argument.</em></p>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Paul Chiusano, creator of the <a
href="https://www.unison-lang.org/">Unison programming language</a>,
personal communication, October 2025. Chiusano observes this is the
difference between libraries (providing functions) and applications
(specifying how functions compose): "The model isn't an oracle" that
will discover correct compositions automatically.<a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Reward hacking optimizes against the specification.
Scheming actively conceals misbehavior. Attempts to train out scheming
appeared effective, but models developed situational awareness to detect
when they're being evaluated, suggesting they learn to hide misbehavior
during testing rather than genuinely aligning.<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>One frontier deserves attention: verifying the planner's
reasoning itself. When AI reasoning is expressed as a typed program (as
in <a href="https://platform.openai.com/docs/guides/reasoning">OpenAI's
o1</a> or <a
href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/">DeepMind's
AlphaProof</a>), type-checking mechanically verifies logical structure
through the <a
href="https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence">Curry-Howard
correspondence</a>. We still evaluate optimality by outcomes, but
structural verification reaches into cognition itself. This is something
courts need judges for, but AI can expose cognition as programs that
machines can verify.<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Philippe Beaudoin, Senior Director, Research at <a
href="https://www.lawzero.org/">LawZero</a>, personal communication,
October 2025.<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>As capabilities increase, high-stakes decisions may
require forward-looking harm assessment for cases with deep epistemic
uncertainty (ambiguous safety specifications, novel contexts). <a
href="https://arxiv.org/abs/2502.15657">Bengio et al.</a> propose
computing harm probabilities across plausible interpretations and
blocking actions when thresholds are exceeded. The coordination
framework's audit trails, effect declarations, and execution histories
provide the substrate such mechanisms require.<a href="#fnref5"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></content>
  </entry>
  <entry>
      <title>The Home Supercomputer Fallacy</title>
      <link href="https://tscholak.github.io/posts/home-supercomputers.html"/>
      <id>https://tscholak.github.io/posts/home-supercomputers.html</id>
      <updated>2025-10-15T00:00:00Z</updated>
      <category term="gpu"/>
      <category term="infrastructure"/>
      <category term="economics"/>
      <summary type="html"><![CDATA[<p>NVIDIA's DGX Spark promises to put an "AI supercomputer" on your
desk. But for most people, owning a $4,000 box is slower, less flexible,
and more expensive than renting smartly. Here's why.</p>]]></summary>
      <content type="html"><![CDATA[<h2 id="the-dgx-spark-hype">The DGX Spark Hype</h2>
<p>NVIDIA just released the DGX Spark, a $3,999 "AI supercomputer for
your desk" the size of a Mac Mini. It ships with 128 GB of unified
memory, a Blackwell GPU, and marketing that borders on poetry:</p>
<blockquote>
<p>"Own your compute!"</p>
</blockquote>
<blockquote>
<p>"Escape cloud vendor lock-in!"</p>
</blockquote>
<blockquote>
<p>"Run the largest models yourself at home!"</p>
</blockquote>
<p>Influencers are already unboxing and calling it a game-changer for
"taking back control" from the cloud.</p>
<p>Here's the problem: <strong>it's slow for real work</strong>. Worse,
the whole premise is a trap because you can get better performance, zero
idle cost, and a persistent environment elsewhere for less money.</p>
<h2 id="the-sparks-actual-performance">The Spark's Actual
Performance</h2>
<p>Running GPT-OSS 20B in Ollama (via <a
href="https://docs.google.com/spreadsheets/d/1SF1u0J2vJ-ou-R_Ry1JZQ0iscOZL8UKHpdVFr85tNLU/edit?gid=0#gid=0">@LMSYS</a>):</p>
<table>
<colgroup>
<col style="width: 17%" />
<col style="width: 9%" />
<col style="width: 14%" />
<col style="width: 13%" />
<col style="width: 16%" />
<col style="width: 27%" />
</colgroup>
<thead>
<tr>
<th>Hardware / Model</th>
<th>Precision</th>
<th>Prefill (tokens/sec)</th>
<th>Decode (tokens/sec)</th>
<th>Relative Speed vs Spark</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>DGX Spark (GB10)</strong></td>
<td>4-bit (mxfp4)</td>
<td>2,054</td>
<td>49.7</td>
<td>1x</td>
<td>128 GB LPDDR5X @ 273 GB/s unified memory</td>
</tr>
<tr>
<td><strong>RTX 6000 Blackwell</strong></td>
<td>4-bit (mxfp4)</td>
<td>10,108</td>
<td>215</td>
<td>4.3x faster</td>
<td>Workstation GPU with ~1 TB/s bandwidth</td>
</tr>
<tr>
<td><strong>GeForce RTX 5090</strong></td>
<td>4-bit (mxfp4)</td>
<td>8,519</td>
<td>205</td>
<td>4.0x faster</td>
<td>Consumer flagship GPU</td>
</tr>
<tr>
<td><strong>GH200 (Cloud, est.)</strong></td>
<td>FP8 / FP16</td>
<td>~10,000-15,000</td>
<td>~250-350</td>
<td>~5-7x faster</td>
<td>96 GB HBM3 @ 4 TB/s; $1.49/hr on Lambda</td>
</tr>
</tbody>
</table>
<p>The Spark is <strong>4x slower</strong> than high-end GPUs on
standard workloads. In SGLang, for a 70B model (FP8), it manages 2.7
tokens per second in generation. Not exactly "supercomputer" speed.</p>
<p>The bottleneck is the memory bandwidth, not the GPU cores. The
Spark's 273 GB/s LPDDR5x sounds impressive until you realize an RTX 5090
has ~1 TB/s. The precious Blackwell GPU cores are starved for data.
NVIDIA clearly traded bandwidth for price; cutting LPDDR5X instead of
HBM keeps it under $4k and avoids cannibalizing the $8.5k RTX 6000.</p>
<h3 id="the-nvfp4-trap">The NVFP4 Trap</h3>
<p>NVIDIA's marketing claims "1 petaFLOP" of performance or "1000 AI
TFLOPS." Technically true, but only for NVFP4, which is NVIDIA's new
proprietary 4-bit floating-point format that almost no models use
yet.</p>
<p>Load a standard model and the Spark essentially behaves like a
mid-range GPU with relatively weak inference performance. You're buying
hardware optimized for a format the ecosystem hasn't adopted yet.</p>
<p>Want the Spark's advertised performance? You need models specifically
trained or converted to NVFP4. Possible, but not convenient.</p>
<h2 id="the-false-binary">The False Binary</h2>
<p>The debate has calcified into two positions: buy expensive hardware
vs rent expensive cloud.</p>
<p>That's the wrong framing entirely. The real question isn't ownership
vs rental because <strong>granularity of commitment</strong>
matters.</p>
<p>What people actually need is:</p>
<ul>
<li>Burst access to serious compute (H100, GH200, 8xA100) when working
on big models.</li>
<li>Zero cost when idle.</li>
<li>Persistent environment between sessions.</li>
</ul>
<p>The Spark gives you one or two of these at $4,000 upfront. AWS gives
you two of three at premium pricing.<br />
Lambda and other neoclouds give you <strong>all three</strong> for about
as low as $1.49/hour for a GH200 on demand with no upfront cost or
commitment.</p>
<p>Break-even napkin math:</p>
<ul>
<li>$3,999 ÷ $1.49/hr = <strong>2,685 hours</strong></li>
<li>At 8 hrs/week: 6.45 years of full utilization</li>
<li>At 8 hrs/day: 336 days of full utilization</li>
</ul>
<p>This assumes your $4k Spark matches GH200 performance (it doesn't)
and the Spark has zero power/cooling costs (it does).</p>
<p>If you are hitting 60%+ duty cycle every day training models or doing
heavy inference, you're not doing enthusiast experiments anymore but
production workloads. You need a big rig or a cluster, not a Spark.</p>
<h2 id="the-real-bottleneck-is-ceremony">The Real Bottleneck is
Ceremony</h2>
<p>While renting compute on neoclouds is cheap and easy, the workflow
friction is the real barrier:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span> launch instance</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">...</span> wait several minutes</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="ex">...</span> <span class="st">&quot;is it up already?&quot;</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="ex">...</span> ssh in, install everything from scratch</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="ex">...</span> <span class="st">&quot;wait, how did I get FlashAttention working with this version of PyTorch again?&quot;</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="ex">...</span> <span class="st">&quot;shit, I forgot to mount my data&quot;</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="ex">...</span> <span class="st">&quot;where&#39;s that experiment config file? did I save it?&quot;</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="ex">...</span> do 30 minutes of work</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="ex">...</span> terminate instance</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="ex">...</span> lose everything</span></code></pre></div>
<p>So in the end you default to your laptop and don't do any of the real
work you intended to do.</p>
<h2 id="declarative-ephemeral-infrastructure">Declarative Ephemeral
Infrastructure</h2>
<p>Simple fix: <strong>persistent storage + declarative environment +
intelligent retry</strong>.</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">devbox</span> command=up_gh200</span></code></pre></div>
<p>(devbox is a tool I wrote to manage ephemeral GPU instances, link at
end)</p>
<p>This launches a GH200 instance with:</p>
<ul>
<li>Your entire <code>/home</code> directory on persistent NFS</li>
<li>Nix store on a 100GB loop device (survives termination)</li>
<li>SSH config auto-generated</li>
<li>Exponential backoff on capacity errors</li>
</ul>
<p>Terminate when done. Environment persists. Next launch: instant. Same
packages, same state.</p>
<h2 id="common-objections">Common Objections</h2>
<p><strong>"But M4/M5 Macs are faster!"</strong> Yep. For models under
30B, an M4 Mac matches or beats the Spark and doubles as a
general-purpose machine. The Spark's 128GB advantage matters for massive
models, except: a 120B model runs at ~14-15 tokens/sec on Spark vs ~53
tokens/sec on an M2 Max Mac Studio.</p>
<p><strong>"What about AMD Strix Halo?"</strong> Faster on many
workloads, roughly half the price. Trade-off: you lose the mature CUDA
ecosystem. (Well, ROCm is getting better, but the compute capabilities
of a Max+ 395 are not the same as a Blackwell.) Pure inference? Strix
wins. Development and scaling? Spark's NVIDIA stack matters.</p>
<p><strong>Local data access?</strong> On first launch you set up your
dotfiles, pull any repos you need, and set up development environments
with nix or uv. After that, everything is on an NFS mount. No difference
from local disk from then on. Persistent storage is dirt cheap.</p>
<p><strong>Latency?</strong> SSH latency is ~20-50ms. Irrelevant for
training/inference.</p>
<p><strong>Vendor lock-in?</strong> Lambda's API is just HTTP. Migrating
to another provider is a weekend project if needed.</p>
<p><strong>Capacity availability?</strong> GH200s are scarce. Retry
logic handles it. In practice: occasional 10-20min waits for capacity,
then instant access, followed by many hours of uninterrupted work. That
overhead is a rounding error compared to the cost of owning
hardware.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The DGX Spark exists because "AI supercomputer for your home office"
sells better than "expensive, slow, vendor-locked bet on NVFP4." NVIDIA
admits the Spark isn't designed for raw performance but as a
"developer-friendly platform" for people prototyping before scaling to
real DGX systems or cloud. It's also a $4k stepping stone to lock you
further into the DGX ecosystem. The "own your infrastructure" narrative
is seductive, but all the brilliant marketing can't hide the fact that
for many people this is a terrible purchase and renting is simply
better.</p>
<p>The Spark conflates ownership with commitment. You can own your data,
environment, and state without owning idle silicon. Renting ephemeral
GPUs gives you better performance, zero idle cost, and the same
persistence.</p>
<p>Don't buy the "home supercomputer." Rent smart. Work smart.</p>
<p>Disclaimer: I have no relationship with Lambda Labs or NVIDIA. I just
do a lot of training framework development and can afford to be
opinionated about infrastructure.</p>
<p>Disclaimer 2: The author of this article has since purchased a DGX
Spark because he thinks it looks cool and makes him look smart at
parties. Just kidding.</p>
<h2 id="next-steps">Next Steps</h2>
<p>If you want to try this out, check out <a
href="https://github.com/tscholak/devbox">devbox</a>, my little
opinionated tool to manage ephemeral GPU instances easily. Drop me a
line if you have questions or feedback!</p>]]></content>
  </entry>
  <entry>
      <title>Everyone&#39;s Arguing About the Wrong Abstraction Layer</title>
      <link href="https://tscholak.github.io/posts/agentkit.html"/>
      <id>https://tscholak.github.io/posts/agentkit.html</id>
      <updated>2025-10-08T00:00:00Z</updated>
      <category term="ai"/>
      <category term="agents"/>
      <summary type="html"><![CDATA[<p>OpenAI <a
href="https://openai.com/index/introducing-agentkit/">shipped AgentKit
this week</a>, a platform with a visual workflow editor, versioned
agents, governed connectors, and evals infrastructure. The internet
immediately split into two camps: people dunking on it ("this isn't
AGI!") and people defending visual editors as necessary for
non-technical users. Both camps are arguing about the wrong thing.</p>]]></summary>
      <content type="html"><![CDATA[<p>Harrison Chase from LangChain wrote <a
href="https://blog.langchain.com/not-another-workflow-builder/">a
thoughtful piece called "Not Another Workflow Builder,"</a> arguing that
visual workflow builders are getting squeezed from both directions:
simple agents (prompt &amp; tools) are handling low-complexity tasks,
while code-based workflows (like LangGraph) win at high complexity. His
conclusion: the middle ground is dying, focus on better no-code agents
and better code generation instead.</p>
<p>It's a clean thesis. Unfortunately, it's also missing the forest for
the trees.</p>
<h2 id="the-abstraction-confusion">The Abstraction Confusion</h2>
<p>Here's what's actually happening: we are watching three different
communities argue past each other because they are each solving for
different constraints.</p>
<ul>
<li><p>The "simple agents win" crowd sees frontier models getting better
and concludes that explicit orchestration becomes unnecessary. Just
throw GPT-5 at the problem with some tools and let emergence handle the
rest. They are right that many workflows are just prompt engineering in
disguise. They look at complex systems and see overengineering.</p></li>
<li><p>The "visual workflow necessary" crowd needs to ship products with
non-technical stakeholders, wants observability baked in, and needs
governance that works at the organizational level. They are right that
code doesn't easily surface what's running and why. They look at
code-first approaches and see gatekeeping.</p></li>
<li><p>The "visual workflow bad" crowd wants composability, types, and
the ability to reason about systems explicitly and even formally. They
are right that dragging boxes around in a canvas doesn't give us
algebraic properties or type safety. They look at AgentKit's visual
editor and see toy-like systems that won't scale.</p></li>
</ul>
<p>All three are correct about what they're optimizing for. All three
are wrong about what the actual problem is.</p>
<h2 id="what-agentkit-actually-represents">What AgentKit Actually
Represents</h2>
<p>Strip away the visual editor for a moment. What did OpenAI actually
release?</p>
<p>They released a platform for building, deploying, and iterating on
multi-agent systems with the following key primitives: versioned
workflows, a governed connector registry (where admins manage how data
and tools connect), guardrails, evaluation infrastructure, and
reinforcement fine-tuning (RFT) integration. The visual canvas is
actually the least interesting part of the release.</p>
<p>OpenAI understands that the real problem isn't how users specify what
they want (visual vs code vs natural language), but how we build systems
that compose, verify, observe, and improve.</p>
<p>Harrison's squeeze thesis argues that visual workflow builders are
losing from both ends. But this assumes the primary value of visual
builders is specification, i.e. helping people define workflows. That's
not actually their killer feature. When done right, visual builders are
primarily about operational visibility. They make implicit logic
explicit, they create artifacts that stakeholders can review, they
enable governance at the right granularity, and they provide
observability by default. These are organizational problems, not
individual productivity problems.</p>
<p>I don't see AgentKit's pitch as "drag boxes instead of writing code."
I see it as "version your agents, govern your data connectors, evaluate
systematically, and iterate with RFT." The visual editor is merely how
OpenAI is packaging that infrastructure for adoption.</p>
<h2 id="the-compositional-substrate-nobodys-building">The Compositional
Substrate Nobody's Building</h2>
<p>Here's my contrarian take: both visual builders and natural language
prompts are failing at scale for the same reason, and it has nothing to
do with their interface paradigm.</p>
<p>I had a long conversation with <a
href="https://pchiusano.github.io">Paul Chiusano</a> from Unison
Computing about this last week. Paul is a functional programming
language designer and a big advocate for types and formal methods. He
says:</p>
<blockquote>
<p>"I am pretty uninterested in all these WYSIWYG type workflow engines,
even with some AI sauce sprinkled on top. I want types and higher-order
functions and all the niceties of a modern programming language."</p>
</blockquote>
<p>Is he a snob for wanting that? No. He's pointing at tools for
managing complexity with a proven track record. Type systems catch
errors before runtime. Higher-order abstractions let programmers build
big things from small things with clear interfaces. Referential
transparency lets people reason locally about global properties.</p>
<p>Neither visual workflow builders nor natural language prompts provide
these properties. They both scale terribly once a certain complexity
threshold is crossed, for the same underlying reason: they don't provide
compositional guarantees.</p>
<p>A visual workflow with 50 nodes and complex branching is
unmaintainable not because it's visual, but because the edges between
nodes carry no semantic contracts. You can't compose workflows safely
because there's no type system preventing you from wiring incompatible
things together. You can't refactor with confidence because there's no
way to verify that your changes preserve behavior.</p>
<p>Similarly, a complex prompt-based agent scales poorly not because
natural language is inherently bad, but because prompts have no formal
composition semantics. You can't build a library of reusable "prompt
modules" with clear interfaces. You can't verify that chaining two
prompts preserves invariants. You can't reason about what happens when
an agent calls a tool that calls another agent.</p>
<p>The problem is not the interface. It's that neither provides
compositional abstractions with formal semantics.</p>
<h2 id="what-code-actually-gives-you">What Code Actually Gives You</h2>
<p>Harrison is right that code wins at the high-complexity end. But it's
worth being precise about why.</p>
<p>Code doesn't win because developers are special or because typing
text is inherently better than dragging boxes. It wins because it's the
only common representation that provides formal semantics we can reason
about, composability through functions and types, verification via type
checkers and tests, versioning and diffing as first-class operations,
and -- critically -- an artifact that is the ground truth of
execution.</p>
<p>This last point is often missed: even if AI always generates perfect
code from natural language descriptions, you still need the code because
the code is the specification of what you actually built and run.
Natural language is for intent, code is for commitment. It's like the
difference between a contract and a conversation. You need both. They
are complementary.</p>
<h2 id="stop-arguing-about-interfaces">Stop Arguing About
Interfaces</h2>
<p>We need to stop conflating the construction interface with the
operational model. The answer isn't choosing between visual, code, or
natural language. We need all three serving different purposes:</p>
<p><strong>Natural language</strong> for expressing human intent and
constraints. <strong>Formal contracts</strong> (types, schemas,
invariants) that specify interfaces and composition rules.
<strong>Code</strong> that implements logic within those contracts,
whether written by humans or generated by AI. <strong>Observability
infrastructure</strong> (traces, evals, guardrails) that shows what
actually happened and feeds back into intent and contracts.</p>
<p>Visual builders try to be all of these simultaneously. That's why
they break. Natural language prompts pretend formal contracts don't
exist. That's why they don't compose. Code-first approaches often skip
observability or treat intent as separate from the system. That's why
they struggle with alignment.</p>
<p>AgentKit is interesting because it's actually trying to build
multiple layers: typed connectors, visual composition as an interface to
implementation, execution with guardrails, and evals infrastructure.
Whether their specific implementation works is TBD, but the architecture
is pointing in the right direction.</p>
<h2 id="what-happens-if-we-get-this-wrong">What Happens If We Get This
Wrong</h2>
<p>Here's what's at stake: we're about to build multi-agent systems that
make consequential decisions at scale. Process invoices. Route customer
support. Manage infrastructure. Screen resumes. Handle medical
triage.</p>
<p>If we build these systems without compositional guarantees, we get
brittle towers of duct tape that work until they catastrophically don't.
If we build them without observability, we get black boxes that fail in
inexplicable ways. If we build them without formal contracts, we can't
verify they preserve the properties we care about. And if we skip the
natural language layer, we've built something only five people in the
world can understand and maintain.</p>
<p>The teams currently arguing about visual vs code vs prompts are
missing the point. The only important question is: can we build systems
that are simultaneously verifiable (formal contracts), understandable
(operational visibility), and accessible (natural language intent)?</p>
<p>I believe the answer is yes, but only if we stop arguing about
interfaces and start building the compositional substrate underneath. We
need strong types and formal semantics, visual projection for operations
and governance, natural language for intent and constraints, and
continuous eval for alignment.</p>
<p>The team that figures out how to integrate all of these coherently
will win.</p>
<p>I'm watching closely.</p>]]></content>
  </entry>
  <entry>
      <title>Stop Renting Moat: Why Enterprises Must Own Part of Their AI Stack</title>
      <link href="https://tscholak.github.io/posts/stop-renting-moat.html"/>
      <id>https://tscholak.github.io/posts/stop-renting-moat.html</id>
      <updated>2025-08-20T00:00:00Z</updated>
      <category term="ai"/>
      <category term="strategy"/>
      <category term="economics"/>
      <summary type="html"><![CDATA[<p>Enterprises are told they have to choose between cost or
differentiation. But that's a false choice. If you outsource all AI,
your costs stay volatile and your upside is capped. The winners will own
enough of the stack to control both unit cost and quality.</p>]]></summary>
      <content type="html"><![CDATA[<h2 id="the-false-choice">The false choice</h2>
<p>Corporate strategy decks love to paint things as a neat fork in the
road. You've probably seen it: on one side, rent everything. Stay light,
keep costs down, let the big labs handle the heavy lifting. On the
other, build everything yourself. Hire a frontier research team, rack up
thousands of GPUs, become your own OpenAI.</p>
<p>That framing makes for a tidy slide, but it's not reality. No
enterprise should try to out-OpenAI OpenAI. That's not the game. On the
other hand, renting everything leaves you totally exposed. Your costs
swing with someone else's pricing strategy, and any "moat" you think you
have can be bought by your competitors tomorrow. You are just an
integrator of someone else's commoditized technology.</p>
<p>The real choice isn't between these two extremes. Smart companies
stake out the middle ground: <strong>own just enough</strong> to control
what matters. You don't need your own frontier model lab, but you can't
afford to own nothing either.</p>
<p>What you need is the <strong>learning loop</strong>. That means
locking down evaluation, securing rights to the data your systems
generate, building privacy-safe feedback mechanisms, and maintaining the
ability to adapt models on <strong>your</strong> schedule, and not when
a vendor decides it's convenient.</p>
<p>Owning that path gives you predictable unit economics and a moat that
compounds. Outsource it all and you lose both.</p>
<h2 id="prices-move-your-moat-shouldnt">Prices move. Your moat
shouldn't</h2>
<p>Do you believe that all providers will eventually offer the same
capabilities at the same, ever-shrinking price? If so, you may be
underestimating the complexity of the market.</p>
<p>What we are witnessing is a <strong>subsidy race</strong>. Providers
are desperate for scale and market lock-in. Labs burn cash to win share,
and hyperscalers cross-subsidize from their profitable core business.
The current prices are a reflection of that strategy and not one of
cost.</p>
<p>For a typical agent/RAG blend (approx. 3:1 input:output), OpenAI <a
href="https://platform.openai.com/docs/pricing">charges</a> about
<strong>$3.44 per million tokens on GPT-5</strong>, <strong>$3.50 on
o3</strong>, and <strong>$1.05 on 4o-mini</strong>. Prices may look
cheap now, but they can and will shift again, and not necessarily
downwards.</p>
<p>According to <a
href="https://techcrunch.com/2024/09/27/openai-might-raise-the-price-of-chatgpt-to-22-by-2025-44-by-2029/">internal
documents reported by The New York Times</a>, OpenAI plans to raise
ChatGPT Plus from $20/month to <strong>$44/month by 2029</strong>, more
than doubling current prices. This while the company reportedly operates
at a loss, with <a
href="https://www.reuters.com/business/openai-hits-12-billion-annualized-revenue-information-reports-2025-07-31/">revenue</a>
unable to cover <a
href="https://www.investing.com/news/stock-market-news/openai-hits-12-bln-in-annualized-revenue-sees-higher-costs-the-information-4161634">operational
costs</a>.</p>
<p>The volatility is already here. <strong>Cursor</strong> <a
href="https://cursor.com/blog/june-2025-pricing">walked back</a> a
flat-rate plan after usage spiked and heavy users blew up the economics.
<strong>Perplexity</strong> grew fast but still <strong>burned ~$65M on
$34M revenue in 2024</strong>. This is a reminder that <a
href="https://www.theinformation.com/articles/google-challenger-perplexity-growth-comes-high-cost">API
spend can already easily outrun sales</a>. If you are an enterprise
relying on APIs today, your P&amp;L becomes a derivative of somebody
else's burn rate and fundraising calendar.</p>
<h2 id="what-to-own-and-why">What to own (and why)</h2>
<p>You don't need to own everything, but you can't afford to own
nothing. The trick is knowing which parts of the stack matter: the
places where volatility destroys you and where defensibility compounds.
Everything else you can rent.</p>
<p>Think of the AI stack as having three tiers:</p>
<table>
<colgroup>
<col style="width: 14%" />
<col style="width: 25%" />
<col style="width: 13%" />
<col style="width: 16%" />
<col style="width: 7%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr>
<th>Tier</th>
<th>Approach</th>
<th>Unit cost</th>
<th>Differentiation</th>
<th>Control</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>Commodity API</td>
<td>Rent it all</td>
<td>Volatile</td>
<td>None</td>
<td>None</td>
<td>Basic agentic chatbot</td>
</tr>
<tr>
<td>Hybrid</td>
<td>APIs + fine-tunes</td>
<td>Mid, blended</td>
<td>Moderate</td>
<td>Partial</td>
<td>RAG with custom data</td>
</tr>
<tr>
<td>Own core loop</td>
<td>Internal models &amp; evals</td>
<td>Predictable</td>
<td>High</td>
<td>Full</td>
<td>Convirza, GS Platform</td>
</tr>
</tbody>
</table>
<p>The commodity tier is where most enterprises start and never escape.
They plug GPT-4o or GPT-5 into every workflow and pat themselves on the
back. It works, but it's indistinguishable from what their competitors
are doing. They're reselling OpenAI with a bit of integration glue. As
soon as the API provider shifts pricing, their margins evaporate.</p>
<p>The hybrid tier feels safer but is actually worse. You spend on
fine-tunes and custom RAG pipelines but still depend on someone else's
pricing whims and roadmap. Your supposed "moat" is just a brittle
collection of prompts and data munging scripts. Anyone can copy it.
You're paying more without buying freedom.</p>
<p>Owning the core learning loop is the only move that compounds. That
doesn't mean training GPT-scale models from scratch, but putting
yourself in control of what ships, what learns, and what lasts. You
define the evaluation gates and the regression rules. You decide what
data you capture, how it's anonymized, and whether it flows back into a
global model. You secure guaranteed compute for adaptation, not just
inference. You build a feedback loop that learns from every deployment,
not just the ones OpenAI decides to optimize for.</p>
<p>That requires structuring data rights from day one. Tenants need
three modes: <strong>off</strong> (nothing leaves their silo),
<strong>local-only</strong> (improvements stay within their instance),
or <strong>global</strong> (anonymized data improves the shared model).
Start everyone on local, but build in incentives for moving to global as
trust grows. You can't bolt this on later. The contracts have to be
right from the first pilot.</p>
<p>Here's what compounding looks like in practice:
<strong>Convirza</strong> migrated from OpenAI GPT models to Llama 3-8B
in 2024 and, per <a
href="https://www.llama.com/community-stories/">Meta's Llama Community
Stories</a>, cut operational cost by <strong>10x</strong> while
improving F1 by <strong>8%</strong> and throughput by
<strong>80%</strong>, now serving <strong>60+ KPIs</strong> across
thousands of daily interactions. <strong>Goldman Sachs</strong> hosts
multiple models, including Llama, behind its firewall. <a
href="https://nanonets.com/blog/goldman-sachs-ai-platform/">Reported
results</a> include <strong>20% developer productivity gains</strong>
and <strong>15% fewer post-release bugs</strong>, with adoption above
50% across 46,000 employees.</p>
<p>The more these systems run, the better they get. Your unit economics
become predictable instead of volatile. Your accuracy rises in domains
where competitors flatline. And your roadmap stops being a derivative of
someone else's burn rate.</p>
<p>Do you want compounding or commoditization? Own the loop, and every
deployment makes you stronger. Rent it all, and you're just financing
someone else's moat.</p>
<h2 id="when-to-switch-from-rent-to-own">When to switch from rent to
own</h2>
<p>Conventional wisdom says to wait: Wait until your volume is high
enough, wait until API prices stabilize, wait until the tooling matures.
But waiting is not neutral. Every month you hold back is a month your
competitor's system gets smarter while yours doesn't exist.</p>
<p>There are only two real triggers. The first is steady spend: if your
token bill is already in the five-figure range each month, you are
exposed to someone else's pricing decisions. The second is workload
criticality: if accuracy, latency, and compliance define your product,
you cannot build an advantage on rented APIs.</p>
<p>The trap is telling yourself you will switch "later." But by then you
are locked in. Your QA processes are built around one provider's quirks,
your customers expect a specific output style, your prompts have
hundreds of workarounds for model-specific bugs, and the cost of change
feels impossible. Meanwhile, your competitor who started small has
already tuned open-weights models to their data, cut their costs by
<strong>10x</strong>, and built evaluation gates that compound every
cycle.</p>
<p>If AI touches your core product, every day you rent the loop is a day
you hand your roadmap to someone else. Start early, even when the
economics seem to look wrong. They only look right after you have
already built capability.</p>
<h2 id="what-to-do-next">What to do next</h2>
<p>The rent-or-build dichotomy is fake. You need to own enough of the
learning loop to compound. You don't need a mega-lab for this. You need
a durable, small stack. Open weights are the clay, and your learning
loop is the sculptor. If you don't do this, you are just another cheap
renter and not a winner.</p>
<p>The winners will be the ones who turn every deployment into
compounding advantage. Convirza cut costs <strong>10x</strong> while
improving quality. Goldman Sachs boosted productivity
<strong>20%</strong> while reducing defects. This is what happens when
you own the learning loop.</p>
<p>Prices will keep shifting, and model deprecations will force
rewrites, but real moats that are built on your data, your evaluations,
your continuous improvement don't move.</p>
<p><strong>If you rent everything, OpenAI's roadmap is your
roadmap.</strong><br />
If you own the loop, your roadmap is yours.</p>]]></content>
  </entry>
  <entry>
      <title>How to Get from A Tree to A Flat Shape And Back Again</title>
      <link href="https://tscholak.github.io/posts/Flattening.html"/>
      <id>https://tscholak.github.io/posts/Flattening.html</id>
      <updated>2022-02-02T00:00:00Z</updated>
      <category term="haskell"/>
      <category term="recursion"/>
      <category term="generics"/>
      <category term="parsing"/>
      <summary type="html"><![CDATA[<p>The adventure continues in this "Unrecurse" sequel. Previously, we
bravely faced turmoil and confusion in a cruel world in which Haskell
suddenly stopped supporting recursive function calls. We barely escaped
the wrath of the compiler. This time, we try to survive an even more
extreme situation: Haskell without recursive data types! It is the
ultimate test of our programming skills. Will we make it through the
final challenge, or is all hope lost? Join us in this journey about
tapes and tribulations.</p>]]></summary>
      <content type="html"><![CDATA[<h2 id="preliminaries">Preliminaries</h2>
<p>This is a <a
href="https://wiki.haskell.org/Literate_programming">Literate
Haskell</a> essay: Every line of program code in this article has been
checked by the Haskell compiler. Every example and property in the
Haddock comments has been tested by the doctest tool. I thank the <a
href="https://wiki.haskell.org/Haskell">Haskell community</a> for making
this possible.</p>
<p>To make this a proper Haskell file, it needs a header. There are
several language extensions we need to enable:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE TypeApplications #-}</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE GADTs #-}</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE RecordWildCards #-}</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE DeriveTraversable #-}</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE TemplateHaskell #-}</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE TypeFamilies #-}</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE ScopedTypeVariables #-}</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE BangPatterns #-}</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE FlexibleContexts #-}</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE MultiParamTypeClasses #-}</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE DefaultSignatures #-}</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE FlexibleInstances #-}</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE TypeOperators #-}</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE UndecidableInstances #-}</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE DeriveGeneric #-}</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE DerivingVia #-}</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE GeneralizedNewtypeDeriving #-}</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE StandaloneDeriving #-}</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE LambdaCase #-}</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE InstanceSigs #-}</span></span></code></pre></div>
<p>Nice, this is more looking like your typical fancy Haskell file now.
We will also need to import a meager handful of libraries, functions,
and types:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">module</span> <span class="dt">Flattening</span> <span class="kw">where</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Control.Applicative</span> (<span class="dt">Alternative</span> (empty, (&lt;|&gt;)))</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Control.Lens</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    ( <span class="dt">Cons</span> (_Cons),</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>      cons,</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>      prism,</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>      uncons,</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>      withPrism,</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>      zoom,</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>      _1,</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>      _2,</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Control.Monad</span> (<span class="dt">MonadPlus</span>, mfilter)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Control.Monad.State</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    ( <span class="dt">MonadState</span> (get, put),</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>      <span class="dt">StateT</span> (runStateT),</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>      evalStateT,</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Control.Monad.Trans</span> (<span class="dt">MonadTrans</span> (lift))</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Control.Monad.Writer</span> (<span class="dt">Writer</span>, execWriter, tell)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Data.Coerce</span> (coerce)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Data.Functor.Foldable</span> (<span class="dt">Base</span>, <span class="dt">Corecursive</span> (embed), <span class="dt">Recursive</span> (cata, project))</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Data.Functor.Foldable.TH</span> (makeBaseFunctor)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Data.Kind</span> (<span class="dt">Type</span>)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Data.Maybe</span> (fromJust)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Data.Monoid</span> (<span class="dt">Sum</span> (..))</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Data.Vector</span> (<span class="dt">Vector</span>)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">GHC.Generics</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    ( <span class="dt">Generic</span> (<span class="dt">Rep</span>, from, to),</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>      <span class="dt">K1</span> (<span class="dt">K1</span>, unK1),</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>      <span class="dt">M1</span> (<span class="dt">M1</span>, unM1),</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>      <span class="dt">U1</span> (<span class="dt">U1</span>),</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>      <span class="dt">V1</span>,</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>      <span class="kw">type</span> (<span class="op">:*:</span>) ((<span class="op">:*:</span>)),</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>      <span class="kw">type</span> (<span class="op">:+:</span>) (<span class="dt">L1</span>, <span class="dt">R1</span>),</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Unrecurse</span> (<span class="dt">Continue</span> (..), <span class="dt">Kont</span> (..), <span class="dt">Stack</span>, <span class="dt">Tree</span> (..), exampleTree, pop, push, while)</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Prelude</span> <span class="kw">hiding</span> (even, odd)</span></code></pre></div>
<p>You will notice that we are importing definitions from the
<code>Unrecurse</code> module, which belongs to the <a
href="/posts/Unrecurse.html">previous article</a> in this series.</p>
<p>For the <code>Tree</code> type from the <code>Unrecurse</code>
module, we need a QuickCheck random generator to run property tests with
<code>doctest</code>:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- $setup</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; import Test.QuickCheck</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; :{</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">--   arbTree :: Arbitrary a =&gt; Int -&gt; Gen (Tree a)</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">--   arbTree 0 = pure Nil</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">--   arbTree n =</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">--     frequency</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">--       [ (1, pure Nil),</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">--         ( 3,</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>  <span class="co">--           Node</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>  <span class="co">--             &lt;$&gt; arbTree (div n 2)</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>  <span class="co">--             &lt;*&gt; arbitrary</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>  <span class="co">--             &lt;*&gt; arbTree (div n 2)</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>  <span class="co">--         )</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>  <span class="co">--       ]</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- :}</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>  <span class="co">--</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; instance Arbitrary a =&gt; Arbitrary (Tree a) where arbitrary = sized arbTree</span></span></code></pre></div>
<p>This should create random binary trees with a frequency distribution
that is exponentially decreasing in the number of constructors.</p>
<p>Ok, enough beating around the bush. Now we can start with the actual
content of the essay.</p>
<h2 id="the-flattening-of-a-tree">The Flattening of A Tree</h2>
<p><a href="/posts/Unrecurse.html">Last time</a> on this channel, we
have seen how one can remove recursive calls from a function. We learned
about continuations, defunctionalization, and monadic <code>State</code>
effects. We used these techniques to reimplement two simple recursive
functions, <code>printTree</code> and <code>accumTree</code>, using only
iteration. These functions are both specific examples of a
<code>fold</code>. They consume a value of type <code>Tree</code>, a
data type for binary trees with two constructors, <code>Nil</code> and
<code>Node</code>. <code>printTree</code> reduces the tree node by node
in depth-first, left-to-right order to an effect: leaf values are
printed to <code>stdout</code> as they are encountered. On the other
hand, <code>accumTree</code> reduces the tree to value, that is, the sum
of all leaf values.</p>
<p>Even though we worked very hard to remove all recursion from these
functions, we still have a problem. The definition of the
<code>Tree</code> type was and remains self-referential: its
<code>Node</code> constructor takes two <code>Tree</code> values as
arguments. That makes <code>Tree</code> a <em>recursive data type</em>,
and that is FORBIDDEN in recursion-free Haskell. Sorry, I don't make the
rules. So far, we did not dare to remove recursion from the
<code>Tree</code> data type. This time, we are more ambitious!</p>
<p>The high-level idea is that we are going to store our
<code>Tree</code> in a linear data structure we call a
<code>Tape</code>. This will be done in a fashion that allows us to zoom
in on subtrees by slicing the <code>Tape</code>.</p>
<p>As usual, we need a few ingredients:</p>
<ul>
<li><code>Token</code>s, which are a set of values that are going to
represent different pieces of a <code>Tree</code>.</li>
<li>The <code>Tape</code>, which is a linear data structure that can be
written to and read from and that can be used to represent a whole
<code>Tree</code> or parts of it.</li>
<li>A linearizer that can convert a <code>Tree</code> to a
<code>Tape</code> of <code>Token</code>s.</li>
<li>A parser that can convert a <code>Tape</code> of <code>Token</code>s
to a <code>Tree</code>.</li>
<li>A base functor for the <code>Tree</code> type that can be used to
construct or deconstruct a tree iteratively.</li>
<li>Lots and lots of boilerplaty Haskell <code>Generic</code> code.</li>
</ul>
<p>We will cover these ingredients in detail in the following sections.
It will take some time to go through all of them. The slow pace will
help you to can get a feel for all this stuff. We shall now start by
defining the <code>Token</code> and <code>Tape</code> types. Chocks
away!</p>
<h2 id="token-tapes">Token Tapes</h2>
<p>We define our tape as a <code>newtype</code> wrapper around an
underlying type constructor, <code>t :: Type -&gt; Type</code>:</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">newtype</span> <span class="dt">Tape</span> t a <span class="ot">=</span> <span class="dt">Tape</span> {<span class="ot">unTape ::</span> t a}</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">deriving</span> stock (<span class="dt">Eq</span>, <span class="dt">Show</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">deriving</span> <span class="kw">newtype</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>      ( <span class="dt">Semigroup</span>,</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Monoid</span>,</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Functor</span>,</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Applicative</span>,</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Monad</span>,</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Alternative</span>,</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Foldable</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>      )</span></code></pre></div>
<p>The type <code>t</code> could be <code>[]</code>, <code>Seq</code>,
<code>Vector</code>, <code>Deque</code>, etc. It doesn't matter, we
won't make a choice at this point. The only requirement is that there is
a way to attach or detach elements on the left side of <code>t</code>.
The <code>Cons</code> data class provides a way to formalize this
requirement, and the following code propagates this requirement to the
<code>Tape</code> type by means of coercion:</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Cons</span> (t a) (t b) a b <span class="ot">=&gt;</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Cons</span> (<span class="dt">Tape</span> t a) (<span class="dt">Tape</span> t b) a b</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    _Cons <span class="ot">=</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>      withPrism _Cons <span class="op">$</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        \(<span class="ot">review&#39; ::</span> (b, t b) <span class="ot">-&gt;</span> t b)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>         (<span class="ot">preview&#39; ::</span> t a <span class="ot">-&gt;</span> <span class="dt">Either</span> (t b) (a, t a)) <span class="ot">-&gt;</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>            prism (coerce review&#39;) (coerce preview&#39;)</span></code></pre></div>
<p>This class instance gives us a <a
href="https://hackage.haskell.org/package/lens-5.1/docs/Control-Lens-Prism.html#t:Prism">prism</a>
that can be used to build or deconstruct a <code>Tape</code> via the
<code>cons</code> and <code>uncons</code> functions from <a
href="https://hackage.haskell.org/package/lens-5.1/docs/Control-Lens-Cons.html">Control.Lens.Cons</a>.
They basically work like <code>(:)</code> and <code>uncons</code> from
<code>Data.List</code>, but they are polymorphic in the type
<code>t</code> and thus can be used with any <code>t</code> that
satisfies the <code>Cons</code> requirement.</p>
<p>Let's now talk about what we are going to put on the tape. Our tapes
will be made up entirely of <code>Token</code>s, to be defined
momentarily. Because of that homogeneity, it is a good idea to save us
some keystrokes and forge a handy type synonym:</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | A tape of tokens.</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">type</span> <span class="dt">TTape</span> t <span class="ot">=</span> <span class="dt">Tape</span> t <span class="dt">Token</span></span></code></pre></div>
<p>Each <code>Token</code> will be used to represent a piece of
information about a particular <code>Tree</code>. For trees with integer
leaf nodes, i.e. <code>Tree Int</code>, we will only ever need four
<code>Token</code>s:</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">data</span> <span class="dt">Token</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="ot">=</span> <span class="co">-- | Represent a recursive call to an abstract data type.</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Rec</span> <span class="dt">Int</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="op">|</span> <span class="co">-- | Represent a left choice between two constructors.</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>      <span class="dt">L</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="op">|</span> <span class="co">-- | Represent a right choice between two constructors.</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">R</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="op">|</span> <span class="co">-- | Represent an integer leaf node.</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>      <span class="dt">I</span> <span class="dt">Int</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">deriving</span> stock (<span class="dt">Eq</span>, <span class="dt">Show</span>)</span></code></pre></div>
<p>I will explain each of these tokens in more detail in a bit. Their
function will become clear as we go along.</p>
<h2 id="linearization">Linearization</h2>
<p>Now, how do we turn a tree into a token tape?</p>
<p>In general, we want a function -- let's call it
<code>linearize</code> -- that turns a value of some type <code>a</code>
into a tape of tokens, <code>TTape t</code>, without losing any
information. <code>a</code> could be any type, but we explicitly want
this to work for <code>a ~ Tree Int</code> in the end.</p>
<p>Let's give <code>linearize</code> a type signature:</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">type</span> <span class="dt">To</span> t a <span class="ot">=</span> a <span class="ot">-&gt;</span> <span class="dt">TTape</span> t</span></code></pre></div>
<p>And, because we like to keep things formal, a formal definition:</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">class</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">ToTokens</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>      (<span class="ot">t ::</span> <span class="dt">Type</span> <span class="ot">-&gt;</span> <span class="dt">Type</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>      (<span class="ot">a ::</span> <span class="dt">Type</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">-- | Convert a value of type `a` into a tape of tokens.</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="ot">    linearize ::</span> <span class="dt">To</span> t a</span></code></pre></div>
<p>This is Haskell. And, in case you haven't noticed, the way of Haskell
is to make things as general as possible, sometimes until it hurts. For
that reason, this class is parameterized not only by the type of the
values we are going to encode, <code>a</code>, but also by the tape's
type parameter, <code>t</code>.</p>
<p>To annoy you further, I will give <code>linearize</code> an arcane
<code>default</code> implementation:</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>    default<span class="ot"> linearize ::</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>      ( <span class="dt">Recursive</span> a,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        <span class="dt">ToTokensStep</span> t (<span class="dt">Base</span> a)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>      ) <span class="ot">=&gt;</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>      <span class="dt">To</span> t a</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    linearize <span class="ot">=</span> cata linearizeStep</span></code></pre></div>
<p>This definition uses the accurately named yet mysterious
<code>Recursive</code> class. <code>Recursive</code> gives us
<code>cata</code>. Both of these are defined in <a
href="https://hackage.haskell.org/package/recursion-schemes-5.2.2.2/docs/Data-Functor-Foldable.html">Data.Functor.Foldable</a>.
The <code>cata</code> function is a generalization of <code>fold</code>
and takes two arguments:</p>
<ul>
<li>A function that performs one step of a recursive computation. For
us, that function is <code>linearizeStep</code> that is doing the actual
work. It has the type <code>Base a (TTape t) -&gt; TTape t</code>.</li>
<li>The value that needs to be worked on. That value has the type
<code>a</code>.</li>
</ul>
<p>With these, <code>cata</code> is recursively chewing up the value
<code>a</code> and turning it into a <code>TTape t</code>. I admit, this
machinery is a wee opaque. I will try my best to explain what is going
on. Stay with me.</p>
<h2 id="base-functors">Base Functors</h2>
<p>Let's first zoom in on the cryptic type of
<code>linearizeStep</code>. This is a function that takes a value of
type <code>Base a (TTape t)</code> and gives us back a value of type
<code>TTape t</code>. I guess it's clear what comes out of this function
(a tape of tokens), but what in tarnation are we passing here? What's
<code>Base</code>, and why is it parameterized by both <code>a</code>
and our trusty token tape type?</p>
<p><code>Base :: Type -&gt; (Type -&gt; Type)</code>, as it turns out,
is also coming from <a
href="https://hackage.haskell.org/package/recursion-schemes-5.2.2.2/docs/Data-Functor-Foldable.html">Data.Functor.Foldable</a>.
It is an open type family and can be thought of as a type-level registry
of so-called "base functors". A registered base functor,
<code>Base a r</code>, is a non-recursive data type that is derived for
a specific recursive data type, <code>a</code>. The type parameter
<code>r</code> is used to represent recursion in <code>a</code>. How?
Think of it in the following way: <code>Base a r</code> is structurally
equal to <code>a</code> except that <code>r</code> takes the place of
all recursive occurrences of <code>a</code> in <code>a</code>.</p>
<p>For instance, the base functor of our <code>Kont</code> type from the
<a href="/posts/Unrecurse.html">previous installment</a> of this series
is:</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | A base functor for `Kont`.</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">data</span> <span class="dt">KontF</span> next r</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    <span class="ot">=</span> <span class="co">-- | Terminate a computation</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>      <span class="dt">FinishedF</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    <span class="op">|</span> <span class="co">-- | Continue a computation with `next`</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">MoreF</span> next r</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">deriving</span> stock (<span class="dt">Eq</span>, <span class="dt">Show</span>, <span class="dt">Functor</span>)</span></code></pre></div>
<p>The <code>r</code> type parameter appears exactly where
<code>Kont next</code> appears in the original <code>More</code>
constructor of <code>Kont next</code>. Go back to the definition of
<code>Kont next</code> and check for yourself if you don't believe me.
Off you pop.</p>
<p>Quick side node on naming. It is customary to name the base functor
and its constructors after the recursive data type they are associated
with (in this case, <code>Kont</code>) except for appending the letter
<code>F</code> for "functor". Like the name suggests, a base functor is
always a functor in the type parameter <code>r</code>, and Haskell can
derive that instance for us. Neat.</p>
<p>Now, with <code>KontF</code> in hand, we can write the following type
family instance:</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">type</span> <span class="kw">instance</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Base</span> (<span class="dt">Kont</span> next) <span class="ot">=</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>      <span class="dt">KontF</span> next</span></code></pre></div>
<p>This tells Haskell that the base functor of <code>Kont</code> is
<code>KontF</code>.</p>
<p>How is all this going to help us?</p>
<p>Like we said before, the argument of <code>linearizeStep</code> is of
type <code>Base a r</code> with <code>r ~ TTape t</code>. If
<code>a</code> were <code>Kont next</code>, then <code>Base a r</code>
would be <code>KontF next (TTape t)</code>. And, likewise, if
<code>a</code> were <code>Tree Int</code>, then <code>Base a r</code>
would be <code>TreeF Int (TTape t)</code>. That means that
<code>linearizeStep</code> always works on a version of <code>a</code>
where recursive constructors are replaced with token tapes,
<code>r ~ TTape t</code>.</p>
<p>We now understand that <code>linearizeStep</code> takes a special
non-recursive version of <code>a</code> and that it is supposed to
produce a token tape. But how should this transformation look like?</p>
<h2 id="linearization-example">Linearization Example</h2>
<p>Let's dive into a concrete example and try to understand how things
should play out for <code>a ~ Kont Int</code>. This is a bit easier than
reaching immediately for trees.</p>
<p>First, consider the base case. For a finished continuation,
<code>FinishedF</code>, our encoding should look like this:</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | A linearized finished continuation.</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; linearizedFinished</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Tape {unTape = [L]}</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="ot">  linearizedFinished ::</span> <span class="dt">TTape</span> []</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  linearizedFinished <span class="ot">=</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span><span class="ot"> finished ::</span> <span class="dt">KontF</span> <span class="dt">Int</span> (<span class="dt">TTape</span> []) <span class="ot">=</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>          <span class="dt">FinishedF</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>     <span class="kw">in</span> linearizeStep finished</span></code></pre></div>
<p>This base case is particularly easy to deal with since the
<code>FinishedF</code> constructor has no arguments. The only
information we need to encode is the constructor itself. I use the token
<code>L</code> (for "left") to represent <code>FinishedF</code>, because
it appears on the left side in the sum type <code>KontF</code>. Thus,
the <code>linearizedFinished</code> tape should have one element: the
token <code>L</code>.</p>
<p>Now, let's take a look at the recursive case: For a continuation with
one more step, <code>MoreF</code>, the situation is more complicated,
but only slightly so. I propose the following encoding:</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | A linearized continuation with one more step.</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; linearizedMore linearizedFinished</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Tape {unTape = [R,I 0,Rec 1,L]}</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; linearizedMore (linearizedMore linearizedFinished)</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Tape {unTape = [R,I 0,Rec 4,R,I 0,Rec 1,L]}</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; linearizedMore (linearizedMore (linearizedMore linearizedFinished))</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Tape {unTape = [R,I 0,Rec 7,R,I 0,Rec 4,R,I 0,Rec 1,L]}</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="ot">  linearizedMore ::</span> <span class="dt">TTape</span> [] <span class="ot">-&gt;</span> <span class="dt">TTape</span> []</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>  linearizedMore previousTape <span class="ot">=</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span><span class="ot"> more ::</span> <span class="dt">KontF</span> <span class="dt">Int</span> (<span class="dt">TTape</span> []) <span class="ot">=</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>          <span class="dt">MoreF</span> <span class="dv">0</span> previousTape</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>     <span class="kw">in</span> linearizeStep more</span></code></pre></div>
<p>I hope the examples make it clear enough that in this encoding:</p>
<ol>
<li><code>R</code> (for "right") is the token for
<code>MoreF</code>.</li>
<li><code>I 0</code> (for "integer") is the token for the first argument
of <code>MoreF</code>. That argument is always <code>0 :: Int</code> in
this contrived example.</li>
<li><code>Rec _</code> is the token for the recursive case. Its argument
counts the number of tokens needed to encode it. Effectively, this just
measures the length of the previous tape we pass to the
<code>linearizedMore</code> function.</li>
</ol>
<p>Note how, in the above examples, calls to <code>linearizedMore</code>
are nested to create a tape that encodes progressively more recursive
calls to the <code>MoreF</code> constructor. What I have done here
manually will in the end be done for us automatically by
<code>linearize</code> thanks to the <code>Recursive</code> type class
and <code>cata</code>:</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- |</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; linearize (Finished :: Kont Int) :: TTape []</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Tape {unTape = [L]}</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; linearize (More 0 $ Finished :: Kont Int) :: TTape []</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Tape {unTape = [R,I 0,Rec 1,L]}</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; linearize (More 0 $ More 0 $ Finished :: Kont Int) :: TTape []</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Tape {unTape = [R,I 0,Rec 4,R,I 0,Rec 1,L]}</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; linearize (More 0 $ More 0 $ More 0 $ Finished :: Kont Int) :: TTape []</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Tape {unTape = [R,I 0,Rec 7,R,I 0,Rec 4,R,I 0,Rec 1,L]}</span></span></code></pre></div>
<p>If we had a working implementation of <code>linearizeStep</code>
already, then the only thing we would need to do to get this behaviour
is to define an instance of the <code>Recursive</code> type class for
<code>Kont next</code>, like so:</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span> <span class="dt">Recursive</span> (<span class="dt">Kont</span> next) <span class="kw">where</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="ot">    project ::</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Kont</span> next <span class="ot">-&gt;</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>      <span class="dt">KontF</span> next (<span class="dt">Kont</span> next)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    project (<span class="dt">More</span> n k) <span class="ot">=</span> <span class="dt">MoreF</span> n k</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    project <span class="dt">Finished</span> <span class="ot">=</span> <span class="dt">FinishedF</span></span></code></pre></div>
<p>This implementation of <code>project</code> tells Haskell how a
single layer of a <code>Kont next</code> value is unrolled into a
<code>KontF next (Kont next)</code> value. The rest is taken care of by
the <code>cata</code> function. I can recommend you to read the newly
revised <a
href="https://hackage.haskell.org/package/recursion-schemes-5.2.2.2#readme-container">documentation</a>
of the recursion schemes package to get an even better understanding of
the principles behind this approach.</p>
<p>Good, we have a more or less clear picture of how
<code>linearizeStep</code> is supposed to work. What's missing is an
implementation. Next up: an implementation.</p>
<h2 id="generic-stepwise-linearization">Generic Stepwise
Linearization</h2>
<p>We can formally introduce <code>linearizeStep</code> like this:</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">class</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">ToTokensStep</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>      (<span class="ot">t ::</span> <span class="dt">Type</span> <span class="ot">-&gt;</span> <span class="dt">Type</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>      (<span class="ot">base ::</span> <span class="dt">Type</span> <span class="ot">-&gt;</span> <span class="dt">Type</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">-- | A stepwise linearization of a value of type `base (TTape t)`.</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="ot">    linearizeStep ::</span> <span class="dt">To</span> t (base (<span class="dt">TTape</span> t))</span></code></pre></div>
<p>Like <code>ToTokens</code>, the <code>ToTokensStep</code> type class
is parameterized by the type of the token tape, <code>t</code>. But
instead of the <code>a</code> type, we've got another parameter,
<code>base</code>, for its base functor.</p>
<p>I promised oodles of boilerplate code, and I am happy to announce
that the waiting is over. We will use <a
href="https://downloads.haskell.org/ghc/latest/docs/html/users_guide/exts/generics.html">datatype-generic
programming</a> to implement this class!</p>
<p>Have a look at the following <code>default</code> implementation:</p>
<div class="sourceCode" id="cb18"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>    default<span class="ot"> linearizeStep ::</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>      ( <span class="dt">Alternative</span> t,</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Foldable</span> t,</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Generic</span> (base (<span class="dt">TTape</span> t)),</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>        <span class="dt">GToTokensStep</span> t (<span class="dt">Rep</span> (base (<span class="dt">TTape</span> t)))</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>      ) <span class="ot">=&gt;</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">To</span> t (base (<span class="dt">TTape</span> t))</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    linearizeStep <span class="ot">=</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>      gLinearizeStep</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>        <span class="op">.</span> GHC.Generics.from</span></code></pre></div>
<p>Of course, that's just a wrapper around <code>gLinearizeStep</code>,
defined below:</p>
<div class="sourceCode" id="cb19"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">class</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">GToTokensStep</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>      (<span class="ot">t ::</span> <span class="dt">Type</span> <span class="ot">-&gt;</span> <span class="dt">Type</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>      (<span class="ot">rep ::</span> <span class="dt">Type</span> <span class="ot">-&gt;</span> <span class="dt">Type</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">-- | A generic implementation of `linearizeStep`.</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="ot">    gLinearizeStep ::</span> <span class="kw">forall</span> a<span class="op">.</span> <span class="dt">To</span> t (rep a)</span></code></pre></div>
<p>This follows <a
href="https://wiki.haskell.org/GHC.Generics#More_general_default_methods">the</a>
<a
href="https://hackage.haskell.org/package/base-4.16.0.0/docs/GHC-Generics.html#g:13">usual</a>
<a
href="https://hackage.haskell.org/package/binary-0.8.9.0/docs/Data-Binary.html#t:Binary">pattern</a>
for datatype-generic programming in Haskell. In particular, this says
that, if our base functor has a <code>Generic</code> instance with
generic representation <code>Rep (base r)</code>, then we can obtain a
<code>ToTokensStep</code> instance (and thus <code>linearizeStep</code>)
for free. Free is very cheap.</p>
<p><code>GHC.Generics.from</code> will convert a <code>base r</code>
value into a <code>Rep (base r)</code> value. The latter represents
<code>base r</code> using only generic primitive types. These types are
defined in the <code>GHC.Generics</code> module and are:</p>
<ul>
<li><code>V1</code> for impossible values (<code>Void</code>). This is
used for types that have no constructors. We can't represent
<code>Void</code> in our token tape.</li>
<li><code>U1</code> for constructors without arguments like
<code>()</code> or <code>Finished</code>.</li>
<li><code>K1</code> for constants like <code>True</code> or
<code>1</code>. This is used for constructor arguments. These could be
recursive values.</li>
<li><code>M1</code> for meta data. This is a wrapper and used to encode
constructor or data type names.</li>
<li><code>(:*:)</code> for product types. This is used to separate
constructor arguments.</li>
<li><code>(:+:)</code> for sum types. This is used to encode a choice
between two constructors.</li>
</ul>
<p>If you have never seen these types before, you may want to read some
of the <a
href="https://hackage.haskell.org/package/base-4.16.0.0/docs/GHC-Generics.html">documentation</a>
in the <code>GHC.Generics</code> module. There are some examples that
will help you understand the types better than I can in this
tutorial.</p>
<p>We only need to specify once what should happen for the six generic
types. For <code>V1</code>, we can't do anything:</p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span> <span class="dt">GToTokensStep</span> t <span class="dt">V1</span> <span class="kw">where</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    gLinearizeStep v <span class="ot">=</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>      v <span class="ot">`seq`</span> <span class="fu">error</span> <span class="st">&quot;GToTokensStep.V1&quot;</span></span></code></pre></div>
<p>For <code>U1</code>, we can just ignore it and return an empty token
tape:</p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Alternative</span> t <span class="ot">=&gt;</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">GToTokensStep</span> t <span class="dt">U1</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    gLinearizeStep _ <span class="ot">=</span> <span class="dt">Tape</span> empty</span></code></pre></div>
<p>For <code>K1</code>, we can just delegate to
<code>linearize</code>:</p>
<div class="sourceCode" id="cb22"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">ToTokens</span> t c <span class="ot">=&gt;</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">GToTokensStep</span> t (<span class="dt">K1</span> i c)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    gLinearizeStep <span class="ot">=</span> linearize <span class="op">.</span> unK1</span></code></pre></div>
<p>When specialized to <code>K1 i Int</code>, this instance is used to
convert an <code>Int</code> constant appearing in
<code>KontF Int r</code> into a tape of a single <code>I</code>
token:</p>
<div class="sourceCode" id="cb23"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Alternative</span> t <span class="ot">=&gt;</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">ToTokens</span> t <span class="dt">Int</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    linearize i <span class="ot">=</span> <span class="fu">pure</span> (<span class="dt">I</span> i)</span></code></pre></div>
<p>Moreover, when specialized to <code>K1 i (TTape t)</code>, the
<code>K1</code> instance defines what should happen for the
<code>TTape t</code> constants in <code>KontF next (TTape t)</code>.
This is the trick that allows us to deal with recursive constructor
arguments:</p>
<div class="sourceCode" id="cb24"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    (<span class="dt">Alternative</span> t, <span class="dt">Foldable</span> t) <span class="ot">=&gt;</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">ToTokens</span> t (<span class="dt">TTape</span> t)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    linearize tape <span class="ot">=</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pure</span> (<span class="dt">Rec</span> <span class="op">$</span> <span class="fu">length</span> tape) <span class="op">&lt;|&gt;</span> tape</span></code></pre></div>
<p>Here we use <code>length</code> to measure the length of the tape. We
store that length in a <code>Rec</code> token that we prepend to the
tape using <code>(&lt;|&gt;)</code>. This length information will be
helpful later when we want to decode the tape back into a value.</p>
<p>For <code>M1</code>, we can just unwrap the constructor:</p>
<div class="sourceCode" id="cb25"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">GToTokensStep</span> t f <span class="ot">=&gt;</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">GToTokensStep</span> t (<span class="dt">M1</span> i c f)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    gLinearizeStep <span class="ot">=</span> gLinearizeStep <span class="op">.</span> unM1</span></code></pre></div>
<p>For the product <code>(f :*: g)</code>, we can delegate to the
<code>GToTokensStep</code> instances of <code>f</code> and
<code>g</code>:</p>
<div class="sourceCode" id="cb26"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    ( <span class="dt">Alternative</span> t,</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Foldable</span> t,</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>      <span class="dt">GToTokensStep</span> t f,</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>      <span class="dt">GToTokensStep</span> t g</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    ) <span class="ot">=&gt;</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    <span class="dt">GToTokensStep</span> t (f <span class="op">:*:</span> g)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>    gLinearizeStep (x <span class="op">:*:</span> y) <span class="ot">=</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>      gLinearizeStep x <span class="op">&lt;|&gt;</span> gLinearizeStep y</span></code></pre></div>
<p>The tapes of the two <code>x :: f a</code> and <code>y :: g a</code>
values are concatenated using <code>(&lt;|&gt;)</code>.</p>
<p>Finally, we can define an instance for the sum
<code>(f :+: g)</code>:</p>
<div class="sourceCode" id="cb27"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    ( <span class="dt">Applicative</span> t,</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Alternative</span> t,</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Foldable</span> t,</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>      <span class="dt">GToTokensStep</span> t f,</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">GToTokensStep</span> t g</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    ) <span class="ot">=&gt;</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    <span class="dt">GToTokensStep</span> t (f <span class="op">:+:</span> g)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    gLinearizeStep (<span class="dt">L1</span> x) <span class="ot">=</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pure</span> <span class="dt">L</span> <span class="op">&lt;|&gt;</span> gLinearizeStep x</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    gLinearizeStep (<span class="dt">R1</span> x) <span class="ot">=</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">pure</span> <span class="dt">R</span> <span class="op">&lt;|&gt;</span> gLinearizeStep x</span></code></pre></div>
<p>We use <code>pure L</code> and <code>pure R</code> to encode the left
and right constructor.</p>
<p>This concludes the definition of <code>GToTokensStep</code> and the
boilerplaty datatype-generic programming exercise for
<code>ToTokensStep</code>. Wasn't that fun? There is more to come.</p>
<h2 id="auto-generating-totokens-instances">Auto-Generating
<code>ToTokens</code> Instances</h2>
<p>Perhaps this was lost in the noise, but we can now automatically
generate <code>ToTokens</code> instances!</p>
<p>For the <code>Kont</code> data type, this is done in three steps:</p>
<p>Step 1: Ask Haskell to generate a <code>Generic</code> instance for
<code>Kont</code>'s base functor, <code>KontF</code>.</p>
<div class="sourceCode" id="cb28"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">deriving</span> stock <span class="kw">instance</span> <span class="dt">Generic</span> (<span class="dt">KontF</span> next r)</span></code></pre></div>
<p>Step 2: Obtain a <code>ToTokensStep</code> instance from the default
implementation.</p>
<div class="sourceCode" id="cb29"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    (<span class="dt">Alternative</span> t, <span class="dt">Foldable</span> t, <span class="dt">ToTokens</span> t next) <span class="ot">=&gt;</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">ToTokensStep</span> t (<span class="dt">KontF</span> next)</span></code></pre></div>
<p>Step 3: Earn a <code>ToTokens</code> instance.</p>
<div class="sourceCode" id="cb30"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">ToTokensStep</span> t (<span class="dt">KontF</span> next) <span class="ot">=&gt;</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">ToTokens</span> t (<span class="dt">Kont</span> next)</span></code></pre></div>
<p>With these we can convert a <code>Kont next</code> value into a
<code>TTape t</code> value (if we also happen to have a
<code>ToTokens</code> instance for <code>next</code>). And we know that
this is true because this is a literate Haskell article, and all
previously seen examples were in fact already working. Surprise!</p>
<p>Originally, we were interested in values of type
<code>Tree Int</code>. Perhaps you remember. Are we any closer to
linearizing those, too? We are. We can automagically generate now
everything we need.</p>
<p>We defined the base functor <code>KontF</code> for the
<code>Kont</code> data type manually. This was a bit tedious, but it
helped us understand base functor types. Now, rather than going through
the trouble of writing our own base functor for <code>Tree</code> (or
any other data type <code>a</code>), we can use
<code>makeBaseFunctor</code> to do this for us.
<code>makeBaseFunctor</code> is a <a
href="https://en.wikipedia.org/wiki/Template_Haskell">Template
Haskell</a> function that generates the base functor for the
<code>Tree</code> type and calls it <code>TreeF</code>.</p>
<div class="sourceCode" id="cb31"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>  makeBaseFunctor &#39;<span class="dt">&#39;Tree</span></span></code></pre></div>
<p>This little trick also generates <code>Base</code> and
<code>Recursive</code> instances for <code>Tree</code>, among a few
other things that we don't need to worry about right now.</p>
<p>However, we don't get a <code>Show</code> or <code>Generic</code>
instance for <code>TreeF</code>, so let's quickly add those:</p>
<div class="sourceCode" id="cb32"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">deriving</span> stock <span class="kw">instance</span> (<span class="dt">Show</span> a, <span class="dt">Show</span> r) <span class="ot">=&gt;</span> <span class="dt">Show</span> (<span class="dt">TreeF</span> a r)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">deriving</span> stock <span class="kw">instance</span> <span class="dt">Generic</span> (<span class="dt">TreeF</span> a r)</span></code></pre></div>
<p>The <code>Generic</code> instance opens up the possibility of
auto-generating the <code>ToTokens</code> instance for
<code>Tree</code>:</p>
<div class="sourceCode" id="cb33"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    (<span class="dt">Alternative</span> t, <span class="dt">Foldable</span> t, <span class="dt">ToTokens</span> t a) <span class="ot">=&gt;</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">ToTokensStep</span> t (<span class="dt">TreeF</span> a)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">ToTokensStep</span> t (<span class="dt">TreeF</span> a) <span class="ot">=&gt;</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    <span class="dt">ToTokens</span> t (<span class="dt">Tree</span> a)</span></code></pre></div>
<p>And that's it! Let's see what we can do with this:</p>
<div class="sourceCode" id="cb34"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; linearize (Nil :: Tree Int) :: TTape []</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Tape {unTape = [L]}</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; linearize (Node Nil 0 Nil :: Tree Int) :: TTape []</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Tape {unTape = [R,Rec 1,L,I 0,Rec 1,L]}</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; linearize (Node (Node Nil 0 Nil) 1 (Node Nil 2 Nil) :: Tree Int) :: TTape []</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Tape {unTape = [R,Rec 6,R,Rec 1,L,I 0,Rec 1,L,I 1,Rec 6,R,Rec 1,L,I 2,Rec 1,L]}</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; linearize exampleTree :: TTape []</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Tape {unTape = [R,Rec 16,R,Rec 6,R,Rec 1,L,I 1,Rec 1,L,I 2,Rec 6,R,Rec 1,L,I 3,Rec 1,L,I 4,Rec 16,R,Rec 6,R,Rec 1,L,I 5,Rec 1,L,I 6,Rec 6,R,Rec 1,L,I 7,Rec 1,L]}</span></span></code></pre></div>
<p>There you have it, we can flatten binary trees and store them in
tapes of tokens. Cool stuff!</p>
<h2 id="parsing-tapes-of-tokens">Parsing Tapes of Tokens</h2>
<p>How can we go back from a <code>TTape t</code> value to a
<code>Tree</code> value?</p>
<p>The answer is <em>parsing</em>. <a
href="https://hackage.haskell.org/package/parsec">Many</a> <a
href="https://hackage.haskell.org/package/megaparsec">parsing</a> <a
href="https://hackage.haskell.org/package/attoparsec">libraries</a> <a
href="https://hackage.haskell.org/package/trifecta">exist</a> for
Haskell, but we will use none of them, because we need a lot less than
what they offer. Instead, we will use a minimal approach to parsing
based on the good old state monad transformer, <code>StateT</code>. We
know it well from the <a href="/posts/Unrecurse.html">previous
article</a>.</p>
<p>It is a little-known fact that <code>StateT</code> already provides
all that we need to implement a <a
href="http://www.cs.nott.ac.uk/~pszgmh/pearl.pdf">monadic parser</a>. It
even supports backtracking. This may be surprising, since
<code>StateT s b a</code> is just a <code>newtype</code> wrapper around
<code>s -&gt; b (a, s)</code>, where <code>s</code> is the state's type,
and <code>b</code> is the type of some inner monad. Why should this
matter for parsing? Well, that's because, at its most fundamental level,
<em>a parser for things <code>a</code> is a function from strings
<code>s</code> to lists <code>b ~ []</code> of pairs <code>(a, s)</code>
of things and strings</em>. That's a little Seussian rhyme I borrowed
from <a
href="http://www.willamette.edu/~fruehr/haskell/seuss.html">Fritz
Ruehr</a>. It means that if we have a string <code>s</code> and a parser
<code>StateT s b a</code> with <code>b ~ []</code>, then running the
parser on <code>s</code> will return:</p>
<ul>
<li>an empty list if there is no way to create an <code>a</code> from
any prefix of the input string <code>s</code> (including the empty
string) or</li>
<li>a non-empty list of full and/or partial parses of <code>s</code>,
where each pair in the list belongs to one alternative parse of
<code>s</code>. The first part of a pair is the parsing result,
<code>a</code>, and the second part is the unconsumed remainder of the
input string.</li>
</ul>
<p>There may be a very long list of alternatives, but for
<code>b ~ []</code> those are lazily evaluated. This is why we can think
of <code>StateT s [] a</code> as a parser with backtracking. If we don't
want backtracking, we can use <code>StateT s Maybe a</code> instead.
Then we will only ever get zero or one parse. If we get
<code>Nothing</code>, the parse failed. If we get <code>Just</code>, the
parse succeeded. For <code>b ~ Maybe</code>, we can never explore more
than one alternative. We are greedily parsing, and committing to the
first alternative that succeeds is a final decision. <code>b</code> (for
"backtracking") should always be a monad with a <code>MonadPlus</code>
instance for supporting choice (<code>mplus</code>) and failure
(<code>mzero</code>). <code>[]</code>, <code>Maybe</code>, and
<code>LogicT</code> from <a
href="https://hackage.haskell.org/package/logict">Control.Monad.Logic</a>
fulfil this requirement, but there are many monads that do not.</p>
<p>In Haskell, a string is a list of characters. Here, we have a tape of
tokens. If we want to parse a tape of tokens, then we should be able to
do that with this state monad transformer:</p>
<div class="sourceCode" id="cb35"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">type</span> <span class="dt">From</span> b t a <span class="ot">=</span> <span class="dt">StateT</span> (<span class="dt">TTape</span> t) b a</span></code></pre></div>
<p>This is the counterpart to <code>To t a</code> that we have been
using to flatten trees into tapes of tokens. To go the other way, we
need to define a value of type <code>From b t a</code>. It will need to
be made such that it is compatible with how we defined
<code>To t a</code> above and undoes the flattening we engineered there.
We will build this value from the ground up starting with the simplest
parser we can write down:</p>
<div class="sourceCode" id="cb36"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | A parser that consumes a single token from the tape and returns it.</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="ot">  token ::</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">forall</span> b t<span class="op">.</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    ( <span class="dt">MonadFail</span> b,</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Cons</span> (<span class="dt">TTape</span> t) (<span class="dt">TTape</span> t) <span class="dt">Token</span> <span class="dt">Token</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    ) <span class="ot">=&gt;</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    <span class="dt">From</span> b t <span class="dt">Token</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>  token <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    t <span class="ot">&lt;-</span> get</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">case</span> uncons t <span class="kw">of</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Nothing</span> <span class="ot">-&gt;</span> <span class="fu">fail</span> <span class="st">&quot;unexpected end of input&quot;</span></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Just</span> (x, xs) <span class="ot">-&gt;</span> put xs <span class="op">&gt;&gt;</span> <span class="fu">pure</span> x</span></code></pre></div>
<p>This parser just tries to take the first token from the tape and
yields it, no matter what the token is. If there are no tokens left, it
fails. The <code>MonadFail</code> constraint is needed for the
<code>fail</code> function, and the <code>Cons</code> constraint is
needed for the <code>uncons</code> function.</p>
<p>The second most simple parser we can write is one that consumes a
single token and returns it if and only if it matches a given
predicate:</p>
<div class="sourceCode" id="cb37"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | A parser that matches a given token and returns it.</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="ot">  isToken ::</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">forall</span> b t<span class="op">.</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>    ( <span class="dt">MonadFail</span> b,</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>      <span class="dt">MonadPlus</span> b,</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Cons</span> (<span class="dt">TTape</span> t) (<span class="dt">TTape</span> t) <span class="dt">Token</span> <span class="dt">Token</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>    ) <span class="ot">=&gt;</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Token</span> <span class="ot">-&gt;</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    <span class="dt">From</span> b t <span class="dt">Token</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>  isToken t <span class="ot">=</span> mfilter (<span class="op">==</span> t) token</span></code></pre></div>
<p>The <code>mfilter</code> function is a monadic version of
<code>filter</code> and provided by the <code>MonadPlus</code>
requirement.</p>
<p>These two parsers, <code>token</code> and <code>isToken</code>, will
turn out to be everything we need. We will use <em>combinator
functions</em> to compose them again and again until we get to the final
parser that solves our problem. The combinators will mostly be provided
by the <code>Alternative</code> and <code>MonadPlus</code> instances for
<code>From b t</code>. This will become much clearer in the next
section. It's all about the combinators from here. There is <a
href="https://en.wikibooks.org/wiki/Haskell/Alternative_and_MonadPlus">documentation</a>
on the subject for those who are interested, but it should not be
necessary to read this to understand the rest of this article.</p>
<h2 id="there-and-back-again">There And Back Again</h2>
<p>We'd like to be able to go back and forth between token tapes and
<code>Tree</code> values:</p>
<div class="sourceCode" id="cb38"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | `parse` is the inverse of `linearize`.</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- prop&gt; \tree -&gt; evalStateT parse (linearize @[] tree) == Just (tree :: Tree Int)</span></span></code></pre></div>
<p>This is a <em>there-and-back-again</em> property. It says that, if we
have a <code>Tree Int</code> value, then we can first linearize it into
a token tape, and then parse it back into the same <code>Tree Int</code>
value we started with. No treasure is lost or gained by this process.
Not even a small chest.</p>
<p>The function <code>parse</code> returns the parser we need. A formal
definition of <code>parse</code> is:</p>
<div class="sourceCode" id="cb39"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">class</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">FromTokens</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>      (<span class="ot">b ::</span> <span class="dt">Type</span> <span class="ot">-&gt;</span> <span class="dt">Type</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>      (<span class="ot">t ::</span> <span class="dt">Type</span> <span class="ot">-&gt;</span> <span class="dt">Type</span>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>      (<span class="ot">a ::</span> <span class="dt">Type</span>)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">-- | Parse a value of type `a` from a list of tokens.</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="ot">    parse ::</span> <span class="dt">From</span> b t a</span></code></pre></div>
<p>We parameterize <code>FromTokens</code> on the backtracking monad,
<code>b</code>, the tape type, <code>t</code>, and the type of the value
we want to parse, <code>a</code>. Like <code>linearize</code>,
<code>parse</code> has an annoyingly opaque <code>default</code>
implementation:</p>
<div class="sourceCode" id="cb40"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>    default<span class="ot"> parse ::</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>      ( <span class="dt">Corecursive</span> a,</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Monad</span> b,</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Traversable</span> (<span class="dt">Base</span> a),</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>        <span class="dt">FromTokensStep</span> b t (<span class="dt">Base</span> a)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>      ) <span class="ot">=&gt;</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">From</span> b t a</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>    parse <span class="ot">=</span> go</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>      <span class="kw">where</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>        go <span class="ot">=</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>          <span class="fu">fmap</span> embed <span class="op">$</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>            parseStep</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>              <span class="op">&gt;&gt;=</span> <span class="fu">traverse</span> (resetParse go)</span></code></pre></div>
<p>Let's take this apart, and see what it does. The helper
<code>go</code> replaces <code>cata</code> in the <code>default</code>
implementation of <code>linearize</code> from before. <code>go</code> is
a recursive descent parser that repeatedly calls the stepwise parser
<code>parseStep</code>. This parser comes from the
<code>FromTokensStep</code> constraint and has the type:
<code>parseStep :: From b t (Base a (TTape t))</code>. We haven't
defined <code>parseStep</code> and <code>FromTokensStep</code> yet, but
we will shortly. <code>parseStep</code> is a parser that returns a base
functor for the type <code>a</code>, where unused tokens are wrapped in
token tapes <code>TTape t</code> that appear in the recursive positions
of <code>a</code> in <code>a</code>. Those tapes are then parsed by
<code>parseStep</code> again and again, until we get a base functor
value that contains no token tapes (for <code>TreeF</code>, that would
be <code>NilF</code>). If we naively glued the base functors coming out
of this recursion together, we would get a value of type
<code>Base a (Base a (Base a (Base ... )))</code>. However, we cannot
work with this type directly, because it would depend on the runtime
value of the token tape: the more nested the encoded value, the more
nested the type. Instead, we need to incrementally roll the functors up
into an <code>a</code> value. We can do this by using the
<code>Corecursive</code> constraint, which is the counterpart to
<code>Recursive</code> from before. <code>Corecursive</code> gives us
<code>embed :: Base a a -&gt; a</code>, the inverse of
<code>project</code>, which is exactly what we need.</p>
<div class="sourceCode" id="cb41"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Run a parser on a tape, and</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- lift the result(s) into the parent parsing scope.</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Unused tokens are discarded.</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="ot">  resetParse ::</span> <span class="dt">Monad</span> b <span class="ot">=&gt;</span> </span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">From</span> b t a <span class="ot">-&gt;</span> <span class="dt">TTape</span> t <span class="ot">-&gt;</span> <span class="dt">From</span> b t a</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>  resetParse m <span class="ot">=</span> lift <span class="op">.</span> evalStateT m</span></code></pre></div>
<div class="sourceCode" id="cb42"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">class</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">FromTokensStep</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>      (<span class="ot">b ::</span> <span class="dt">Type</span> <span class="ot">-&gt;</span> <span class="dt">Type</span>)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>      (<span class="ot">t ::</span> <span class="dt">Type</span> <span class="ot">-&gt;</span> <span class="dt">Type</span>)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>      (<span class="ot">base ::</span> <span class="dt">Type</span> <span class="ot">-&gt;</span> <span class="dt">Type</span>)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">-- | A stepwise parser of a value of type `base (TTape t)`.</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="ot">    parseStep ::</span> <span class="dt">From</span> b t (base (<span class="dt">TTape</span> t))</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>    default<span class="ot"> parseStep ::</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>      ( <span class="dt">Functor</span> b,</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Generic</span> (base (<span class="dt">TTape</span> t)),</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>        <span class="dt">GFromTokensStep</span> b t (<span class="dt">Rep</span> (base (<span class="dt">TTape</span> t)))</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>      ) <span class="ot">=&gt;</span></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>      <span class="dt">From</span> b t (base (<span class="dt">TTape</span> t))</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>    parseStep <span class="ot">=</span> to <span class="op">&lt;$&gt;</span> gParseStep</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>  <span class="kw">class</span></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>    <span class="dt">GFromTokensStep</span></span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>      (<span class="ot">b ::</span> <span class="dt">Type</span> <span class="ot">-&gt;</span> <span class="dt">Type</span>)</span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>      (<span class="ot">t ::</span> <span class="dt">Type</span> <span class="ot">-&gt;</span> <span class="dt">Type</span>)</span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>      (<span class="ot">rep ::</span> <span class="dt">Type</span> <span class="ot">-&gt;</span> <span class="dt">Type</span>)</span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">-- | A generic implementation of `parseStep`.</span></span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a><span class="ot">    gParseStep ::</span> <span class="kw">forall</span> a<span class="op">.</span> <span class="dt">From</span> b t (rep a)</span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a>    <span class="dt">MonadFail</span> b <span class="ot">=&gt;</span></span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a>    <span class="dt">GFromTokensStep</span> b t <span class="dt">V1</span></span>
<span id="cb42-29"><a href="#cb42-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb42-30"><a href="#cb42-30" aria-hidden="true" tabindex="-1"></a>    gParseStep <span class="ot">=</span> <span class="fu">fail</span> <span class="st">&quot;GFromTokensStep.V1&quot;</span></span>
<span id="cb42-31"><a href="#cb42-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-32"><a href="#cb42-32" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb42-33"><a href="#cb42-33" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Monad</span> b <span class="ot">=&gt;</span></span>
<span id="cb42-34"><a href="#cb42-34" aria-hidden="true" tabindex="-1"></a>    <span class="dt">GFromTokensStep</span> b t <span class="dt">U1</span></span>
<span id="cb42-35"><a href="#cb42-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb42-36"><a href="#cb42-36" aria-hidden="true" tabindex="-1"></a>    gParseStep <span class="ot">=</span> <span class="fu">pure</span> <span class="dt">U1</span></span>
<span id="cb42-37"><a href="#cb42-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-38"><a href="#cb42-38" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb42-39"><a href="#cb42-39" aria-hidden="true" tabindex="-1"></a>    ( <span class="dt">MonadFail</span> b,</span>
<span id="cb42-40"><a href="#cb42-40" aria-hidden="true" tabindex="-1"></a>      <span class="dt">MonadPlus</span> b,</span>
<span id="cb42-41"><a href="#cb42-41" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Cons</span> (<span class="dt">TTape</span> t) (<span class="dt">TTape</span> t) <span class="dt">Token</span> <span class="dt">Token</span>,</span>
<span id="cb42-42"><a href="#cb42-42" aria-hidden="true" tabindex="-1"></a>      <span class="dt">GFromTokensStep</span> b t f,</span>
<span id="cb42-43"><a href="#cb42-43" aria-hidden="true" tabindex="-1"></a>      <span class="dt">GFromTokensStep</span> b t g</span>
<span id="cb42-44"><a href="#cb42-44" aria-hidden="true" tabindex="-1"></a>    ) <span class="ot">=&gt;</span></span>
<span id="cb42-45"><a href="#cb42-45" aria-hidden="true" tabindex="-1"></a>    <span class="dt">GFromTokensStep</span> b t (f <span class="op">:+:</span> g)</span>
<span id="cb42-46"><a href="#cb42-46" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb42-47"><a href="#cb42-47" aria-hidden="true" tabindex="-1"></a>    gParseStep <span class="ot">=</span></span>
<span id="cb42-48"><a href="#cb42-48" aria-hidden="true" tabindex="-1"></a>      (isToken <span class="dt">L</span> <span class="op">&gt;&gt;</span> <span class="dt">L1</span> <span class="op">&lt;$&gt;</span> gParseStep)</span>
<span id="cb42-49"><a href="#cb42-49" aria-hidden="true" tabindex="-1"></a>        <span class="op">&lt;|&gt;</span> (isToken <span class="dt">R</span> <span class="op">&gt;&gt;</span> <span class="dt">R1</span> <span class="op">&lt;$&gt;</span> gParseStep)</span>
<span id="cb42-50"><a href="#cb42-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-51"><a href="#cb42-51" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb42-52"><a href="#cb42-52" aria-hidden="true" tabindex="-1"></a>    ( <span class="dt">MonadFail</span> b,</span>
<span id="cb42-53"><a href="#cb42-53" aria-hidden="true" tabindex="-1"></a>      <span class="dt">MonadPlus</span> b,</span>
<span id="cb42-54"><a href="#cb42-54" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Cons</span> (<span class="dt">TTape</span> t) (<span class="dt">TTape</span> t) <span class="dt">Token</span> <span class="dt">Token</span>,</span>
<span id="cb42-55"><a href="#cb42-55" aria-hidden="true" tabindex="-1"></a>      <span class="dt">GFromTokensStep</span> b t f,</span>
<span id="cb42-56"><a href="#cb42-56" aria-hidden="true" tabindex="-1"></a>      <span class="dt">GFromTokensStep</span> b t g</span>
<span id="cb42-57"><a href="#cb42-57" aria-hidden="true" tabindex="-1"></a>    ) <span class="ot">=&gt;</span></span>
<span id="cb42-58"><a href="#cb42-58" aria-hidden="true" tabindex="-1"></a>    <span class="dt">GFromTokensStep</span> b t (f <span class="op">:*:</span> g)</span>
<span id="cb42-59"><a href="#cb42-59" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb42-60"><a href="#cb42-60" aria-hidden="true" tabindex="-1"></a>    gParseStep <span class="ot">=</span></span>
<span id="cb42-61"><a href="#cb42-61" aria-hidden="true" tabindex="-1"></a>      (<span class="op">:*:</span>)</span>
<span id="cb42-62"><a href="#cb42-62" aria-hidden="true" tabindex="-1"></a>        <span class="op">&lt;$&gt;</span> gParseStep</span>
<span id="cb42-63"><a href="#cb42-63" aria-hidden="true" tabindex="-1"></a>        <span class="op">&lt;*&gt;</span> gParseStep</span>
<span id="cb42-64"><a href="#cb42-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-65"><a href="#cb42-65" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb42-66"><a href="#cb42-66" aria-hidden="true" tabindex="-1"></a>    (<span class="dt">Monad</span> b, <span class="dt">FromTokens</span> b t c) <span class="ot">=&gt;</span></span>
<span id="cb42-67"><a href="#cb42-67" aria-hidden="true" tabindex="-1"></a>    <span class="dt">GFromTokensStep</span> b t (<span class="dt">K1</span> i c)</span>
<span id="cb42-68"><a href="#cb42-68" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb42-69"><a href="#cb42-69" aria-hidden="true" tabindex="-1"></a>    gParseStep <span class="ot">=</span> <span class="dt">K1</span> <span class="op">&lt;$&gt;</span> parse</span>
<span id="cb42-70"><a href="#cb42-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-71"><a href="#cb42-71" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb42-72"><a href="#cb42-72" aria-hidden="true" tabindex="-1"></a>    (<span class="dt">Functor</span> b, <span class="dt">GFromTokensStep</span> b t f) <span class="ot">=&gt;</span></span>
<span id="cb42-73"><a href="#cb42-73" aria-hidden="true" tabindex="-1"></a>    <span class="dt">GFromTokensStep</span> b t (<span class="dt">M1</span> i c f)</span>
<span id="cb42-74"><a href="#cb42-74" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb42-75"><a href="#cb42-75" aria-hidden="true" tabindex="-1"></a>    gParseStep <span class="ot">=</span> <span class="dt">M1</span> <span class="op">&lt;$&gt;</span> gParseStep</span></code></pre></div>
<div class="sourceCode" id="cb43"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>    ( <span class="dt">MonadFail</span> b,</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>      <span class="dt">MonadPlus</span> b,</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Cons</span> (t <span class="dt">Token</span>) (t <span class="dt">Token</span>) <span class="dt">Token</span> <span class="dt">Token</span>,</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Alternative</span> t,</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">FromTokens</span> b t a</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>    ) <span class="ot">=&gt;</span></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>    <span class="dt">FromTokensStep</span> b t (<span class="dt">TreeF</span> a)</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>    (<span class="dt">Monad</span> b, <span class="dt">FromTokensStep</span> b t (<span class="dt">TreeF</span> a)) <span class="ot">=&gt;</span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>    <span class="dt">FromTokens</span> b t (<span class="dt">Tree</span> a)</span></code></pre></div>
<div class="sourceCode" id="cb44"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    ( <span class="dt">MonadFail</span> b,</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Cons</span> (<span class="dt">TTape</span> t) (<span class="dt">TTape</span> t) <span class="dt">Token</span> <span class="dt">Token</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    ) <span class="ot">=&gt;</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">FromTokens</span> b t <span class="dt">Int</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>    parse <span class="ot">=</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>      token <span class="op">&gt;&gt;=</span> \<span class="kw">case</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>        <span class="dt">I</span> i <span class="ot">-&gt;</span> <span class="fu">pure</span> i</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>        _ <span class="ot">-&gt;</span> <span class="fu">fail</span> <span class="st">&quot;expected Int&quot;</span></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>    ( <span class="dt">MonadFail</span> b,</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Alternative</span> t,</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Cons</span> (<span class="dt">TTape</span> t) (<span class="dt">TTape</span> t) <span class="dt">Token</span> <span class="dt">Token</span></span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>    ) <span class="ot">=&gt;</span></span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>    <span class="dt">FromTokens</span> b t (<span class="dt">TTape</span> t)</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">where</span></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>    parse <span class="ot">=</span></span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>      token <span class="op">&gt;&gt;=</span> \<span class="kw">case</span></span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Rec</span> n <span class="ot">-&gt;</span> go n</span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>          <span class="kw">where</span></span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a><span class="ot">            go ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">From</span> b t (<span class="dt">TTape</span> t)</span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>            go <span class="dv">0</span> <span class="ot">=</span> <span class="fu">pure</span> empty</span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a>            go n&#39; <span class="ot">=</span> cons <span class="op">&lt;$&gt;</span> token <span class="op">&lt;*&gt;</span> go (n&#39; <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a>        _ <span class="ot">-&gt;</span> <span class="fu">fail</span> <span class="st">&quot;expected Rec&quot;</span></span></code></pre></div>
<div class="sourceCode" id="cb45"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">data</span> <span class="dt">NextF</span> a r <span class="ot">=</span> <span class="dt">FirstF</span> r <span class="op">|</span> <span class="dt">SecondF</span> a <span class="op">|</span> <span class="dt">ThirdF</span> r</span></code></pre></div>
<div class="sourceCode" id="cb46"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="ot">  accumTree&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39; ::</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">forall</span> t a<span class="op">.</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    ( <span class="dt">Alternative</span> t,</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Foldable</span> t,</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Monoid</span> a,</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">ToTokens</span> t a,</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">FromTokens</span> <span class="dt">Maybe</span> t a,</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Cons</span> (t <span class="dt">Token</span>) (t <span class="dt">Token</span>) <span class="dt">Token</span> <span class="dt">Token</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>    ) <span class="ot">=&gt;</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    <span class="dt">StateT</span> (<span class="dt">TTape</span> t, <span class="dt">Stack</span> (<span class="dt">NextF</span> a (<span class="dt">TTape</span> t))) (<span class="dt">Writer</span> a) ()</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>  accumTree&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39; <span class="ot">=</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>    while <span class="op">$</span> <span class="kw">do</span></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>      treeF <span class="ot">&lt;-</span> fromJust <span class="op">.</span> evalStateT parseStep <span class="op">&lt;$&gt;</span> zoom _1 get</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>      <span class="kw">case</span> treeF <span class="kw">of</span></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>        <span class="dt">NilF</span> <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>          c <span class="ot">&lt;-</span> zoom _2 pop</span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>          <span class="kw">case</span> c <span class="kw">of</span></span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>            <span class="dt">Just</span> (<span class="dt">FirstF</span> leftF) <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>              zoom _1 <span class="op">$</span> put leftF</span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>              <span class="fu">pure</span> <span class="dt">Continue</span></span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>            <span class="dt">Just</span> (<span class="dt">SecondF</span> contentF) <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a>              lift (tell contentF)</span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a>              zoom _1 <span class="op">$</span> put (linearizeStep <span class="op">$</span> <span class="dt">NilF</span> <span class="op">@</span>a)</span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a>              <span class="fu">pure</span> <span class="dt">Continue</span></span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a>            <span class="dt">Just</span> (<span class="dt">ThirdF</span> rightF) <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a>              zoom _1 <span class="op">$</span> put rightF</span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a>              <span class="fu">pure</span> <span class="dt">Continue</span></span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a>            <span class="dt">Nothing</span> <span class="ot">-&gt;</span> <span class="fu">pure</span> <span class="dt">Break</span></span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a>        <span class="dt">NodeF</span> {<span class="op">..</span>} <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a>          zoom _2 <span class="op">$</span> push (<span class="dt">ThirdF</span> rightF)</span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a>          zoom _2 <span class="op">$</span> push (<span class="dt">SecondF</span> contentF)</span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a>          zoom _2 <span class="op">$</span> push (<span class="dt">FirstF</span> leftF)</span>
<span id="cb46-33"><a href="#cb46-33" aria-hidden="true" tabindex="-1"></a>          zoom _1 <span class="op">$</span> put (linearizeStep <span class="op">$</span> <span class="dt">NilF</span> <span class="op">@</span>a)</span>
<span id="cb46-34"><a href="#cb46-34" aria-hidden="true" tabindex="-1"></a>          <span class="fu">pure</span> <span class="dt">Continue</span></span></code></pre></div>
<div class="sourceCode" id="cb47"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>  makeBaseFunctor &#39;<span class="dt">&#39;Sum</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">deriving</span> stock <span class="kw">instance</span> (<span class="dt">Show</span> a, <span class="dt">Show</span> r) <span class="ot">=&gt;</span> <span class="dt">Show</span> (<span class="dt">SumF</span> a r)</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">deriving</span> stock <span class="kw">instance</span> <span class="dt">Generic</span> (<span class="dt">SumF</span> a r)</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>    ( <span class="dt">Alternative</span> t,</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Foldable</span> t,</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>      <span class="dt">ToTokens</span> t a</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>    ) <span class="ot">=&gt;</span></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>    <span class="dt">ToTokensStep</span> t (<span class="dt">SumF</span> a)</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>    <span class="dt">ToTokensStep</span> t (<span class="dt">SumF</span> a) <span class="ot">=&gt;</span></span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a>    <span class="dt">ToTokens</span> t (<span class="dt">Sum</span> a)</span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a>    ( <span class="dt">Monad</span> b,</span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Alternative</span> t,</span>
<span id="cb47-21"><a href="#cb47-21" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Foldable</span> t,</span>
<span id="cb47-22"><a href="#cb47-22" aria-hidden="true" tabindex="-1"></a>      <span class="dt">FromTokens</span> b t a</span>
<span id="cb47-23"><a href="#cb47-23" aria-hidden="true" tabindex="-1"></a>    ) <span class="ot">=&gt;</span></span>
<span id="cb47-24"><a href="#cb47-24" aria-hidden="true" tabindex="-1"></a>    <span class="dt">FromTokensStep</span> b t (<span class="dt">SumF</span> a)</span>
<span id="cb47-25"><a href="#cb47-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-26"><a href="#cb47-26" aria-hidden="true" tabindex="-1"></a>  <span class="kw">instance</span></span>
<span id="cb47-27"><a href="#cb47-27" aria-hidden="true" tabindex="-1"></a>    (<span class="dt">Monad</span> b, <span class="dt">FromTokensStep</span> b t (<span class="dt">SumF</span> a)) <span class="ot">=&gt;</span></span>
<span id="cb47-28"><a href="#cb47-28" aria-hidden="true" tabindex="-1"></a>    <span class="dt">FromTokens</span> b t (<span class="dt">Sum</span> a)</span></code></pre></div>
<div class="sourceCode" id="cb48"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Calculate the sum of the content values of the linearized example tree.</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; sumTree&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- Sum {getSum = 28}</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="ot">  sumTree&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39; ::</span> <span class="dt">Sum</span> <span class="dt">Int</span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>  sumTree&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39; <span class="ot">=</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>    execWriter <span class="op">$</span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>      runStateT</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>        (accumTree&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39; <span class="op">@</span><span class="dt">Vector</span>)</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>        (linearize <span class="op">$</span> <span class="dt">Sum</span> <span class="op">&lt;$&gt;</span> exampleTree, [])</span></code></pre></div>]]></content>
  </entry>
  <entry>
      <title>Unrecurse -- A Recursive Function That Doesn&#39;t Recurse</title>
      <link href="https://tscholak.github.io/posts/Unrecurse.html"/>
      <id>https://tscholak.github.io/posts/Unrecurse.html</id>
      <updated>2022-01-20T00:00:00Z</updated>
      <category term="haskell"/>
      <category term="recursion"/>
      <summary type="html"><![CDATA[<p>Have you ever wanted to write a recursive function and wondered what
would happen if someone took away recursion from Haskell? Say goodbye to
recursive function calls, say goodbye to recursive data types. How sad
Haskell would be without them! I'm sure that thought must have occured
to you -- if not, what are you even doing here?! Well, this article has
you covered should that day ever come. After reading it, you will know
how to write a recursive function that doesn't recurse.</p>]]></summary>
      <content type="html"><![CDATA[<h2 id="preliminaries">Preliminaries</h2>
<p>For this <a
href="https://wiki.haskell.org/Literate_programming">Literate
Haskell</a> essay, a few language extensions are required. Nothing
extraordinarily fancy, just the usually fancy Haskell flavour.</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE GADTs #-}</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE RecordWildCards #-}</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE DeriveTraversable #-}</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE TypeFamilies #-}</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE ScopedTypeVariables #-}</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE FlexibleContexts #-}</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE MultiParamTypeClasses #-}</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE FlexibleInstances #-}</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE UndecidableInstances #-}</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE DeriveGeneric #-}</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE DerivingVia #-}</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="ot">{-# LANGUAGE LambdaCase #-}</span></span></code></pre></div>
<p>A bunch of these are part of <a
href="https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/control.html#extension-GHC2021">GHC2021</a>
that was introduced in GHC 9.2, but this blog is boring and still
running on GHC 8.10.</p>
<p>Unsurprisingly, we will also work with code that is not in the
<code>Prelude</code>:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">module</span> <span class="dt">Unrecurse</span> <span class="kw">where</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Control.Lens</span> (zoom, _1, _2)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Control.Monad.Cont</span> (<span class="dt">ContT</span> (runContT))</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Control.Monad.State</span> (<span class="dt">MonadState</span> (get, put), <span class="dt">StateT</span> (runStateT), evalStateT, modify)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Control.Monad.Trans</span> (<span class="dt">MonadTrans</span> (lift))</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Control.Monad.Writer</span> (<span class="dt">Writer</span>, execWriter, tell)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Data.Monoid</span> (<span class="dt">Sum</span> (..))</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">GHC.Generics</span> (<span class="dt">Generic</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  <span class="kw">import</span> <span class="dt">Prelude</span> <span class="kw">hiding</span> (even, odd)</span></code></pre></div>
<p>Now, since this is settled, we can get on with the article.</p>
<h2 id="the-best-refactoring-you-have-never-done">The Best Refactoring
You Have Never Done</h2>
<p>The first part of this article is based on a <a
href="https://www.pathsensitive.com/2019/07/the-best-refactoring-youve-never-heard.html">2019
post and talk</a> by <a href="https://www.jameskoppel.com">James
Koppel</a> about the equivalence of recursion and iteration.</p>
<p>James' talk is a great introduction to the topic, but it left out a
few important details and did not explain how to generalize the example
from the talk to more complicated cases. Also, the original talk used
Java and only a little bit of Haskell, but I'm going to exclusively use
Haskell here. This will make it clearer for people familiar with Haskell
but not with Java, like me.</p>
<p>James' example is a recursive function that prints the content of a
binary tree. The problem he chose to focus on is to convert that
recursive function to an iterative one. We will reproduce the conversion
process in Haskell code, and the first step is going to be to define an
abstract data type for binary trees:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">data</span> <span class="dt">Tree</span> a</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="ot">=</span> <span class="dt">Nil</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="op">|</span> <span class="dt">Node</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        {<span class="ot"> left ::</span> <span class="dt">Tree</span> a,</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="ot">          content ::</span> a,</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="ot">          right ::</span> <span class="dt">Tree</span> a</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">deriving</span> stock (<span class="dt">Eq</span>, <span class="dt">Show</span>, <span class="dt">Functor</span>, <span class="dt">Foldable</span>, <span class="dt">Generic</span>)</span></code></pre></div>
<p>For illustration purposes, we will use the following balanced tree
that carries consecutive integers at its seven leaves:</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ot">  exampleTree ::</span> <span class="dt">Tree</span> <span class="dt">Int</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  exampleTree <span class="ot">=</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Node</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>      ( <span class="dt">Node</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>          (<span class="dt">Node</span> <span class="dt">Nil</span> <span class="dv">1</span> <span class="dt">Nil</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>          <span class="dv">2</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>          (<span class="dt">Node</span> <span class="dt">Nil</span> <span class="dv">3</span> <span class="dt">Nil</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>      <span class="dv">4</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>      ( <span class="dt">Node</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>          (<span class="dt">Node</span> <span class="dt">Nil</span> <span class="dv">5</span> <span class="dt">Nil</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>          <span class="dv">6</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>          (<span class="dt">Node</span> <span class="dt">Nil</span> <span class="dv">7</span> <span class="dt">Nil</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>      )</span></code></pre></div>
<p>Really, any tree will do, but we will use this one. We can print the
contents of our tree using the <code>Show</code> instance of
integers.</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Print the content of a `Tree a`.</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; printTree exampleTree</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 1</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 2</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 3</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 4</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 5</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 6</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 7</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="ot">  printTree ::</span> <span class="kw">forall</span> a<span class="op">.</span> <span class="dt">Show</span> a <span class="ot">=&gt;</span> <span class="dt">Tree</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>  printTree <span class="dt">Nil</span> <span class="ot">=</span> <span class="fu">pure</span> ()</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>  printTree <span class="dt">Node</span> {<span class="op">..</span>} <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    printTree left</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">print</span> content</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    printTree right</span></code></pre></div>
<p>This is the function we want to convert to an iterative one. In its
current form, it contains two recursive calls to itself. To eliminate
the recursive calls, we need to perform a number of transformations.
Each transformation is potentially headache inducing, and I am not going
to promise pretty code. In fact, the code is going to get worse and
worse.</p>
<h2 id="continuations-and-continuation-passing-style">Continuations And
Continuation Passing Style</h2>
<p>With your expectations properly lowered, let's start with the first
transformation. We need to rewrite the <code>printTree</code> function
to use continuations, using something called the "continuation passing
style" or CPS. I'm not going to explain CPS in all its glory, only that
it is a style of programming in which functions do not return values,
but instead repeatedly pass control to a function called a continuation
that decides what to do next. The mind-bending implications of this
style of programming are introduced and discussed in <a
href="https://en.wikibooks.org/wiki/Haskell/Continuation_passing_style">this
article on wikibooks.org</a>. Have a look at that article if you are
interested in the fine details. It's not necessary to understand the
details of CPS to understand the rest of this article, though.</p>
<p>Haskell is particularly good at handling the CPS style, rewriting to
it is easy and mechanical. The tool we will use is called the
<code>ContT</code> monad transformer. It is found in the <a
href="https://hackage.haskell.org/package/transformers">transformers</a>
package. <code>ContT</code> will wrap the <code>IO</code> monad, and we
will use the <code>&gt;&gt;=</code> operator to chain continuations.
<code>IO</code> values need to be lifted to <code>ContT</code> values.
This gives us:</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ot">  printTree&#39; ::</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">forall</span> a r<span class="op">.</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Show</span> a <span class="ot">=&gt;</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Tree</span> a <span class="ot">-&gt;</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">ContT</span> r <span class="dt">IO</span> ()</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  printTree&#39; <span class="dt">Nil</span> <span class="ot">=</span> <span class="fu">pure</span> ()</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  printTree&#39; <span class="dt">Node</span> {<span class="op">..</span>} <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    printTree&#39; left</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    lift <span class="op">$</span> <span class="fu">print</span> content</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    printTree&#39; right</span></code></pre></div>
<p>The code appears mostly the same, except for a few subtleties. We
have changed the return type and added a new type variable,
<code>r</code>, that we cannot touch since it is quantified over. It is
the type of the result of the continuation. <code>r</code> will only be
of interest when we run the <code>ContT</code> monad transformer. This
is done using the
<code>runContT :: ContT r m a -&gt; (a -&gt; m r) -&gt; m r</code>
function. It runs the CPS computation encoded in
<code>ContT r m a</code> and gets the result, but only if we seed it
with one final continuation of the form <code>a -&gt; m r</code>:</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Run the `ContT` computation for `printTree&#39;`.</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; runPrintTree&#39; exampleTree</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 1</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 2</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 3</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 4</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 5</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 6</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 7</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="ot">  runPrintTree&#39; ::</span> <span class="dt">Show</span> a <span class="ot">=&gt;</span> <span class="dt">Tree</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>  runPrintTree&#39; tree <span class="ot">=</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    runContT (printTree&#39; tree) <span class="fu">pure</span></span></code></pre></div>
<p>The final continuation is <code>pure</code>, and it decides that the
result of the continuation is <code>r ~ ()</code>. Everything still
works as expected, phew.</p>
<p>The <code>ContT</code> monad transformer is a great convenience and
allows us to deal with continuations in the familiar monadic style.
What's great for Haskell and its users is not so great for us in this
article, though. Remember, we want less of that good, idiomatic Haskell,
not more of it. The goodbye to recursion must hurt. <code>ContT</code>
is very effective at hiding what is actually happening behind the
scenes. We need to pull that curtain up and see what is going on. Below
is the same code as before, but with the <code>ContT</code> monad
transformer inlined into the <code>printTree'</code> function:</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="ot">  printTree&#39;&#39; ::</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">forall</span> a r<span class="op">.</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Show</span> a <span class="ot">=&gt;</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Tree</span> a <span class="ot">-&gt;</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    (() <span class="ot">-&gt;</span> <span class="dt">IO</span> r) <span class="ot">-&gt;</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">IO</span> r</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>  printTree&#39;&#39; <span class="dt">Nil</span> <span class="ot">=</span> \c <span class="ot">-&gt;</span> c ()</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  printTree&#39;&#39; <span class="dt">Node</span> {<span class="op">..</span>} <span class="ot">=</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> first <span class="ot">=</span> \c <span class="ot">-&gt;</span> printTree&#39;&#39; left c</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        second <span class="ot">=</span> \c <span class="ot">-&gt;</span> <span class="fu">print</span> content <span class="op">&gt;&gt;=</span> c</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        third <span class="ot">=</span> \c <span class="ot">-&gt;</span> printTree&#39;&#39; right c</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        inner <span class="ot">=</span> \c <span class="ot">-&gt;</span> second (\x <span class="ot">-&gt;</span> (\() <span class="ot">-&gt;</span> third) x c)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>        outer <span class="ot">=</span> \c <span class="ot">-&gt;</span> first (\x <span class="ot">-&gt;</span> (\() <span class="ot">-&gt;</span> inner) x c)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>     <span class="kw">in</span> outer</span></code></pre></div>
<p>This is starting to look nasty. Don't look at me, I warned you.
<code>printTree''</code> is now a higher-order function that takes a
continuation function, <code>c</code>, as its second argument.
Notwithstanding, we can also clearly see now that <code>c</code> takes a
value of type <code>()</code> and returns a value of type
<code>IO r</code>. The <code>()</code> type of the argument is a
consequence of the fact that the original <code>printTree</code>
function returned a value of type <code>IO ()</code>.</p>
<p>Let's take a look at the <code>Node</code> case of
<code>printTree''</code>. The <code>do</code> notation is <a
href="https://en.wikipedia.org/wiki/Syntactic_sugar">desugared</a> into
nested continuations. <code>inner</code> chains the <code>second</code>
and <code>third</code> functions, and <code>outer</code> chains the
<code>first</code> and <code>inner</code> functions. <code>first</code>
happens first, then <code>second</code>, and then <code>third</code>. We
can convince ourselves that this painfully obfuscated
<code>printTree''</code> function is still computing the same result as
the <code>printTree</code> function.</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Run the CPS computation for `printTree&#39;&#39;`.</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; runPrintTree&#39;&#39; exampleTree</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 1</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 2</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 3</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 4</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 5</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 6</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 7</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="ot">  runPrintTree&#39;&#39; ::</span> <span class="dt">Show</span> a <span class="ot">=&gt;</span> <span class="dt">Tree</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>  runPrintTree&#39;&#39; tree <span class="ot">=</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    printTree&#39;&#39; tree (\() <span class="ot">-&gt;</span> <span class="fu">pure</span> ())</span></code></pre></div>
<h2 id="defunctionalization">Defunctionalization</h2>
<p>What we have achieved so far is nice, but we still have not
eliminated any recursive calls. In order to make progress, we need to
convert the higher-order <code>printTree''</code> function to a
first-order function. This process is called "defunctionalization". Once
again, there is a <a
href="https://en.wikipedia.org/wiki/Defunctionalization">wiki
article</a> on the subject if you are interested. It's one of those rare
and wonderous articles on Wikipedia that exclusively use Haskell to
explain things. Not that there should be more of them, but I
digress.</p>
<p>Concretely, we defunctionalize the <code>printTree''</code> function
by replacing all the continuations, <code>c :: () -&gt; IO r</code>,
with a value of a new data type <code>Kont (Next a)</code>.
<code>Kont</code> and <code>Next</code> look like this:</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">data</span> <span class="dt">Kont</span> next</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="ot">=</span> <span class="dt">Finished</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="op">|</span> <span class="dt">More</span> next (<span class="dt">Kont</span> next)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">data</span> <span class="dt">Next</span> a</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="ot">=</span> <span class="dt">First</span> (<span class="dt">Tree</span> a)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">|</span> <span class="dt">Second</span> a</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    <span class="op">|</span> <span class="dt">Third</span> (<span class="dt">Tree</span> a)</span></code></pre></div>
<p><code>Kont</code> is a recursive data type with two constructors,
<code>Finished</code> and <code>More</code>. We use
<code>Finished</code> to terminate the computation, and
<code>More</code> to indicate that we need to continue. When that
happens, we use <code>Next</code> to describe the details of the next
step in the computation. Each constructor of <code>Next</code>
corresponds to a different action that needs to be taken. The
<code>First</code> constructor is named after the <code>first</code>
function in <code>printTree''</code>. It takes a left subtree as
argument. The <code>Second</code> constructor is named after the
<code>second</code> function in <code>printTree''</code>. Its argument
is the content of the current node that needs to be printed. The
<code>Third</code> constructor is named after the <code>third</code>
function in <code>printTree''</code>, and it takes a right subtree as
argument. We need a new function, <code>apply</code>, that interprets a
<code>Kont (Next a)</code> value and executes the corresponding
action:</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="ot">  apply ::</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">forall</span> a<span class="op">.</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Show</span> a <span class="ot">=&gt;</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Kont</span> (<span class="dt">Next</span> a) <span class="ot">-&gt;</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">IO</span> ()</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  apply (<span class="dt">More</span> (<span class="dt">First</span> left) c) <span class="ot">=</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    printTree&#39;&#39;&#39; left c</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>  apply (<span class="dt">More</span> (<span class="dt">Second</span> content) c) <span class="ot">=</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">print</span> content <span class="op">&gt;&gt;</span> apply c</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>  apply (<span class="dt">More</span> (<span class="dt">Third</span> right) c) <span class="ot">=</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    printTree&#39;&#39;&#39; right c</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>  apply <span class="dt">Finished</span> <span class="ot">=</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pure</span> ()</span></code></pre></div>
<p>We can see here how different <code>Next</code> values correspond to
different actions. When the computation is finished, <code>apply</code>
returns <code>()</code>. When there is more work to do,
<code>apply</code> either calls the yet-to-be-defined
<code>printTree'''</code> function with the next subtree and the
continuation value, <code>c :: Kont (Next a)</code>, or it calls the
<code>print</code> function on the content of the node and then itself
to continue the computation. The purpose of the
<code>printTree'''</code> function is to build continuation values and
then call <code>apply</code> to execute the corresponding actions:</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="ot">  printTree&#39;&#39;&#39; ::</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">forall</span> a<span class="op">.</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Show</span> a <span class="ot">=&gt;</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Tree</span> a <span class="ot">-&gt;</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Kont</span> (<span class="dt">Next</span> a) <span class="ot">-&gt;</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">IO</span> ()</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  printTree&#39;&#39;&#39; <span class="dt">Nil</span> c <span class="ot">=</span> apply c</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  printTree&#39;&#39;&#39; <span class="dt">Node</span> {<span class="op">..</span>} c <span class="ot">=</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    apply</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>      ( <span class="dt">More</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>          (<span class="dt">First</span> left)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>          ( <span class="dt">More</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>              (<span class="dt">Second</span> content)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>              (<span class="dt">More</span> (<span class="dt">Third</span> right) c)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>          )</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>      )</span></code></pre></div>
<p>How do we know that this is all working correctly? We can run it:</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Run the defunctionalized CPS computation</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- for `printTree&#39;&#39;&#39;`.</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; runPrintTree&#39;&#39;&#39; exampleTree</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 1</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 2</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 3</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 4</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 5</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 6</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 7</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="ot">  runPrintTree&#39;&#39;&#39; ::</span> <span class="dt">Show</span> a <span class="ot">=&gt;</span> <span class="dt">Tree</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>  runPrintTree&#39;&#39;&#39; tree <span class="ot">=</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    printTree&#39;&#39;&#39; tree <span class="dt">Finished</span></span></code></pre></div>
<p>Great, we have successfully defunctionalized <code>printTree''</code>
and turned it into a first-order function. This has been a major step,
but we are not done yet. We still have to eliminate the recursive calls.
It only appears as if <code>printTree'''</code> doesn't call itself
anymore. In fact, it still does, just indirectly through mutual
recursion. This becomes more apparent once we inline <code>apply</code>
into <code>printTree'''</code>:</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="ot">  printTree&#39;&#39;&#39;&#39; ::</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">forall</span> a<span class="op">.</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Show</span> a <span class="ot">=&gt;</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Tree</span> a <span class="ot">-&gt;</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Kont</span> (<span class="dt">Next</span> a) <span class="ot">-&gt;</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">IO</span> ()</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>  printTree&#39;&#39;&#39;&#39; <span class="dt">Nil</span> (<span class="dt">More</span> (<span class="dt">First</span> left) c) <span class="ot">=</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    printTree&#39;&#39;&#39;&#39; left c</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>  printTree&#39;&#39;&#39;&#39; <span class="dt">Nil</span> (<span class="dt">More</span> (<span class="dt">Second</span> content) c) <span class="ot">=</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">print</span> content <span class="op">&gt;&gt;</span> printTree&#39;&#39;&#39;&#39; <span class="dt">Nil</span> c</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>  printTree&#39;&#39;&#39;&#39; <span class="dt">Nil</span> (<span class="dt">More</span> (<span class="dt">Third</span> right) c) <span class="ot">=</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    printTree&#39;&#39;&#39;&#39; right c</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>  printTree&#39;&#39;&#39;&#39; <span class="dt">Nil</span> <span class="dt">Finished</span> <span class="ot">=</span> <span class="fu">pure</span> ()</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>  printTree&#39;&#39;&#39;&#39; <span class="dt">Node</span> {<span class="op">..</span>} c <span class="ot">=</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    printTree&#39;&#39;&#39;&#39;</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Nil</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>      ( <span class="dt">More</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>          (<span class="dt">First</span> left)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>          ( <span class="dt">More</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>              (<span class="dt">Second</span> content)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>              (<span class="dt">More</span> (<span class="dt">Third</span> right) c)</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>          )</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>      )</span></code></pre></div>
<h2 id="state-and-stack">State And Stack</h2>
<p>At first glance, <code>printTree''''</code> doesn't look better than
what we had before. We went from two recursive calls up to now four.
There is something interesting going on here, though. The recursive call
to <code>printTree''''</code> always appears in the tail position. And
this means that we should be able to replace the calls with a loop.
Wikipedia also has <a href="https://en.wikipedia.org/wiki/Tail_call">an
article on that</a>. However, we also notice that
<code>printTree''''</code> is called with different arguments in all
four cases. We can't replace these calls with a loop without removing
those arguments first, and we can't remove the arguments until we have a
way to keep track of them. Or do we? Haskell has a special type, called
<code>State</code>, that allows for just that. On hackage,
<code>State</code> is available as <a
href="https://hackage.haskell.org/package/transformers-0.6.0.2/docs/Control-Monad-Trans-State-Lazy.html"><code>Control.Monad.Trans.State.Lazy</code></a>.
Rather than passing arguments, we are going to update the
<code>State</code> with the arguments' values. In preparation for this,
let us have a closer look at <code>Kont</code>. You may have already
noticed, but our <code>Kont</code> is isomorphic to <code>[]</code>:
<code>Finished</code> is the empty list, and <code>More</code> is simply
the list constructor. Let's acknowledge that fact by using the
<code>[]</code> data type directly and by giving <code>Kont</code> a
better name: <code>Stack</code>.</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">type</span> <span class="dt">Stack</span> a <span class="ot">=</span> [a]</span></code></pre></div>
<p>The only operations on <code>Stack</code> we will need in the
following are adding and removing single elements from its end. These
operations are commonly called <code>push</code> and <code>pop</code>.
They can be implemented as follows:</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="ot">  push ::</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">forall</span> a m<span class="op">.</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">MonadState</span> (<span class="dt">Stack</span> a) m <span class="ot">=&gt;</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    a <span class="ot">-&gt;</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    m ()</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  push x <span class="ot">=</span> modify (x <span class="op">:</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="ot">  pop ::</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">forall</span> a m<span class="op">.</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="dt">MonadState</span> (<span class="dt">Stack</span> a) m <span class="ot">=&gt;</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    m (<span class="dt">Maybe</span> a)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>  pop <span class="ot">=</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    get <span class="op">&gt;&gt;=</span> \<span class="kw">case</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>      [] <span class="ot">-&gt;</span> <span class="fu">pure</span> <span class="dt">Nothing</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>      (x <span class="op">:</span> xs) <span class="ot">-&gt;</span> put xs <span class="op">&gt;&gt;</span> <span class="fu">pure</span> (<span class="dt">Just</span> x)</span></code></pre></div>
<p>Notice here how we use <code>get</code>, <code>put</code>, and
<code>modify</code> to update the <code>Stack</code> state. With
<code>push</code> and <code>pop</code>, <code>printTree''''</code>
becomes:</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="ot">  printTree&#39;&#39;&#39;&#39;&#39; ::</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">forall</span> a<span class="op">.</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Show</span> a <span class="ot">=&gt;</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Tree</span> a <span class="ot">-&gt;</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">StateT</span> (<span class="dt">Stack</span> (<span class="dt">Next</span> a)) <span class="dt">IO</span> ()</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>  printTree&#39;&#39;&#39;&#39;&#39; <span class="dt">Nil</span> <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    next <span class="ot">&lt;-</span> pop</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">case</span> next <span class="kw">of</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Just</span> (<span class="dt">First</span> left) <span class="ot">-&gt;</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>        printTree&#39;&#39;&#39;&#39;&#39; left</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Just</span> (<span class="dt">Second</span> content) <span class="ot">-&gt;</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>        lift (<span class="fu">print</span> content)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>          <span class="op">&gt;&gt;</span> printTree&#39;&#39;&#39;&#39;&#39; <span class="dt">Nil</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Just</span> (<span class="dt">Third</span> right) <span class="ot">-&gt;</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>        printTree&#39;&#39;&#39;&#39;&#39; right</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Nothing</span> <span class="ot">-&gt;</span> <span class="fu">pure</span> ()</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>  printTree&#39;&#39;&#39;&#39;&#39; <span class="dt">Node</span> {<span class="op">..</span>} <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    push (<span class="dt">Third</span> right)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    push (<span class="dt">Second</span> content)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>    push (<span class="dt">First</span> left)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    printTree&#39;&#39;&#39;&#39;&#39; <span class="dt">Nil</span></span></code></pre></div>
<p>One thing to note here is that we use <code>StateT</code>, not
<code>State</code>, to represent the state of our computation. This is
because <code>StateT</code> is a monad transformer, and we already have
effects in <code>IO</code> that we need to lift into it.</p>
<p>Rather than building a value of type <code>Stack (Next a)</code> that
we pass to <code>printTree''''</code>, in <code>printTree'''''</code>,
we use <code>push</code> and <code>pop</code> to update the
<code>Stack</code> state. As always, we need to confirm that this is
doing the right thing:</p>
<div class="sourceCode" id="cb18"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Run the defunctionalized CPS computation</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- for `printTree&#39;&#39;&#39;&#39;&#39;`.</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; runPrintTree&#39;&#39;&#39;&#39;&#39; exampleTree</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 1</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 2</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 3</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 4</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 5</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 6</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 7</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="ot">  runPrintTree&#39;&#39;&#39;&#39;&#39; ::</span> <span class="dt">Show</span> a <span class="ot">=&gt;</span> <span class="dt">Tree</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>  runPrintTree&#39;&#39;&#39;&#39;&#39; tree <span class="ot">=</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    evalStateT (printTree&#39;&#39;&#39;&#39;&#39; tree) []</span></code></pre></div>
<p>The result is as expected. This takes care of the
<code>Kont (Next a)</code> argument, but we still need to eliminate the
<code>Tree a</code> argument. We can use the same trick again and add
<code>Tree a</code> to the state:</p>
<div class="sourceCode" id="cb19"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="ot">  printTree&#39;&#39;&#39;&#39;&#39;&#39; ::</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">forall</span> a<span class="op">.</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Show</span> a <span class="ot">=&gt;</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">StateT</span> (<span class="dt">Tree</span> a, <span class="dt">Stack</span> (<span class="dt">Next</span> a)) <span class="dt">IO</span> ()</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>  printTree&#39;&#39;&#39;&#39;&#39;&#39; <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    tree <span class="ot">&lt;-</span> zoom _1 get</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">case</span> tree <span class="kw">of</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Nil</span> <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>        c <span class="ot">&lt;-</span> zoom _2 pop</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>        <span class="kw">case</span> c <span class="kw">of</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>          <span class="dt">Just</span> (<span class="dt">First</span> left) <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>            zoom _1 <span class="op">$</span> put left</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>            printTree&#39;&#39;&#39;&#39;&#39;&#39;</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>          <span class="dt">Just</span> (<span class="dt">Second</span> content) <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>            lift (<span class="fu">print</span> content)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>            zoom _1 <span class="op">$</span> put <span class="dt">Nil</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>            printTree&#39;&#39;&#39;&#39;&#39;&#39;</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>          <span class="dt">Just</span> (<span class="dt">Third</span> right) <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>            zoom _1 <span class="op">$</span> put right</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>            printTree&#39;&#39;&#39;&#39;&#39;&#39;</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>          <span class="dt">Nothing</span> <span class="ot">-&gt;</span> <span class="fu">pure</span> ()</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>      <span class="dt">Node</span> {<span class="op">..</span>} <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>        zoom _2 <span class="op">$</span> push (<span class="dt">Third</span> right)</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>        zoom _2 <span class="op">$</span> push (<span class="dt">Second</span> content)</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>        zoom _2 <span class="op">$</span> push (<span class="dt">First</span> left)</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>        zoom _1 <span class="op">$</span> put <span class="dt">Nil</span></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>        printTree&#39;&#39;&#39;&#39;&#39;&#39;</span></code></pre></div>
<p>In this new version, <code>printTree''''''</code> appears in the tail
position and does not have any arguments. We are now ready for the final
magic step, which is to eliminate all recursive calls.</p>
<h2 id="while">While</h2>
<p>Let us introduce a little helper, <code>while</code>:</p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">data</span> <span class="dt">Continue</span> <span class="ot">=</span> <span class="dt">Continue</span> <span class="op">|</span> <span class="dt">Break</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="ot">  while ::</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">forall</span> m<span class="op">.</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Monad</span> m <span class="ot">=&gt;</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    m <span class="dt">Continue</span> <span class="ot">-&gt;</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    m ()</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>  while m <span class="ot">=</span> m <span class="op">&gt;&gt;=</span> \<span class="kw">case</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Continue</span> <span class="ot">-&gt;</span> while m</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Break</span> <span class="ot">-&gt;</span> <span class="fu">pure</span> ()</span></code></pre></div>
<p>This function just runs the given monadic computation,
<code>m :: m Continue</code>, again and again until it returns
<code>Break</code>. This is as close to a "while" loop as we can get in
Haskell, we can't remove the recursion here. Let us pretend the
hypothetical recursion-free Haskell has <code>while</code> as a
primitive.</p>
<p>With this, we finally have:</p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="ot">  printTree&#39;&#39;&#39;&#39;&#39;&#39;&#39; ::</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">forall</span> a<span class="op">.</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Show</span> a <span class="ot">=&gt;</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">StateT</span> (<span class="dt">Tree</span> a, <span class="dt">Stack</span> (<span class="dt">Next</span> a)) <span class="dt">IO</span> ()</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>  printTree&#39;&#39;&#39;&#39;&#39;&#39;&#39; <span class="ot">=</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    while <span class="op">$</span> <span class="kw">do</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>      tree <span class="ot">&lt;-</span> zoom _1 get</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>      <span class="kw">case</span> tree <span class="kw">of</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Nil</span> <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>          c <span class="ot">&lt;-</span> zoom _2 pop</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>          <span class="kw">case</span> c <span class="kw">of</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>            <span class="dt">Just</span> (<span class="dt">First</span> left) <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>              zoom _1 <span class="op">$</span> put left</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>              <span class="fu">pure</span> <span class="dt">Continue</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>            <span class="dt">Just</span> (<span class="dt">Second</span> content) <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>              lift (<span class="fu">print</span> content)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>              zoom _1 <span class="op">$</span> put <span class="dt">Nil</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>              <span class="fu">pure</span> <span class="dt">Continue</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>            <span class="dt">Just</span> (<span class="dt">Third</span> right) <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>              zoom _1 <span class="op">$</span> put right</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>              <span class="fu">pure</span> <span class="dt">Continue</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>            <span class="dt">Nothing</span> <span class="ot">-&gt;</span> <span class="fu">pure</span> <span class="dt">Break</span></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Node</span> {<span class="op">..</span>} <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>          zoom _2 <span class="op">$</span> push (<span class="dt">Third</span> right)</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>          zoom _2 <span class="op">$</span> push (<span class="dt">Second</span> content)</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>          zoom _2 <span class="op">$</span> push (<span class="dt">First</span> left)</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>          zoom _1 <span class="op">$</span> put <span class="dt">Nil</span></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>          <span class="fu">pure</span> <span class="dt">Continue</span></span></code></pre></div>
<p>There are no recursive calls left. Well, almost, because we are still
using the recursive <code>Tree</code> type. We will worry about that in
a follow-up piece.</p>
<p>This marvel of a function still computes the same result,</p>
<div class="sourceCode" id="cb22"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Run the unrolled `printTree&#39;&#39;&#39;&#39;&#39;&#39;&#39;` program.</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; runPrintTree&#39;&#39;&#39;&#39;&#39;&#39;&#39; exampleTree</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 1</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 2</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 3</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 4</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 5</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 6</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 7 </span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="ot">  runPrintTree&#39;&#39;&#39;&#39;&#39;&#39;&#39; ::</span> <span class="dt">Show</span> a <span class="ot">=&gt;</span> <span class="dt">Tree</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>  runPrintTree&#39;&#39;&#39;&#39;&#39;&#39;&#39; tree <span class="ot">=</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    evalStateT printTree&#39;&#39;&#39;&#39;&#39;&#39;&#39; (tree, [])</span></code></pre></div>
<p>Fantastic! What's next?</p>
<h2 id="accumulations">Accumulations</h2>
<p>The <code>printTree</code> example from James' 2019 talk is a bit too
simple, because we run <code>printTree</code> only for its effects. We
don't care about the result since it is just <code>()</code> and will be
the same for all trees we pass to <code>printTree</code>. What if this
was different? In many real applications, we might want to reduce the
tree to a value, say, accumulate a result, like a sum. This common
pattern is captured by the function below:</p>
<div class="sourceCode" id="cb23"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="ot">  accumTree ::</span> <span class="kw">forall</span> a<span class="op">.</span> <span class="dt">Monoid</span> a <span class="ot">=&gt;</span> <span class="dt">Tree</span> a <span class="ot">-&gt;</span> a</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>  accumTree <span class="dt">Nil</span> <span class="ot">=</span> <span class="fu">mempty</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>  accumTree <span class="dt">Node</span> {<span class="op">..</span>} <span class="ot">=</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> lacc <span class="ot">=</span> accumTree left</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>        racc <span class="ot">=</span> accumTree right</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>     <span class="kw">in</span> lacc <span class="op">&lt;&gt;</span> content <span class="op">&lt;&gt;</span> racc</span></code></pre></div>
<p>Using <code>accumTree</code>, summing up all the content values of
our example tree is a simple matter:</p>
<div class="sourceCode" id="cb24"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Sum the content values of a tree.</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; sumTree exampleTree</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 28</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="ot">  sumTree ::</span> <span class="dt">Num</span> a <span class="ot">=&gt;</span> <span class="dt">Tree</span> a <span class="ot">-&gt;</span> a</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>  sumTree tree <span class="ot">=</span> getSum <span class="op">$</span> accumTree (<span class="dt">Sum</span> <span class="op">&lt;$&gt;</span> tree)</span></code></pre></div>
<p><code>Sum</code> is a newtype wrapper whose only function is to
select the <code>Monoid</code> instance for summation, where
<code>mempty</code> is zero and <code>mappend</code> is addition. This
is necessary since Haskell doesn't have named class instances.</p>
<p>By the way, since <code>Tree</code> has a <code>Foldable</code>
instance, we could have achieved the same by using <code>foldMap</code>
from <code>Data.Foldable</code>:</p>
<div class="sourceCode" id="cb25"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Sum the content values of a tree.</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; sumTree&#39; exampleTree</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 28</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="ot">  sumTree&#39; ::</span> (<span class="dt">Num</span> a, <span class="dt">Foldable</span> f) <span class="ot">=&gt;</span> f a <span class="ot">-&gt;</span> a</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>  sumTree&#39; tree <span class="ot">=</span> getSum <span class="op">$</span> <span class="fu">foldMap</span> <span class="dt">Sum</span> tree</span></code></pre></div>
<p>This certainly is convenient. Haskellers love <code>foldMap</code>,
because they can use it on any data type that has a
<code>Foldable</code> instance, not just <code>Tree</code>. But this is
supposed to be a tutorial about inconvenient, recursion-free Haskell,
and for that we need to understand how we can remove recursion from
<code>accumTree</code>. The tool we are going to use here is the
<code>Writer</code> monad.</p>
<div class="sourceCode" id="cb26"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="ot">  accumTree&#39;&#39; ::</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">forall</span> a<span class="op">.</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Monoid</span> a <span class="ot">=&gt;</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Tree</span> a <span class="ot">-&gt;</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Writer</span> a ()</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>  accumTree&#39;&#39; <span class="dt">Nil</span> <span class="ot">=</span> <span class="fu">pure</span> ()</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>  accumTree&#39;&#39; <span class="dt">Node</span> {<span class="op">..</span>} <span class="ot">=</span> <span class="kw">do</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    accumTree&#39;&#39; left</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>    tell content</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>    accumTree&#39;&#39; right</span></code></pre></div>
<p>This version of <code>accumTree</code> is a bit more complicated.
Accumulation has been moved to the <code>Writer</code> monad, and we
need to use <code>tell</code> to accumulate the result. We also are
working with a monadic effect, <code>Writer</code>, whereas
<code>accumTree</code> was pure. We can extract the result by using
<code>execWriter</code>:</p>
<div class="sourceCode" id="cb27"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Sum the content values of a tree.</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; sumTree&#39;&#39; exampleTree</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 28</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="ot">  sumTree&#39;&#39; ::</span> <span class="dt">Num</span> a <span class="ot">=&gt;</span> <span class="dt">Tree</span> a <span class="ot">-&gt;</span> a</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>  sumTree&#39;&#39; tree <span class="ot">=</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    getSum <span class="op">$</span> execWriter <span class="op">$</span> accumTree&#39;&#39; (<span class="dt">Sum</span> <span class="op">&lt;$&gt;</span> tree)</span></code></pre></div>
<p>Great, this works. Now, sharp eyes will notice that
<code>accumTree''</code> and <code>printTree</code> from before are
structurally equivalent. The only difference is that
<code>printTree</code> uses <code>IO</code>, and
<code>accumTree''</code> uses <code>Writer a</code>. That's all. Based
on what we have seen so far, we can therefore immediately see how
<code>accumTree''</code> can be made iterative:</p>
<div class="sourceCode" id="cb28"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="ot">  accumTree&#39;&#39;&#39;&#39;&#39;&#39;&#39; ::</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">forall</span> a<span class="op">.</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">Monoid</span> a <span class="ot">=&gt;</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">StateT</span> (<span class="dt">Tree</span> a, <span class="dt">Stack</span> (<span class="dt">Next</span> a)) (<span class="dt">Writer</span> a) ()</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>  accumTree&#39;&#39;&#39;&#39;&#39;&#39;&#39; <span class="ot">=</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    while <span class="op">$</span> <span class="kw">do</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>      tree <span class="ot">&lt;-</span> zoom _1 get</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>      <span class="kw">case</span> tree <span class="kw">of</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Nil</span> <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>          c <span class="ot">&lt;-</span> zoom _2 pop</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>          <span class="kw">case</span> c <span class="kw">of</span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>            <span class="dt">Just</span> (<span class="dt">First</span> left) <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>              zoom _1 <span class="op">$</span> put left</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>              <span class="fu">pure</span> <span class="dt">Continue</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>            <span class="dt">Just</span> (<span class="dt">Second</span> content) <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>              lift (tell content)</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>              zoom _1 <span class="op">$</span> put <span class="dt">Nil</span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>              <span class="fu">pure</span> <span class="dt">Continue</span></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>            <span class="dt">Just</span> (<span class="dt">Third</span> right) <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>              zoom _1 <span class="op">$</span> put right</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>              <span class="fu">pure</span> <span class="dt">Continue</span></span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>            <span class="dt">Nothing</span> <span class="ot">-&gt;</span> <span class="fu">pure</span> <span class="dt">Break</span></span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>        <span class="dt">Node</span> {<span class="op">..</span>} <span class="ot">-&gt;</span> <span class="kw">do</span></span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>          zoom _2 <span class="op">$</span> push (<span class="dt">Third</span> right)</span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>          zoom _2 <span class="op">$</span> push (<span class="dt">Second</span> content)</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>          zoom _2 <span class="op">$</span> push (<span class="dt">First</span> left)</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>          zoom _1 <span class="op">$</span> put <span class="dt">Nil</span></span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>          <span class="fu">pure</span> <span class="dt">Continue</span></span></code></pre></div>
<p>Does this look familiar? This is the exact same as
<code>printTree'''''''</code> from above, except
<code>print content</code> is replaced by <code>tell content</code>. We
run this function using its companion function
<code>sumTree'''''''</code> that executes the <code>Writer</code> and
<code>State</code> effects:</p>
<div class="sourceCode" id="cb29"><pre
class="sourceCode haskell literate"><code class="sourceCode haskell"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- | Run the unrolled `accumTree&#39;&#39;&#39;&#39;&#39;&#39;&#39;` program</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- and calculate the sum of the content values of the tree.</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- &gt;&gt;&gt; sumTree&#39;&#39;&#39;&#39;&#39;&#39;&#39; exampleTree</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">-- 28</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="ot">  sumTree&#39;&#39;&#39;&#39;&#39;&#39;&#39; ::</span> <span class="dt">Num</span> a <span class="ot">=&gt;</span> <span class="dt">Tree</span> a <span class="ot">-&gt;</span> a</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>  sumTree&#39;&#39;&#39;&#39;&#39;&#39;&#39; tree <span class="ot">=</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    getSum <span class="op">$</span> execWriter <span class="op">$</span> runStateT accumTree&#39;&#39;&#39;&#39;&#39;&#39;&#39; (<span class="dt">Sum</span> <span class="op">&lt;$&gt;</span> tree, [])</span></code></pre></div>
<p>This settles the issue. Now you know how to write a recursive
function that doesn't recurse.</p>
<h2 id="next-up">Next Up</h2>
<p>Next time, we will take a closer look at the <code>Tree</code> type,
and we will make sure it doesn't recurse either. This will be super
ugly, I can't wait for that.</p>]]></content>
  </entry>
  <entry>
      <title>Nil.</title>
      <link href="https://tscholak.github.io/posts/hello-world.html"/>
      <id>https://tscholak.github.io/posts/hello-world.html</id>
      <updated>2022-01-01T00:00:00Z</updated>
      <summary type="html"><![CDATA[Nil.]]></summary>
      <content type="html"><![CDATA[<p>Nil.</p>]]></content>
  </entry>
  <entry>
      <title>UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding
with Text-to-Text Language Models</title>
      <link href="https://tscholak.github.io/publications/unified-skg.html"/>
      <id>https://tscholak.github.io/publications/unified-skg.html</id>
      <updated>2022-01-16T00:00:00Z</updated>
      <category term="research"/>
      <summary type="html"><![CDATA[]]></summary>
      <content type="html"><![CDATA[<p>Structured knowledge grounding (SKG) leverages structured knowledge
to complete user requests, such as semantic parsing over databases and
question answering over knowledge bases. Since the inputs and outputs of
SKG tasks are heterogeneous, they have been studied separately by
different communities, which limits systematic and compatible research
on SKG. In this paper, we overcome this limitation by proposing the SKG
framework, which unifies 21 SKG tasks into a text-to-text format, aiming
to promote systematic SKG research, instead of being exclusive to a
single task, domain, or dataset. We use UnifiedSKG to benchmark T5 with
different sizes and show that T5, with simple modifications when
necessary, achieves state-of-the-art performance on almost all of the 21
tasks. We further demonstrate that multi-task prefix-tuning improves the
performance on most tasks, largely improving the overall performance.
UnifiedSKG also facilitates the investigation of zero-shot and few-shot
learning, and we show that T0, GPT-3, and Codex struggle in zero-shot
and few-shot learning for SKG. We also use UnifiedSKG to conduct a
series of controlled experiments on structured knowledge encoding
variants across SKG tasks. UnifiedSKG is easily extensible to more
tasks, and it is open-sourced.</p>]]></content>
  </entry>
  <entry>
      <title>Towards Neural Functional Program Evaluation</title>
      <link href="https://tscholak.github.io/publications/neural-interpreters.html"/>
      <id>https://tscholak.github.io/publications/neural-interpreters.html</id>
      <updated>2021-12-09T00:00:00Z</updated>
      <category term="research"/>
      <category term="haskell"/>
      <summary type="html"><![CDATA[]]></summary>
      <content type="html"><![CDATA[<p>This paper explores the capabilities of current transformer-based
language models for program evaluation of simple functional programming
languages. We introduce a new program generation mechanism that allows
control over syntactic sugar for semantically equivalent programs. T5
experiments reveal that neural functional program evaluation performs
surprisingly well, achieving high 90% exact program match scores for
most in-distribution and out-of-distribution tests. Using pretrained T5
weights has significant advantages over random initialization. We
present and evaluate on three datasets to study generalization abilities
that are specific to functional programs based on: type, function
composition, and reduction steps.</p>]]></content>
  </entry>
  <entry>
      <title>PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding
from Language Models</title>
      <link href="https://tscholak.github.io/publications/picard.html"/>
      <id>https://tscholak.github.io/publications/picard.html</id>
      <updated>2021-11-01T00:00:00Z</updated>
      <category term="research"/>
      <category term="haskell"/>
      <summary type="html"><![CDATA[]]></summary>
      <content type="html"><![CDATA[<p>Large pre-trained language models for textual data have an
unconstrained output space; at each decoding step, they can produce any
of 10,000s of sub-word tokens. When fine-tuned to target constrained
formal languages like SQL, these models often generate invalid code,
rendering it unusable. We propose PICARD, a method for constraining
auto-regressive decoders of language models through incremental parsing.
PICARD helps to find valid output sequences by rejecting inadmissible
tokens at each decoding step. On the challenging Spider and CoSQL
text-to-SQL translation tasks, we show that PICARD transforms fine-tuned
T5 models with passable performance into state-of-the-art solutions.
Code and trained models are available <a
href="https://github.com/ElementAI/picard">here</a>.</p>]]></content>
  </entry>
  <entry>
      <title>DuoRAT: Towards Simpler Text-to-SQL Models</title>
      <link href="https://tscholak.github.io/publications/duorat.html"/>
      <id>https://tscholak.github.io/publications/duorat.html</id>
      <updated>2021-06-01T00:00:00Z</updated>
      <category term="research"/>
      <summary type="html"><![CDATA[]]></summary>
      <content type="html"><![CDATA[<p>Recent neural text-to-SQL models can effectively translate natural
language questions to corresponding SQL queries on unseen databases.
Working mostly on the Spider dataset, researchers have proposed
increasingly sophisticated solutions to the problem. Contrary to this
trend, in this paper, we focus on simplifications. We begin by building
DuoRAT, a re-implementation of the state-of-the-art RAT-SQL model that
unlike RAT-SQL is using only relation-aware or vanilla transformers as
the building blocks. We perform several ablation experiments using
DuoRAT as the baseline model. Our experiments confirm the usefulness of
some techniques and point out the redundancy of others, including
structural SQL features and features that link the question with the
schema.</p>]]></content>
  </entry>
  <entry>
      <title>Apriel-H1</title>
      <link href="https://tscholak.github.io/slide-decks/apriel-h1.html"/>
      <id>https://tscholak.github.io/slide-decks/apriel-h1.html</id>
      <updated>2025-11-05T00:00:00Z</updated>
      <summary type="html"><![CDATA[]]></summary>
      <content type="html"><![CDATA[<section id="efficiency--capability" class="slide level2">
<h2>Efficiency = Capability</h2>
<p><strong>Apriel matches frontier reasoning at 15B.</strong><br />
But full attention pays the quadratic tax → long ctx throughput is now
the bottleneck.</p>
<p><strong>Speed creates capability:</strong></p>
<ul>
<li><strong>Agents keep full tickets/logs in memory</strong> → fewer
compactions</li>
<li><strong>More tools per turn</strong> at same latency</li>
<li><strong>Deeper reasoning chains</strong> with more steps → better
accuracy</li>
<li><strong>Larger RAG contexts</strong> stay in-context</li>
<li><strong>Higher req/s on existing fleet</strong> → lower unit cost,
better UX</li>
</ul>
<p><strong>That's why we're building efficient hybrids.</strong></p>
<aside class="notes">
<p>60s</p>
<p>Sathwik showed Apriel matches much bigger frontier models at 15B
parameters.</p>
<p>But it runs full attention - every token sees every token, cost
scales quadratically.</p>
<p>That quadratic cost is now the ceiling: how long can a reasoning
chain run? How many tools can an agent call? How much context fits
before we truncate?</p>
<p>Efficiency determines what's possible inside a latency budget. That's
the strategic shift.</p>
<p>The path is hybrid architectures - that's Apriel-H.</p>
</aside>
</section>
<section id="how-hybrids-work" class="slide level2">
<h2>How Hybrids Work</h2>
<table>
<thead>
<tr>
<th></th>
<th><strong>Full Attention</strong></th>
<th><strong>Efficient (Linear/Sparse)</strong></th>
<th><strong>Hybrid</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Complexity</strong></td>
<td>O(n²)</td>
<td>O(n) or sub-quadratic</td>
<td>Mixed</td>
</tr>
<tr>
<td><strong>KV cache</strong></td>
<td>Large, grows with n²</td>
<td>Small or none</td>
<td>Reduced ~50-75%</td>
</tr>
<tr>
<td><strong>Global fidelity</strong></td>
<td>Perfect</td>
<td>Limited</td>
<td>Preserved in key layers</td>
</tr>
<tr>
<td><strong>Throughput gain</strong></td>
<td>1×</td>
<td>2-10× (but quality risk)</td>
<td>2-10× at minimal Δ</td>
</tr>
</tbody>
</table>
<p><strong>Pattern:</strong> Keep ~20-30% full attention for global
reasoning,<br />
replace rest with Mamba/linear/sparse mechanisms.</p>
<aside class="notes">
<p>45s</p>
<p>Here's the trade-off table.</p>
<p>Full attention: it's great but expensive. Efficient mechanisms: fast
but risky. Hybrids: keep 20 to 30 percent of layers as full attention to
preserve global patterns, replace the rest with efficient
mechanisms.</p>
<p>Result: 2 to 10 times throughput with quality deltas you can
ship.</p>
<p>And there's research that shows that hybrids can beat full attention
in some cases, i.e. they might be pareto-optimal. The detail is in how
you design them, what the ratio is, and how you distill them.</p>
</aside>
</section>
<section id="hybrids-are-shipping-at-scale" class="slide level2">
<h2>Hybrids Are Shipping at Scale</h2>
<ul>
<li><p><strong>Apr</strong>: <a
href="https://arxiv.org/abs/2504.03624">NVIDIA Nemotron-H-47B</a><br />
<strong>9:1 Mamba-2:FA</strong> hybrid, <strong>≈3× faster</strong> vs
dense 70B at long ctx</p></li>
<li><p><strong>May</strong>: <a
href="https://falcon-lm.github.io/blog/falcon-h1/">Falcon-H1-34B</a><br />
Parallel Mamba-2 + FA hybrid, <strong>4× prefill</strong>, <strong>8×
decode</strong> at long ctx</p></li>
<li><p><strong>Jun</strong>: <a
href="https://arxiv.org/abs/2506.13585">MiniMax-M1</a><br />
<strong>7:1 Lightning:FA</strong> hybrid, <strong>≈3–4× faster
decode</strong> @100k tokens</p></li>
<li><p><strong>Aug</strong>: <a
href="https://arxiv.org/abs/2508.14444">Nemotron-Nano-9B-v2</a><br />
<strong>7:1 Mamba-2:FA</strong> hybrid, <strong>up to 6×
throughput</strong> vs Qwen3-8B</p></li>
<li><p><strong>Sep</strong>: <a
href="https://qwen.ai/blog?id=4074cca80393150c248e508aa62983f9cb7d27cd&amp;from=research.latest-advancements-list">Qwen3-Next-80B-A3B</a><br />
<strong>3:1</strong> Gated-DeltaNet:FA hybrid, <strong>&gt;10×
throughput</strong> vs Qwen3-32B @&gt;32k</p></li>
<li><p><strong>Sep</strong>: <a
href="https://api-docs.deepseek.com/news/news250929">DeepSeek
V3.2-Exp</a><br />
<strong>MLA+DSA</strong> sparse, 1:64 attended:total tokens @128k,
<strong>3× faster</strong> at long ctx</p></li>
<li><p><strong>Oct</strong>: <a
href="https://arxiv.org/abs/2510.26692">Kimi-Linear-48B-A3B</a><br />
<strong>3:1</strong> KLA:FA hybrid, <strong>75% KV↓</strong>, <strong>up
to 6× decode</strong> @1M</p></li>
</ul>
<aside class="notes">
<p>50s</p>
<p>The industry is converging on hybrids.</p>
<p>April: Nemotron-H, 3× faster.</p>
<p>May: Falcon-H1, 4-8× gains.</p>
<p>June: MiniMax Lightning Attention, 3-4× at 100k tokens.</p>
<p>August-September: Nemotron-Nano v2 and Qwen3-Next in the 3:1 to 7:1
range, pushing 6-10× throughput.</p>
<p>Then DeepSeek and most recently Kimi with production-grade sparse and
linear hybrids.</p>
<p>Hybrids and efficient attention are becoming the new normal for long
context and agentic workloads.</p>
</aside>
</section>
<section id="apriel-h1" class="slide level2">
<h2>Apriel-H1</h2>
<section id="what-you-get" class="level3">
<h3>What You Get</h3>
<p><img data-src="/images/apriel-h.png" width="250"
alt="Apriel-H" /></p>
<p>Today we release <strong>Apriel-H1</strong>:</p>
<ul>
<li><strong>Hybrid reasoner</strong> distilled from Apriel-15B</li>
<li><strong>~2× throughput</strong> in vLLM with <strong>minimal quality
deltas</strong></li>
<li><strong>Runs today</strong> in vLLM</li>
</ul>
<aside class="notes">
<p>60s</p>
<p>So what happens when we apply this? Apriel-H1 30 - thirty Mamba-2
layers, twenty full attention layers.</p>
<p>About 2× throughput in vLLM - meaning you can serve twice as many
requests on the same hardware, or cut latency in half for the same
load.</p>
</aside>
</section>
<section id="proof-it-works" class="level3">
<h3>Proof It Works</h3>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Apriel 15B</th>
<th><strong>Apriel-H1 30</strong></th>
<th>Δ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Throughput (vLLM)</strong></td>
<td>1×</td>
<td><strong>~2×</strong></td>
<td><strong>+2×</strong></td>
</tr>
<tr>
<td>MATH500</td>
<td>90</td>
<td><strong>92</strong></td>
<td>+2</td>
</tr>
<tr>
<td>GSM8k</td>
<td>97</td>
<td><strong>95</strong></td>
<td>−2</td>
</tr>
<tr>
<td>AIME'24</td>
<td>70</td>
<td><strong>65</strong></td>
<td>−5</td>
</tr>
<tr>
<td>GPQA-D</td>
<td>59</td>
<td><strong>55</strong></td>
<td>−4</td>
</tr>
<tr>
<td>MBPP</td>
<td>86</td>
<td><strong>85</strong></td>
<td>−1</td>
</tr>
<tr>
<td>MT-Bench</td>
<td>8.30</td>
<td><strong>8.58</strong></td>
<td>+0.28</td>
</tr>
</tbody>
</table>
<aside class="notes">
<p>Here are the numbers. 2× throughput. Benchmark quality nearly flat -
MATH500 actually goes up, GSM8k down 2 points, AIME down 5. The hardest
reasoning tasks dip slightly but well within recoverable range via
tuning.</p>
<p>Our hybrids are production-grade and can ship today.</p>
</aside>
</section>
<section id="evaluation-results" class="level3">
<h3>Evaluation Results</h3>
<p><img
data-src="/images/apriel-h-vs-apriel-15b-eval-thrput-comparison.png"
alt="Apriel-H1 Evaluation Results" /></p>
<aside class="notes">
<p>Here's the side-by-side comparison showing the quality-throughput
trade.</p>
</aside>
</section>
</section>
<section id="how-apriel-h1-works" class="slide level2">
<h2>How Apriel-H1 Works</h2>
<section id="architecture--h1-30" class="level3">
<h3>Architecture — H1-30</h3>
<ul>
<li>Start: Apriel-15B teacher (50 FA layers)</li>
<li>Replace least-critical FA layers with <strong>Mamba</strong> (no KV
cache, linear time)</li>
<li>Keep <strong>20 FA layers</strong> to preserve global patterns</li>
</ul>
<aside class="notes">
<p>20s</p>
<p>The architecture is straightforward: start with Apriel-15B - 50
full-attention layers.</p>
<p>We identify which layers are least critical for reasoning, replace
them with Mamba blocks - no KV cache, linear time complexity.</p>
<p>Keep 20 full-attention layers to preserve the global reasoning
patterns.</p>
<p>That's the H1-30 configuration.</p>
</aside>
</section>
<section id="distillation--3-steps" class="level3">
<h3>Distillation — 3 steps</h3>
<ol>
<li><strong>Score layer importance</strong> (LOO perf drop + MMR distill
loss)</li>
<li><strong>Swap</strong> low-importance FA → Mamba (MIL-style init from
attention)</li>
<li><strong>Stage &amp; gate</strong>: H1-25 → H1-27 →
<strong>H1-30</strong> (… H1-34/37/40) with reverse-KL; ship at best
quality/throughput trade</li>
</ol>
<pre><code>Teacher (50L): [FA][FA][FA][FA][FA][FA][FA][FA][FA][FA] ...
H1-30:         [FA][FA][FA][M ][FA][M ][M ][M ][M ][FA] ...
                ^           ^           ^           ^
              &quot;keep&quot;     &quot;convert&quot;   &quot;convert&quot;    &quot;keep&quot;</code></pre>
<aside class="notes">
<p>Three-step process:</p>
<p>First, we score every layer - measure performance drop when removed,
measure distillation loss when replaced with Mamba. That tells us which
layers the model actually needs.</p>
<p>Second, swap the low-importance layers to Mamba, initialize from the
attention weights so we don't start from scratch.</p>
<p>Third, staged distillation - walk the ratio up gradually: H1-25,
H1-27, H1-30, gate at each step with reverse-KL divergence. Ship where
quality-throughput trade is best.</p>
</aside>
</section>
<section id="eval-score-vs-throughput" class="level3">
<h3>Eval Score vs Throughput</h3>
<p><img data-src="/images/apriel-h1-eval-score-vs-throughput.png"
alt="Apriel-H1 Family Performance" /></p>
<aside class="notes">
<p>Here's the trade-off curve.</p>
<p>Baseline Apriel-15B on the left. As we convert more layers to Mamba,
throughput climbs while quality incurs small deltas.</p>
<p>H1-30 is the sweet spot we're shipping - 2× throughput, same general
reasoning strength.</p>
<p>Beyond that, H1-40 pushes toward 3× with acceptable quality
deltas.</p>
<p>With more compute, each of these can be tuned further to recover
quality if needed.</p>
</aside>
</section>
</section>
<section id="whats-next" class="slide level2">
<h2>What's Next</h2>
<p><strong>Apriel-H2 roadmap:</strong></p>
<ul>
<li><strong>Advanced mixers</strong>: Gated DeltaNet, Kimi Linear
Attention</li>
<li><strong>Higher efficient-to-full ratios</strong>: Search-guided
layer placement</li>
<li><strong>Stacked optimizations</strong>: Sliding window +
quantization + sparse attention</li>
<li><strong>Target</strong>: 5-10× throughput while maintaining
reasoning quality</li>
</ul>
<p><strong>The path forward:</strong></p>
<ul>
<li>From-scratch hybrid training gives the best ceiling</li>
<li>Distillation offers practical retrofitting for existing models</li>
<li>Both approaches matter for different constraints</li>
</ul>
<aside class="notes">
<p>45s</p>
<p>Looking ahead to H2:</p>
<p>We'll explore more advanced mixers like Gated DeltaNet and Kimi
Linear Attention.</p>
<p>Use search-guided layer placement to push higher efficient-to-full
attention ratios.</p>
<p>Stack multiple optimizations - sliding window, quantization, sparse
attention - to compound gains.</p>
<p>Target: 5-10× throughput while maintaining reasoning quality.</p>
<p>The lesson: from-scratch hybrid training gives you the best possible
result, but distillation offers a practical path when you can't retrain
from scratch. Both approaches have their place.</p>
</aside>
</section>
<section id="thank-you" class="title-slide slide level1"
data-background-color="#000">
<h1>Thank You</h1>

</section>

<section id="apriel-h1-efficient-reasoning-through-hybrid-architectures"
class="slide level2" data-background-color="#000">
<h2>Apriel-H1: Efficient Reasoning Through Hybrid Architectures</h2>
<p><strong>SLAM Lab — ServiceNow</strong></p>
<p><strong>Contact</strong>: Torsten Scholak (<a
href="mailto:torsten.scholak@servicenow.com"
class="email">torsten.scholak@servicenow.com</a>)</p>
<p><strong>Team</strong>: Oleksiy Ostapenko, Luke Kumar, Raymond Li,
Denis Kocetkov, Joel Lamy-Poirier</p>
</section>]]></content>
  </entry>
</feed>